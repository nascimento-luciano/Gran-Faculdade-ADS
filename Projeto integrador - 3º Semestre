# üìÅ Projeto: Classifica√ß√£o de Imagens com MobileNet e Arquiteturas Avan√ßadas

Este projeto realiza a **classifica√ß√£o de imagens industriais** (relacionadas ao processo de peneiramento vibrat√≥rio) utilizando **redes neurais convolucionais (CNNs)** com TensorFlow e Keras no Google Colab. O c√≥digo foi estruturado para facilitar o uso de diferentes arquiteturas e maximizar a performance via GPU e precis√£o mista.

---

## üìå Objetivo

Desenvolver e treinar modelos de Deep Learning para classificar imagens de um processo industrial real, utilizando:

- T√©cnicas de **data augmentation**
- **Divis√£o estratificada** de dados
- **Treinamento com GPU** e precis√£o mista (`mixed_float16`)
- **Arquiteturas modernas de CNNs** pr√©-treinadas

---

## üß∞ Tecnologias Utilizadas

- Python 3.x
- Google Colab (com suporte a GPU)
- TensorFlow 2.x / Keras
- Pandas, NumPy, Matplotlib, Seaborn
- OpenCV, Pillow
- Scikit-learn
- Plotly, IPyWidgets

---

## üß† Funcionalidades

- üìÇ Acesso direto ao Google Drive para ler o dataset
- üîÑ Pr√©-processamento e aumento de dados (`ImageDataGenerator`)
- üß† Treinamento com arquiteturas como:
  - `MobileNet`
  - `ResNet50`
  - `VGG16`
  - `EfficientNetB0/B3`
  - `DenseNet121`
  - `InceptionV3`
  - `Xception`
- üìä Avalia√ß√£o com:
  - Matriz de confus√£o
  - Curvas ROC e Precision-Recall
  - F1-Score e AUC
- ‚öôÔ∏è Uso de callbacks (`EarlyStopping`, `ReduceLROnPlateau`)
- üß™ Separa√ß√£o autom√°tica em treino, valida√ß√£o e teste (80/10/10)
- üéØ Visualiza√ß√£o interativa com widgets e gr√°ficos

---

## üìÅ Estrutura Esperada do Dataset


//------------------------------------------------ USAR C√ìDIGO INICIAL PARA OS PR√ìXIMOS MODELOS ------------------------------------------------//

C√≥digo usado como exemplo e adaptado ao projeto:

https://medium.com/thedeephub/computer-vision-project-image-classification-with-tensorflow-and-keras-264944d09721

1. Montagem do Google Drive no Google Colab
"""

from google.colab import drive
drive.mount('/content/drive')

from google.colab import drive  # Importa a biblioteca para montar o Google Drive no Colab
import os  # Importa a biblioteca 'os' para interagir com o sistema de arquivos

# Montando o Google Drive para acesso no Colab
drive.mount('/content/drive')  # Monta o Google Drive no caminho '/content/drive'

# Listando os arquivos e diret√≥rios dentro de 'Colab Notebooks' para verificar a estrutura
print("Conte√∫do de 'Colab Notebooks':")  # Exibe uma mensagem para indicar o que ser√° mostrado
print(os.listdir('/content/drive/MyDrive/Colab Notebooks/PeneiraDataSetJPG4Partes/'))  # Lista e exibe o conte√∫do da pasta 'Colab Notebooks'

# Habilitar Suporte a Widgets no Colab
from google.colab import output
output.enable_custom_widget_manager()

import os
from google.colab import drive

# Fun√ß√£o para montar o Google Drive com tratamento de erros
def mount_drive(mountpoint='/content/drive'):
    try:
        # Verificar se o diret√≥rio j√° existe e est√° montado
        if os.path.exists(mountpoint):
            print(f"üîç Verificando estado do ponto de montagem: {mountpoint}")
            if os.path.ismount(mountpoint):
                print("‚úÖ Google Drive j√° est√° montado.")
                return
            else:
                # Se o diret√≥rio existe mas n√£o est√° montado, tentar limpar
                print("‚ö†Ô∏è Ponto de montagem existe mas n√£o est√° conectado. Tentando limpar...")
                os.system(f"rm -rf {mountpoint}/*")  # Remove arquivos residuais (cuidado com isso)
                if os.listdir(mountpoint):
                    raise OSError(f"Ponto de montagem {mountpoint} cont√©m arquivos residuais que n√£o podem ser removidos.")

        # Criar o diret√≥rio se n√£o existir
        if not os.path.exists(mountpoint):
            print(f"üìÅ Criando diret√≥rio {mountpoint}")
            os.makedirs(mountpoint)

        # Montar o Google Drive
        print("‚è≥ Montando Google Drive...")
        drive.mount(mountpoint, force_remount=True)
        print("‚úÖ Google Drive montado com sucesso em", mountpoint)

    except OSError as e:
        print(f"‚ùå Erro ao montar o Google Drive: {e}")
        print("üí° Sugest√£o: Tente desconectar e reconectar o runtime (Runtime > Disconnect and delete runtime) e execute novamente.")
    except Exception as e:
        print(f"‚ùå Erro inesperado: {e}")

# Executar a montagem
mount_drive('/content/drive')

# Verificar se o Drive foi montado corretamente
if os.path.ismount('/content/drive'):
    print("üîç Listando conte√∫do inicial de '/content/drive':")
    print(os.listdir('/content/drive'))
else:
    print("‚ùå Falha na montagem. Verifique sua conex√£o ou tente novamente.")

# Listando os arquivos e diret√≥rios dentro de 'Colab Notebooks' para verificar a estrutura
print("Conte√∫do de 'Colab Notebooks':")  # Exibe uma mensagem para indicar o que ser√° mostrado
print(os.listdir('/content/drive/MyDrive/Colab Notebooks/PeneiraDataSetJPG4Partes/'))  # Lista e exibe o conte√∫do da pasta 'Colab Notebooks'

"""2. Comando Completo para Limpeza"""

import shutil  # Biblioteca para opera√ß√µes de alto n√≠vel com arquivos e diret√≥rios (ex: remover pastas).
import os      # Biblioteca para interagir com o sistema operacional (ex: manipula√ß√£o de caminhos e diret√≥rios).
import gc      # M√≥dulo para coleta de lixo (garbage collection), usado para liberar mem√≥ria.
from google.colab import runtime  # M√≥dulo do Colab para gerenciar o ambiente de execu√ß√£o (ex: reiniciar o runtime).

# Limpar arquivos tempor√°rios
shutil.rmtree('/content', ignore_errors=True)
os.makedirs('/content', exist_ok=True)

# Liberar mem√≥ria
gc.collect()

# Reiniciar o ambiente de execu√ß√£o (opcional)
runtime.unassign()

print("Limpeza conclu√≠da: arquivos tempor√°rios, mem√≥ria e cookies removidos!")

"""//-------------- USAR PARA FAZER A LIMPEZA DAS BIBLIOTECAS INSTALADAS EM CASO DE CONFLITO --------------//"""

!pip uninstall -y tensorflow-estimator
!pip uninstall -y tensorflow
!pip uninstall -y keras
!pip uninstall -y scikit-learn
!pip uninstall -y plotly
!pip uninstall -y numpy
!pip uninstall -y scipy
!pip uninstall -y joblib
!pip uninstall -y threadpoolctl
!pip uninstall -y opencv-python
!pip uninstall -y imgaug
!pip uninstall -y matplotlib
!pip uninstall -y numba
!pip uninstall -y gensim
!pip uninstall -y langchain
!pip uninstall -y pytensor
!pip uninstall -y thinc
!pip uninstall -y cupy-cuda12x
!pip uninstall -y pytorch-lightning
!pip uninstall -y pandas
!pip uninstall -y seaborn
!pip uninstall -y utils
!pip uninstall -y pillow
!pip uninstall -y google-colab
!pip uninstall -y logging
!pip uninstall -y csv
!pip uninstall -y tensorboard

# Desinstalar bibliotecas instaladas com pip
!pip uninstall -y opencv-python numpy pillow matplotlib seaborn scikit-learn tensorflow keras plotly

# Remover depend√™ncias do Google Colab
!pip uninstall -y visualization-utils

# Desinstalar outros pacotes relacionados a aprendizado de m√°quina
!pip uninstall -y shap

"""1. Bibliotecas Importadas para Processamento de Dados, Vis√£o Computacional e Deep Learning"""

# NOTA:
# *** Ap√≥s instalar bibliotecas no Colab, execute novamente as c√©lulas de c√≥digo
# para que as novas bibliotecas sejam reconhecidas e continue o treinamento,
# optando por n√£o reiniciar o runtime a menos que seja estritamente necess√°rio. ***

# Ap√≥s reconectar ao Google Drive, clique em "Cancelar" para dar continuidade ao treinamento.

# ============================
# Instala√ß√£o de Depend√™ncias (Se necess√°rio)
# ============================
import importlib

def install_if_needed(package_name, install_name=None):
    if install_name is None:
        install_name = package_name
    try:
        importlib.import_module(package_name)
        print(f"{package_name} j√° est√° instalado.")
    except ImportError:
        print(f"{package_name} n√£o encontrado. Instalando...")
        !pip install {install_name}
        print(f"{package_name} instalado com sucesso.")

# Verificar e instalar bibliotecas necess√°rias
install_if_needed('plotly')
install_if_needed('scikit-learn')
install_if_needed('seaborn')
install_if_needed('opencv-python', 'opencv-python==4.6.0.66')
install_if_needed('pillow')
install_if_needed('numpy', 'numpy==1.23.5')
install_if_needed('scipy')
install_if_needed('matplotlib')
install_if_needed('pandas')
install_if_needed('numba', 'numba==0.57')
install_if_needed('joblib')
install_if_needed('cufflinks')
install_if_needed('geemap')
install_if_needed('datascience')
install_if_needed('tensorflow', 'tensorflow==2.17.0')
install_if_needed('llvmlite', 'llvmlite==0.43.0')
install_if_needed('shap')
install_if_needed('tqdm')
install_if_needed('progressbar2')
install_if_needed('cupy-cuda12x', 'cupy-cuda12x==12.0.0')
install_if_needed('thinc', 'thinc==8.2.2')
install_if_needed('pytensor', 'pytensor==2.26.1')
install_if_needed('cudf-cu12')
install_if_needed('nx-cugraph-cu12')
install_if_needed('rmm-cu12')

# Atualizar pip, setuptools e wheel
!pip install --upgrade pip setuptools wheel

# ============================
# Bibliotecas Padr√£o
# ============================
import os  # Para manipula√ß√£o de diret√≥rios e caminhos.
import time  # Para medir tempos de execu√ß√£o e c√°lculos de delays.
import random  # Para gera√ß√£o de valores aleat√≥rios.
import logging  # Logs Adicionais
import csv  # Fun√ß√£o para salvar os resultados de treinamento em um arquivo CSV
import h5py  # Formato .h5 pode ser usado para modelos Keras mais antigos

# ============================
# Bibliotecas de Visualiza√ß√£o
# ============================
import matplotlib.pyplot as plt  # Biblioteca para cria√ß√£o de gr√°ficos e visualiza√ß√µes.
import seaborn as sns  # Biblioteca para gr√°ficos estat√≠sticos e estiliza√ß√£o.
import plotly.graph_objects as go  # Ferramenta para criar gr√°ficos interativos avan√ßados.
from rich.console import Console  # Importa a classe Console para exibir elementos formatados e coloridos no terminal
from rich.progress import Progress, BarColumn, TextColumn, TimeRemainingColumn  # Importa ferramentas para criar barras de progresso personalizadas
import tensorflow as tf  # Importa o TensorFlow para constru√ß√£o e treinamento de modelos de machine learning

# ============================
# Manipula√ß√£o de Imagens
# ============================
#import cv2  # Biblioteca OpenCV para manipula√ß√£o e processamento de imagens.
import numpy as np  # Biblioteca para opera√ß√µes matem√°ticas e manipula√ß√£o de arrays.
from PIL import Image  # Biblioteca Pillow para manipula√ß√£o avan√ßada de imagens.

!pip uninstall -y numpy opencv-python  # Desinstala as vers√µes atuais de NumPy e OpenCV para evitar poss√≠veis conflitos.
!pip install numpy==1.19.5 opencv-python==4.6.0.66 --no-cache-dir  # Instala vers√µes espec√≠ficas de NumPy e OpenCV sem usar cache, garantindo compatibilidade controlada.

#import cv2  # Importa a biblioteca OpenCV para processamento de imagens.
import numpy as np  # Importa o NumPy, utilizado para opera√ß√µes num√©ricas e manipula√ß√£o de arrays.

#print("OpenCV version:", cv2.__version__)  # Exibe a vers√£o instalada do OpenCV.
print("NumPy version:", np.__version__)  # Exibe a vers√£o instalada do NumPy.

# ============================
# Bibliotecas de Aprendizado de M√°quina
# ============================
import pandas as pd  # Para manipula√ß√£o de dados, especialmente com dataframes.
from sklearn.model_selection import train_test_split, StratifiedKFold  # Para divis√£o de dados e valida√ß√£o cruzada.
from sklearn.model_selection import cross_val_score, cross_val_predict  # Para valida√ß√£o cruzada.
from sklearn.preprocessing import label_binarize, LabelBinarizer  # Para binariza√ß√£o de r√≥tulos (transforma√ß√£o de classes).
from sklearn.decomposition import PCA  # Para an√°lise de componentes principais (redu√ß√£o de dimensionalidade).
from sklearn.metrics import (
    confusion_matrix,  # Para calcular matrizes de confus√£o.
    classification_report,  # Para relat√≥rios detalhados de classifica√ß√£o.
    f1_score,  # Para calcular o F1 Score.
    precision_recall_curve,  # Para curvas de precis√£o-recall.
    average_precision_score,  # Para c√°lculo de m√©dia de precis√£o.
    roc_curve,  # Para curvas ROC.
    auc,  # Para calcular a √°rea sob a curva ROC.
    ConfusionMatrixDisplay  # Para exibir matrizes de confus√£o.
)
from sklearn.manifold import TSNE  # Para visualiza√ß√£o de dados em dimens√µes reduzidas (e.g., t-SNE).
from sklearn.ensemble import RandomForestClassifier  # Para classifica√ß√£o utilizando Random Forest.

# ============================
# Bibliotecas de Deep Learning (TensorFlow e Keras)
# ============================
import tensorflow as tf  # Biblioteca principal de aprendizado de m√°quina.
print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))
from tensorflow import keras  # Interface de alto n√≠vel para TensorFlow.
from tensorflow.keras.applications import ResNet50  # Importa a arquitetura ResNet50, popular por suas conex√µes residuais que facilitam o treinamento de redes profundas.
from tensorflow.keras.applications import VGG16  # Importa a arquitetura VGG16, conhecida pela simplicidade e efic√°cia em tarefas de classifica√ß√£o de imagens.
from tensorflow.keras.applications import MobileNet  # Importa a arquitetura MobileNet, projetada para dispositivos m√≥veis e sistemas de baixa pot√™ncia.
from tensorflow.keras.applications import InceptionV3  # Importa a arquitetura InceptionV3, eficiente em tarefas complexas devido ao uso de m√≥dulos Inception.
from tensorflow.keras.applications import DenseNet121  # Importa a arquitetura DenseNet121, que utiliza conex√µes densas entre camadas para efici√™ncia e precis√£o.
from tensorflow.keras.applications import EfficientNetB0  # Importa a arquitetura EfficientNetB0, projetada para escalabilidade e desempenho em diversos tamanhos de redes.
from tensorflow.keras.applications import EfficientNetB3  # Importa a arquitetura EfficientNetB3, uma vers√£o mais avan√ßada e eficiente da fam√≠lia EfficientNet.
from tensorflow.keras.applications import Xception  # Importa a arquitetura Xception, baseada em convolu√ß√µes separ√°veis, ideal para tarefas que requerem efici√™ncia e alta precis√£o.
from tensorflow.keras import layers, backend as K, utils  # Camadas, backend e utilit√°rios do Keras.
from tensorflow.keras.models import Model, load_model  # Para definir modelos customizados.
from tensorflow.keras.metrics import categorical_crossentropy  # Para c√°lculo de perda categ√≥rica cruzada.
from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Para gerar e transformar imagens em tempo real.
from tensorflow.keras.layers import Flatten, Dense, Activation, GlobalAveragePooling2D, Dropout, BatchNormalization  # Camadas para modelos.
from tensorflow.keras.optimizers import RMSprop  # Otimizador RMSprop.
from tensorflow.keras.optimizers import Adam  # Importando o otimizador Adam
from tensorflow.keras.callbacks import Callback, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau  # Callbacks para treinamento.
from tensorflow.keras.applications import ResNet50, MobileNet, VGG16  # Modelos de redes neurais pr√©-treinados.
from tensorflow.keras.utils import plot_model  # Para gerar uma visualiza√ß√£o gr√°fica da arquitetura do modelo treinado.
from tqdm import tqdm  # Importa o m√≥dulo tqdm para exibir barras de progresso no terminal

# ============================
# Ferramentas de Aprendizado de M√°quina do Scikit-learn
# ============================
from sklearn.preprocessing import LabelBinarizer  # Para binarizar as classes no formato one-hot.
from sklearn.metrics import precision_recall_curve, roc_curve, auc  # M√©tricas de avalia√ß√£o de desempenho.
from sklearn.metrics import confusion_matrix, roc_curve, auc  # Para avalia√ß√£o do modelo de classifica√ß√£o.
from sklearn import metrics  # Importa o m√≥dulo metrics para usar fun√ß√µes como classification_report

# ============================
# Configura√ß√£o de Precis√£o Mista
# ============================
policy = tf.keras.mixed_precision.Policy('mixed_float16')  # Usa FP16 para c√°lculos e FP32 para vari√°veis
tf.keras.mixed_precision.set_global_policy(policy)  # Configura a pol√≠tica global de precis√£o mista

# Verificar se a pol√≠tica foi aplicada corretamente
print(f"Policy set to: {tf.keras.mixed_precision.global_policy()}")

# ============================
# Montar o Google Drive
# ============================
# from google.colab import drive
# drive.mount('/content/drive')

# ============================
# Fun√ß√µes Utilit√°rias e Importa√ß√µes
# ============================
# Verifica a presen√ßa do arquivo 'utils.py' e tenta importar fun√ß√µes
# utils_path = '/content/drive/MyDrive/Colab Notebooks/PeneiraDataSetJPG4Partes/utils.py'
# if os.path.exists(utils_path):
#     print("O arquivo 'utils.py' foi encontrado.")
#     !cat utils_path  # Exibe o conte√∫do do arquivo 'utils.py' para verifica√ß√£o.
#     try:
#         from utils import *  # Importa todas as fun√ß√µes utilit√°rias.
#         print("Fun√ß√µes importadas com sucesso!")
#     except ImportError as e:
#         print(f"Erro ao importar as fun√ß√µes do arquivo 'utils.py': {e}")
# else:
#     print("O arquivo 'utils.py' n√£o foi encontrado no diret√≥rio especificado.")

"""2. Bibliotecas Importadas para Processamento de Dados, Vis√£o Computacional e Deep Learning"""

# NOTA:
# *** Ap√≥s instalar bibliotecas no Colab, execute novamente as c√©lulas de c√≥digo
# para que as novas bibliotecas sejam reconhecidas e continue o treinamento,
# optando por n√£o reiniciar o runtime a menos que seja estritamente necess√°rio. ***

# Ap√≥s reconectar ao Google Drive somente clique em "Cancelar" para dar continuidade ao treinamento.

# ============================
# Instala√ß√£o de Depend√™ncias (Se necess√°rio)
# ============================
#!pip install tensorflow --upgrade  # Atualiza o TensorFlow
!pip install plotly  # Para gr√°ficos interativos.
!pip install scikit-learn  # Para ferramentas de aprendizado de m√°quina.
!pip install seaborn  # Para gr√°ficos estat√≠sticos.
!pip install opencv-python==4.6.0.66  # Para a vers√£o espec√≠fica do OpenCV.
!pip install pillow  # Para manipula√ß√£o de imagens.
!pip install numpy==1.23.5  # Para garantir a vers√£o correta do NumPy.
!pip install scipy matplotlib pandas seaborn pillow scikit-learn numba joblib plotly  # Instala pacotes essenciais para an√°lise de dados e machine learning
!pip install pandas matplotlib scipy  # Instala novamente os pacotes principais para resolver depend√™ncias
!pip install --upgrade --upgrade-strategy eager -r <requirements.txt>  # Atualiza pacotes de acordo com um arquivo de requisitos, for√ßando a instala√ß√£o de depend√™ncias mais recentes
#!pip uninstall cufflinks geemap datascience  # Remove pacotes problem√°ticos para reinstal√°-los posteriormente
!pip install cufflinks geemap datascience  # Reinstala os pacotes mencionados para corrigir depend√™ncias ausentes
!pip install tensorflow==2.17.0 # Utilizado para constru√ß√£o e treinamento de modelos de aprendizado de m√°quina e redes neurais
!pip uninstall -y llvmlite numba shap  # Remove as vers√µes atuais para evitar conflitos
!pip install -U llvmlite==0.43.0      # Instala a vers√£o espec√≠fica necess√°ria do llvmlite
!pip install -U numba                 # Atualiza o numba para uma vers√£o compat√≠vel
!pip install shap                     # Reinstala o SHAP com depend√™ncias corrigidas
!pip install tqdm                     # Use a fun√ß√£o tqdm para exibir a barra de progresso de maneira personalizada.
!pip install progressbar2             # O progressbar2 tamb√©m oferece barras de progresso para o terminal com uma apar√™ncia mais personalizada.
!pip install --upgrade --force-reinstall numpy pandas seaborn matplotlib  # Atualiza e reinstala as bibliotecas para corrigir incompatibilidades
!pip install --upgrade --force-reinstall numpy pandas scipy seaborn matplotlib tensorflow  # Reinstala todas as bibliotecas para corrigir conflitos
!pip install --no-cache-dir numpy  # Garante que a vers√£o correta do numpy seja usada
import os
os.kill(os.getpid(), 9)  # Reinicia o kernel para aplicar as mudan√ßas


# Remova pacotes conflitantes
#!pip uninstall -y cudf-cu12 nx-cugraph-cu12 rmm-cu12

# O pacote cupy-cuda12x √© uma biblioteca Python que fornece uma interface semelhante √† do NumPy
# Para realizar c√°lculos num√©ricos no GPU usando CUDA, a plataforma de computa√ß√£o paralela desenvolvida pela NVIDIA.
#!pip install cupy-cuda12x==12.0.0
!pip install numba==0.57 cupy-cuda12x==12.0.0 thinc==8.2.2 pytensor==2.26.1
!pip install cudf-cu12

# Instale pacotes necess√°rios com as vers√µes corretas
#!pip install numba==0.57 cupy-cuda12x==12.0.0 thinc==8.2.2 pytensor==2.26.1
!pip install pandas==2.2.2

# Reinstale pacotes conflitantes com depend√™ncias ajustadas
!pip install cudf-cu12 nx-cugraph-cu12 rmm-cu12

# For√ßar Atualiza√ß√µes de Depend√™ncias
!pip install --upgrade --force-reinstall --no-deps pandas matplotlib scipy seaborn pillow scikit-learn numba joblib plotly tensorflow

# Resolver Conflitos Futuros
!pip install --upgrade --force-reinstall --no-deps cudf-cu12 cupy-cuda12x pandas matplotlib scipy seaborn pillow scikit-learn

# Cria√ß√£o de um ambiente virtual no Colab (n√£o padr√£o, mas funcional)
!python -m venv myenv  # Cria o ambiente virtual chamado 'myenv'

# Ativa√ß√£o do ambiente virtual (adaptado para o Colab)
!source myenv/bin/activate  # Ativa o ambiente no Linux/Mac
# No Windows, isso seria equivalente a: !myenv\Scripts\activate.bat

# Ap√≥s ativar o ambiente, instale os pacotes necess√°rios
!myenv/bin/pip install scipy matplotlib pandas seaborn pillow scikit-learn numba joblib plotly  # Instala os pacotes no ambiente virtual

# Confirme as instala√ß√µes
!myenv/bin/pip list  # Lista os pacotes instalados no ambiente virtual

# Confirme as Instala√ß√µes
!pip list

# Listar pacotes pr√©-instalados no Colab
!pip freeze

# Instale o TensorFlow com suporte a GPU
!pip install tensorflow-gpu
#For√ßar a instala√ß√£o de uma vers√£o espec√≠fica
!pip install tensorflow-gpu==2.10.0
# Adicione o par√¢metro --no-cache-dir para garantir que o cache n√£o interfira na instala√ß√£o
!pip install tensorflow-gpu --no-cache-dir

# Atualizar o pip, setuptools e wheel
!pip install --upgrade pip setuptools wheel

# ============================
# Bibliotecas Padr√£o
# ============================
import os  # Para manipula√ß√£o de diret√≥rios e caminhos.
import time  # Para medir tempos de execu√ß√£o e c√°lculos de delays.
import random  # Para gera√ß√£o de valores aleat√≥rios.
import logging  # Logs Adicionais
import csv  # Fun√ß√£o para salvar os resultados de treinamento em um arquivo CSV
import h5py # Formato .h5 pode ser usado para modelos Keras mais antigos

# ============================
# Bibliotecas de Visualiza√ß√£o
# ============================
import matplotlib.pyplot as plt  # Biblioteca para cria√ß√£o de gr√°ficos e visualiza√ß√µes.
#import seaborn as sns  # Biblioteca para gr√°ficos estat√≠sticos e estiliza√ß√£o.
import plotly.graph_objects as go  # Ferramenta para criar gr√°ficos interativos avan√ßados.
from rich.console import Console  # Importa a classe Console para exibir elementos formatados e coloridos no terminal
from rich.progress import Progress, BarColumn, TextColumn, TimeRemainingColumn  # Importa ferramentas para criar barras de progresso personalizadas
#import tensorflow as tf  # Importa o TensorFlow para constru√ß√£o e treinamento de modelos de machine learning

# ============================
# Manipula√ß√£o de Imagens
# ============================
import cv2  # Biblioteca OpenCV para manipula√ß√£o e processamento de imagens.
import numpy as np  # Biblioteca para opera√ß√µes matem√°ticas e manipula√ß√£o de arrays.
from PIL import Image  # Biblioteca Pillow para manipula√ß√£o avan√ßada de imagens.

# ============================
# Bibliotecas de Aprendizado de M√°quina
# ============================
import pandas as pd  # Para manipula√ß√£o de dados, especialmente com dataframes.
from sklearn.model_selection import train_test_split, StratifiedKFold  # Para divis√£o de dados e valida√ß√£o cruzada.
from sklearn.model_selection import cross_val_score, cross_val_predict  # Para valida√ß√£o cruzada.
from sklearn.preprocessing import label_binarize, LabelBinarizer  # Para binariza√ß√£o de r√≥tulos (transforma√ß√£o de classes).
from sklearn.decomposition import PCA  # Para an√°lise de componentes principais (redu√ß√£o de dimensionalidade).
from sklearn.metrics import (
    confusion_matrix,  # Para calcular matrizes de confus√£o.
    classification_report,  # Para relat√≥rios detalhados de classifica√ß√£o.
    f1_score,  # Para calcular o F1 Score.
    precision_recall_curve,  # Para curvas de precis√£o-recall.
    average_precision_score,  # Para c√°lculo de m√©dia de precis√£o.
    roc_curve,  # Para curvas ROC.
    auc,  # Para calcular a √°rea sob a curva ROC.
    ConfusionMatrixDisplay  # Para exibir matrizes de confus√£o.
)
from sklearn.manifold import TSNE  # Para visualiza√ß√£o de dados em dimens√µes reduzidas (e.g., t-SNE).
from sklearn.ensemble import RandomForestClassifier  # Para classifica√ß√£o utilizando Random Forest.

# ============================
# Bibliotecas de Deep Learning (TensorFlow e Keras)
# ============================
import tensorflow as tf  # Biblioteca principal de aprendizado de m√°quina.
print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))
from tensorflow import keras  # Interface de alto n√≠vel para TensorFlow.
from tensorflow.keras.applications import ResNet50  # Importa a arquitetura ResNet50, popular por suas conex√µes residuais que facilitam o treinamento de redes profundas.
from tensorflow.keras.applications import VGG16  # Importa a arquitetura VGG16, conhecida pela simplicidade e efic√°cia em tarefas de classifica√ß√£o de imagens.
from tensorflow.keras.applications import MobileNet  # Importa a arquitetura MobileNet, projetada para dispositivos m√≥veis e sistemas de baixa pot√™ncia.
from tensorflow.keras.applications import InceptionV3  # Importa a arquitetura InceptionV3, eficiente em tarefas complexas devido ao uso de m√≥dulos Inception.
from tensorflow.keras.applications import DenseNet121  # Importa a arquitetura DenseNet121, que utiliza conex√µes densas entre camadas para efici√™ncia e precis√£o.
from tensorflow.keras.applications import EfficientNetB0  # Importa a arquitetura EfficientNetB0, projetada para escalabilidade e desempenho em diversos tamanhos de redes.
from tensorflow.keras.applications import EfficientNetB3  # Importa a arquitetura EfficientNetB3, uma vers√£o mais avan√ßada e eficiente da fam√≠lia EfficientNet.
from tensorflow.keras.applications import Xception  # Importa a arquitetura Xception, baseada em convolu√ß√µes separ√°veis, ideal para tarefas que requerem efici√™ncia e alta precis√£o.
from tensorflow.keras import layers, backend as K, utils  # Camadas, backend e utilit√°rios do Keras.
from tensorflow.keras.models import Model, load_model  # Para definir modelos customizados.
from tensorflow.keras.metrics import categorical_crossentropy  # Para c√°lculo de perda categ√≥rica cruzada.
from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Para gerar e transformar imagens em tempo real.
from tensorflow.keras.layers import Flatten, Dense, Activation, GlobalAveragePooling2D, Dropout, BatchNormalization  # Camadas para modelos.
from tensorflow.keras.optimizers import RMSprop  # Otimizador RMSprop.
from tensorflow.keras.optimizers import Adam # Importando o otimizador Adam
from tensorflow.keras.callbacks import Callback, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau  # Callbacks para treinamento.
from tensorflow.keras.applications import ResNet50, MobileNet, VGG16  # Modelos de redes neurais pr√©-treinados.
from tensorflow.keras.utils import plot_model  # Para gerar uma visualiza√ß√£o gr√°fica da arquitetura do modelo treinado.
from tqdm import tqdm # Importa o m√≥dulo tqdm para exibir barras de progresso no terminal
#from tensorflow.keras.callbacks import TQDMProgressBar # Importa a classe TQDMProgressBar do Keras para integrar uma barra de progresso com o treinamento do modelo

# ============================
# Ferramentas de Aprendizado de M√°quina do Scikit-learn
# ============================
from sklearn.preprocessing import LabelBinarizer  # Para binarizar as classes no formato one-hot.
from sklearn.metrics import precision_recall_curve, roc_curve, auc  # M√©tricas de avalia√ß√£o de desempenho.
from sklearn.metrics import confusion_matrix, roc_curve, auc  # Para avalia√ß√£o do modelo de classifica√ß√£o.
from sklearn import metrics  # Importa o m√≥dulo metrics para usar fun√ß√µes como classification_report
#import shap  # Fun√ß√£o de import√¢ncia das features usando SHAP.

# ============================
# Configura√ß√£o de Precis√£o Mista
# ============================
policy = tf.keras.mixed_precision.Policy('mixed_float16')  # Usa FP16 para c√°lculos e FP32 para vari√°veis
tf.keras.mixed_precision.set_global_policy(policy)  # Configura a pol√≠tica global de precis√£o mista

# Verificar se a pol√≠tica foi aplicada corretamente
print(f"Policy set to: {tf.keras.mixed_precision.global_policy()}")

# ============================
# Montar o Google Drive
# ============================
#from google.colab import drive
#drive.mount('/content/drive')

# ============================
# Fun√ß√µes Utilit√°rias e Importa√ß√µes
# ============================
# Verifica a presen√ßa do arquivo 'utils.py' e tenta importar fun√ß√µes
#utils_path = '/content/drive/MyDrive/Colab Notebooks/PeneiraDataSetJPG4Partes/utils.py'
#if os.path.exists(utils_path):
#    print("O arquivo 'utils.py' foi encontrado.")
#    !cat utils_path  # Exibe o conte√∫do do arquivo 'utils.py' para verifica√ß√£o.
#    try:
#       from utils import *  # Importa todas as fun√ß√µes utilit√°rias.
#        print("Fun√ß√µes importadas com sucesso!")
#    except ImportError as e:
#        print(f"Erro ao importar as fun√ß√µes do arquivo 'utils.py': {e}")
#else:
#    print("O arquivo 'utils.py' n√£o foi encontrado no diret√≥rio especificado.")

""" Verifica informa√ß√µes da GPU dispon√≠vel, como nome, uso de mem√≥ria e utiliza√ß√£o atual"""

!nvidia-smi

# Verifica se h√° GPUs dispon√≠veis para o TensorFlow e exibe a lista de dispositivos detectados
import tensorflow as tf
print("GPUs detectadas:", tf.config.list_physical_devices('GPU'))

import tensorflow as tf  # Importa o TensorFlow

# Lista as GPUs dispon√≠veis
gpus = tf.config.list_physical_devices('GPU')

# Verifica se h√° alguma GPU dispon√≠vel
if gpus:
    try:
        # Para cada GPU dispon√≠vel, define o crescimento de mem√≥ria como True
        # Isso faz com que o TensorFlow aloque mem√≥ria conforme necess√°rio,
        # em vez de ocupar toda a mem√≥ria da GPU de uma vez
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print("Configura√ß√£o de mem√≥ria ajustada para GPU.")
    except RuntimeError as e:
        # Caso ocorra erro (por exemplo, a GPU j√° foi inicializada), exibe o erro
        print(e)

# Verifica se uma GPU est√° dispon√≠vel para o TensorFlow
print("TensorFlow est√° utilizando GPU?", tf.test.is_gpu_available())

# Exibe o nome do dispositivo GPU em uso, se houver
print("Dispositivo padr√£o:", tf.test.gpu_device_name())

"""// ------ PROGRAMA TERCEIRA VERS√ÉO / FUN√á√ïES SIMPLIFICADAS ------ //"""

# Data da cria√ß√£o 07/04 - OUTROS PAR√ÇMETROS

# MODELO USANDO VGG16, RESNET50,  MOBILENET, EFFICIENTENETB3, INCEPTIONV3, DENSENET121 E XCEPTION AO MESMO TEMPO - USANDO PESOS ADICIONADOS AO TREINAMENTO

# =============================================================================#
# √ÅREA DE IMPORTA√á√ÉO DAS BIBLIOTECAS PARA O TREINAMENTO
# =============================================================================#

# ==================================
# Configura√ß√£o do Diret√≥rio de Dados
# ==================================

# Monitore o uso de mem√≥ria durante a execu√ß√£o
!free -h

# Importar o m√≥dulo os
import os  # ‚úÖ Adicione esta linha

# Vari√°veis globais
dataDir = '/content/drive/MyDrive/Colab Notebooks/PeneiraDataSetJPG4Partes/'
roi_path = '/content/drive/MyDrive/Colab Notebooks/PeneiraDataSetJPG4Partes/roi_selecionada.jpg'
augmented_images_data = {}
actual_vs_predicted_data = {}

# Verificar se o diret√≥rio existe
if not os.path.exists(dataDir):
    print(f"‚ùå O diret√≥rio {dataDir} n√£o existe!")
else:
    print(f"‚úÖ O diret√≥rio {dataDir} existe.")
    # Listar conte√∫do do diret√≥rio
    print("Conte√∫do do diret√≥rio:")
    print(os.listdir(dataDir))

    # Encontrar todas as imagens no diret√≥rio e subdiret√≥rios
    def find_images_in_directory(directory):
        image_files = []
        for root, _, files in os.walk(directory):
            for file in files:
                if file.lower().endswith(('.jpg', '.jpeg', '.png')):
                    image_files.append(os.path.join(root, file))
        return image_files

    image_files = find_images_in_directory(dataDir)

    if not image_files:
        raise ValueError("‚ùå O diret√≥rio de dados est√° vazio ou n√£o cont√©m imagens v√°lidas!")
    else:
        print(f"‚úÖ Diret√≥rio verificado: {dataDir} cont√©m {len(image_files)} imagens.")

# ============================
# Verifica√ß√£o e Importa√ß√£o do utils.py
# ============================

import sys  # Permite manipular o sistema e modificar caminhos de importa√ß√£o
from pathlib import Path  # Fornece uma forma orientada a objetos para manipular caminhos de arquivos

# Acessa o diret√≥rio onde as imagens est√£o armazenadas
sys.path.append('/content/drive/MyDrive/Colab Notebooks/PeneiraDataSetJPG4Partes')

# Caminho do arquivo utils.py
#utils_path = "/content/drive/MyDrive/Colab Notebooks/PeneiraDataSetJPG4Partes/utils.py"

# Verifica se o arquivo 'utils.py' existe antes de tentar importar
#if os.path.exists(utils_path):
#    print("‚úÖ O arquivo 'utils.py' foi encontrado. Importando fun√ß√µes...")

    # Adiciona o caminho do diret√≥rio para garantir que utils.py pode ser importado
#    import sys
#    sys.path.append('/content/drive/MyDrive/Colab Notebooks/PeneiraDataSetJPG4Partes/')

    # Tenta importar as fun√ß√µes de utils.py
#    try:
#        from utils import (
#            build_vgg_model, build_resnet_model, build_mobilenet_model, build_efficientnet_model,
#            build_inception_model, build_densenet_model, build_xception_model
#        )
#        print("‚úÖ Fun√ß√µes de modelos importadas com sucesso!")
#    except ImportError as e:
#        print(f"‚ùå Erro ao importar as fun√ß√µes do arquivo 'utils.py': {e}")
#        raise
#else:
#    print("‚ùå O arquivo 'utils.py' n√£o foi encontrado. Verifique o caminho e tente novamente.")
#    raise FileNotFoundError("Arquivo utils.py n√£o encontrado!")

# ============================
# Visualiza√ß√£o Interativa
# ============================
# Biblioteca para criar gr√°ficos interativos.
import plotly.graph_objects as go  # Ferramenta para criar gr√°ficos interativos avan√ßados.
import ipywidgets as widgets  # Importa a biblioteca ipywidgets, que permite criar widgets interativos em Jupyter Notebooks ou Google Colab.
from ipywidgets import interact, FloatSlider, IntSlider, ToggleButtons, Button, VBox, HBox, Label, Output, Dropdown  # Cria widgets interativos para ajustar par√¢metros no Jupyter Notebook

# Configura√ß√£o extra para interatividade no Colab
from IPython.display import display, clear_output, HTML
#display(plt.gcf())  # Garante que o gr√°fico seja exibido corretamente no ambiente do Colab

# Adicionar estilo CSS
display(HTML("""
<style>
.automatico-on .widget-toggle-button { background-color: #28a745 !important; }
.automatico-off .widget-toggle-button { background-color: #dc3545 !important; }
</style>
"""))


# Carregar e dividir o dataset
import os # Importa a biblioteca para interagir com o sistema de arquivos
import pandas as pd # Importa o pandas, que ajuda a trabalhar com dados em tabelas
from sklearn.model_selection import train_test_split # Importa a fun√ß√£o para dividir os dados em treino e teste
from sklearn.datasets import load_iris # Importa o conjunto de dados Iris, usado para exemplos de classifica√ß√£o
from sklearn.ensemble import RandomForestClassifier # Importa o classificador RandomForest, que √© usado para classifica√ß√£o de dados

# ============================
# Instala√ß√£o de Depend√™ncias (se necess√°rio)
# ============================
# Instala√ß√£o de bibliotecas adicionais diretamente no ambiente.
!pip install plotly  # Para gr√°ficos interativos.
!pip install scikit-learn  # Para ferramentas de aprendizado de m√°quina.
!pip install seaborn  # Para gr√°ficos estat√≠sticos.
!pip install tensorflow  # Para deep learning.
!pip install utils  # Caso necess√°rio, para instalar utils do PyPI.
!pip install ipympl  # Instala a biblioteca ipympl para permitir interatividade com gr√°ficos do Matplotlib em notebooks Jupyter
!pip install --upgrade jupyter matplotlib ipympl  # Atualiza Jupyter, Matplotlib e ipympl para a vers√£o mais recente

#!pip uninstall -y numpy opencv-python opencv-python-headless # Desinstalar pacotes conflitantes
!pip install --upgrade tensorflow opencv-python-headless
#!pip install --no-cache-dir numpy==1.23.5 # Reinstalar a vers√£o correta do NumPy
!pip install --no-cache-dir opencv-python-headless # Reinstalar OpenCV sem conflitos
!pip install --upgrade numba pynndescent umap-learn # Atualiza as bibliotecas para as vers√µes mais recentes
!pip uninstall numba pynndescent umap-learn -y # Desinstala as bibliotecas atuais sem pedir confirma√ß√£o
!pip install numba pynndescent umap-learn # Reinstala as bibliotecas para garantir depend√™ncias corretas
!pip install numba==0.56.4 # Instala a vers√£o 0.56.4 do numba para compatibilidade
!pip install umap-learn==0.5.3 # Instala a vers√£o 0.5.3 do umap-learn para redu√ß√£o de dimensionalidade

#Essa classe √© amplamente utilizada para realizar preprocessamento e augmenta√ß√£o de dados de imagens durante o treinamento de modelos de aprendizado profundo.
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import tensorflow as tf
print(tf.__version__)

!pip install tensorflow --upgrade # Atualiza o TensorFlow para a vers√£o mais recente

# Verificar conflitos de depend√™ncias
#!pip check

# ============================
# Carregar o Dataset
# ============================
from google.colab import drive
drive.mount('/content/drive', force_remount=True)  # For√ßa remount para evitar cache

# ============================
# Fun√ß√µes Utilit√°rias e Importa√ß√µes de Biblioteca
# ============================
# Lista os arquivos do diret√≥rio onde as imagens est√£o armazenadas
#!ls '/content/drive/MyDrive/Colab Notebooks/PeneiraDataSetJPG4Partes'
#!ls -l '/content/drive/MyDrive/Colab/ Notebooks/PeneiraDataSetJPG4Partes/train_data'
#!ls -l '/content/drive/MyDrive/Colab/ Notebooks/PeneiraDataSetJPG4Partes/valid_data'

# Remover os comandos !ls e substituir por verifica√ß√µes em Python
print("\nüîç Verificando o diret√≥rio de dados:")
data_dir_path = '/content/drive/MyDrive/Colab Notebooks/PeneiraDataSetJPG4Partes'
if os.path.exists(data_dir_path):
    print(f"‚úÖ Diret√≥rio encontrado: {data_dir_path}")
    print(f"Conte√∫do: {os.listdir(data_dir_path)}")
else:
    print(f"‚ùå Diret√≥rio n√£o encontrado: {data_dir_path}")

# Verifica se os diret√≥rios de treino/valida√ß√£o/teste existem e est√£o populados
print("\nüîç Verificando diret√≥rios de dados:")
for dir_name in ['train_data', 'valid_data', 'test_data']:
    dir_path = os.path.join(dataDir, dir_name)
    print(f"\n--- {dir_name} ---")
    if os.path.exists(dir_path):
        files = os.listdir(dir_path)
        num_files = len(files)
        print(f"Conte√∫do: {files}")
        print(f"Total de arquivos: {num_files}")
    else:
        print(f"Diret√≥rio {dir_name} n√£o encontrado!")
        # Cria diret√≥rios se n√£o existirem (opcional)
        # os.makedirs(dir_path, exist_ok=True)

# Verifica se os diret√≥rios de treino/valida√ß√£o/teste existem e est√£o populados
#print("\nüîç Verificando diret√≥rios de dados:")
#for dir_name in ['train_data', 'valid_data', 'test_data']:
#    dir_path = os.path.join(dataDir, dir_name)
#    print(f"\n--- {dir_name} ---")
#    if os.path.exists(dir_path):
#        !ls -l {dir_path}
#        num_files = len(os.listdir(dir_path))
#        print(f"Total de arquivos: {num_files}")
#    else:
#        print(f"Diret√≥rio {dir_name} n√£o encontrado!")
        # Cria diret√≥rios se n√£o existirem (opcional)
        # os.makedirs(dir_path, exist_ok=True)

# Verifica se o arquivo 'utils.py' est√° presente
#if os.path.exists(utils_path):
#    print("O arquivo 'utils.py' foi encontrado.")
    # Exibe o conte√∫do do arquivo para garantir que as fun√ß√µes est√£o presentes
#    !cat utils_path
    # Agora tenta importar as fun√ß√µes do m√≥dulo 'utils.py'
#    try:
#        from utils import get_sample_image_path_from_original
#        from utils import load_and_split_dataset
#        from utils import augment_data
#        from utils import build_vgg_model
#        from utils import build_resnet_model
#        from utils import build_mobilenet_model
#        from utils import build_efficientnet_model
#        from utils import build_inception_model
#        from utils import build_densenet_model
#        from utils import build_xception_model
#        from utils import compile_model
#        from utils import train_and_evaluate_model
#        from utils import compare_models
#        from utils import plot_advanced_analysis
#        print("Fun√ß√µes importadas com sucesso!")
#    except ImportError as e:
#        print(f"Erro ao importar as fun√ß√µes do arquivo 'utils.py': {e}")
#else:
#    print("O arquivo 'utils.py' n√£o foi encontrado no diret√≥rio especificado.")

# ============================
# Bibliotecas Padr√£o
# ============================
# Bibliotecas b√°sicas para manipula√ß√£o de arquivos e opera√ß√µes relacionadas ao tempo.
import os  # Para manipula√ß√£o de diret√≥rios e caminhos.
import time  # Para medir tempos de execu√ß√£o e c√°lculos de delays.
import random  # Para gera√ß√£o de valores aleat√≥rios.
import logging # Logs Adicionais
import csv # Fun√ß√£o para salvar os resultados de treinamento em um arquivo CSV
import tempfile  # Importa a biblioteca tempfile, que permite criar arquivos e diret√≥rios tempor√°rios automaticamente gerenciados pelo sistema.

# Adicione o import do shutil no in√≠cio do script
import shutil  # ‚úÖ Adicione esta linha

# ============================
# Manipula√ß√£o de Imagens e Visualiza√ß√£o
# ============================
# Bibliotecas usadas para processar imagens e criar visualiza√ß√µes.
#import cv2  # Biblioteca OpenCV para manipula√ß√£o e processamento de imagens.
import numpy as np  # Biblioteca para opera√ß√µes matem√°ticas e manipula√ß√£o de arrays.
from PIL import Image  # Biblioteca Pillow para manipula√ß√£o avan√ßada de imagens.
import matplotlib.pyplot as plt  # Biblioteca para cria√ß√£o de gr√°ficos e visualiza√ß√µes.
import seaborn as sns  # Biblioteca para gr√°ficos estat√≠sticos e estiliza√ß√£o.
from collections import Counter  # Importa Counter para contar elementos iter√°veis de forma eficiente
from matplotlib.widgets import RectangleSelector  # Ferramenta para sele√ß√£o interativa de regi√µes em imagens

# ============================
# Manipula√ß√£o de Dados
# ============================
# Bibliotecas para leitura, manipula√ß√£o e an√°lise de dados.
import pandas as pd  # Biblioteca para an√°lise e manipula√ß√£o de dados tabulares.

# ============================
# Bibliotecas de Aprendizado de M√°quina
# ============================
# Ferramentas para dividir dados, avaliar modelos e realizar an√°lises estat√≠sticas.
from sklearn.utils import class_weight  # Importa a fun√ß√£o class_weight do Scikit-Learn, usada para calcular pesos das classes em conjuntos de dados desbalanceados.
from sklearn.model_selection import train_test_split, StratifiedKFold  # Para divis√£o de dados e valida√ß√£o cruzada.
from sklearn.preprocessing import label_binarize, LabelBinarizer  # Para binariza√ß√£o de r√≥tulos (transforma√ß√£o de classes).
from sklearn.metrics import (
    confusion_matrix,  # Para calcular matrizes de confus√£o.
    classification_report,  # Para relat√≥rios detalhados de classifica√ß√£o.
    f1_score,  # Para calcular o F1 Score.
    precision_recall_curve,  # Para curvas de precis√£o-recall.
    average_precision_score,  # Para c√°lculo de m√©dia de precis√£o.
    roc_curve,  # Para curvas ROC.
    auc,  # Para calcular a √°rea sob a curva ROC.
    ConfusionMatrixDisplay  # Para exibir matrizes de confus√£o.
)
from sklearn.calibration import calibration_curve  # Para Gr√°fico de Calibra√ß√£o
from sklearn.decomposition import PCA  # Para an√°lise de componentes principais (redu√ß√£o de dimensionalidade).
from sklearn.manifold import TSNE  # Para visualiza√ß√£o de dados em dimens√µes reduzidas (e.g., t-SNE).

# ============================
# Bibliotecas de TensorFlow e Keras
# ============================
# Ferramentas para constru√ß√£o, treinamento e avalia√ß√£o de modelos de deep learning.
tf.config.run_functions_eagerly(True) # Habilitar execu√ß√£o eager
import tensorflow as tf  # Biblioteca principal de aprendizado de m√°quina.
from tensorflow import keras  # Interface de alto n√≠vel para TensorFlow.
from tensorflow.keras import layers, backend as K, utils  # Camadas, backend e utilit√°rios do Keras.
from tensorflow.keras.models import Model  # Para definir modelos customizados.
from tensorflow.keras.metrics import categorical_crossentropy  # Para c√°lculo de perda categ√≥rica cruzada.
from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Para gerar e transformar imagens em tempo real.
from tensorflow.keras.layers import Flatten, Dense, Activation, GlobalAveragePooling2D, Dropout  # Camadas para modelos.
from tensorflow.keras.optimizers import Adam, SGD, RMSprop  # Importa os otimizadores Adam, SGD e RMSprop. O Adam combina os benef√≠cios de outros otimizadores, como o RMSprop, para ajustes din√¢micos da taxa de aprendizado. O SGD √© o m√©todo de Gradiente Estoc√°stico, onde a atualiza√ß√£o dos pesos √© feita com base em uma amostra aleat√≥ria dos dados. O RMSprop ajusta a taxa de aprendizado para cada par√¢metro, sendo √∫til em casos de grande varia√ß√£o nos gradientes.
from tensorflow.keras.callbacks import Callback, EarlyStopping, LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau, Callback  # Callbacks para treinamento.
from tensorflow.keras import models, optimizers # Este m√≥dulo √© respons√°vel por definir, treinar e salvar modelos
from tensorflow.keras.utils import to_categorical  # Converte r√≥tulos em formato one-hot encoding para classifica√ß√£o multiclasse
from tensorflow.keras.layers import BatchNormalization  # Normaliza a ativa√ß√£o das camadas para acelerar e estabilizar o treinamento
from tensorflow.keras.callbacks import ModelCheckpoint  # Salva automaticamente o modelo durante o treinamento quando h√° melhoria
from tensorflow.keras import activations  # Importa o m√≥dulo de fun√ß√µes de ativa√ß√£o do Keras. As fun√ß√µes de ativa√ß√£o s√£o respons√°veis por introduzir n√£o linearidade no modelo, permitindo que a rede aprenda padr√µes complexos. Exemplos incluem 'relu', 'sigmoid', 'softmax', entre outras.

# - 'ResNet50', 'MobileNet', e 'VGG16' s√£o arquiteturas de redes neurais profundas frequentemente usadas para tarefas de vis√£o computacional.
from tensorflow.keras.applications import ResNet50, MobileNet, MobileNetV2, VGG16, EfficientNetB0, EfficientNetB3, InceptionV3, DenseNet121, Xception # Importar os modelos
import matplotlib.pyplot as plt # Importa a biblioteca matplotlib.pyplot, que fornece fun√ß√µes para cria√ß√£o de gr√°ficos e visualiza√ß√µes.

#  Definir o dicion√°rio de arquiteturas
ARCHITECTURES = {
    "VGG16": VGG16,
    "ResNet50": ResNet50,
    "MobileNet": MobileNet,
    "EfficientNetB0": EfficientNetB0,
    "InceptionV3": InceptionV3,
    "DenseNet121": DenseNet121,
    "Xception": Xception
}

# Mapeamento de fun√ß√µes de ativa√ß√£o
ACTIVATION_FUNCTIONS = {
    'ReLU': activations.relu,
    'Leaky ReLU': activations.relu,  # Ajuste se necess√°rio
    'Sigmoid': activations.sigmoid,
    'Softmax': activations.softmax,
}

# Ferramentas de aprendizado de m√°quina do scikit-learn:
# - 'precision_recall_curve' e 'roc_curve' s√£o usados para an√°lise de desempenho de modelos de classifica√ß√£o.
# - 'auc' calcula a √°rea sob a curva (AUC) para curvas ROC.
from sklearn.metrics import precision_recall_curve, roc_curve, auc  # M√©tricas de avalia√ß√£o do scikit-learn.


# =============================================================================
# VERIFICA SE H√Å GPU DISPON√çVEL
# =============================================================================

# Verifica se h√° GPU dispon√≠vel antes de definir a pol√≠tica de precis√£o
if len(tf.config.list_physical_devices('GPU')) > 0:
    print("‚úÖ GPU detectada. Usando precis√£o mista (mixed_float16).")
    tf.keras.mixed_precision.set_global_policy('mixed_float16')
else:
    print("‚ö†Ô∏è GPU n√£o detectada. Usando precis√£o padr√£o (float32).")

# Configura√ß√£o do uso de precis√£o mista
#policy = tf.keras.mixed_precision.Policy('mixed_float16')  # Usa FP16 para c√°lculos e FP32 para vari√°veis
#tf.keras.mixed_precision.set_global_policy(policy)
# Verificar se a pol√≠tica foi aplicada corretamente
#print(f"Policy set to: {tf.keras.mixed_precision.global_policy()}")


# =============================================================================#
# √ÅREA DE CONFIGURA√á√ÉO DE FUN√á√ïES AUXILIARES E CARREGAR AS IMAGENS
# =============================================================================#

# ============================
# Definir os diret√≥rios das imagens
# ============================
dataDir = '/content/drive/MyDrive/Colab Notebooks/PeneiraDataSetJPG4Partes/'

# ============================
# Definir os diret√≥rios do conjunto de dados em formato RGB
# ============================

import cv2  # Importa a biblioteca OpenCV para manipula√ß√£o de imagens
# Carrega uma imagem de exemplo do seu conjunto de dados em formato RGB
roi_path = '/content/drive/MyDrive/Colab Notebooks/PeneiraDataSetJPG4Partes/roi_selecionada.jpg'
image = cv2.imread(roi_path)  # Carrega a imagem (o OpenCV carrega como BGR por padr√£o)
if image is None:
    raise ValueError(f"Imagem n√£o encontrada em {roi_path}! Verifique o caminho.")

# Converte de BGR (padr√£o do OpenCV) para RGB
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
print(f"Imagem carregada com sucesso: {roi_path}")

# ============================
# √Årea de Tratamento do Dataset
# ============================

# Fun√ß√£o para criar DataFrame a partir dos dados filtrados
def create_dataframe_from_filtered_data(filtered_data):
    """
    Cria um DataFrame com caminhos e r√≥tulos a partir da lista filtrada.
    Args:
        filtered_data: Lista de caminhos de arquivos filtrados.
    Returns:
        pd.DataFrame: DataFrame com colunas 'filepaths' e 'labels'.
    """
    data = []
    for file_path in filtered_data:
        label = os.path.basename(os.path.dirname(file_path))  # Extrai o r√≥tulo do diret√≥rio
        data.append({"filepaths": file_path, "labels": label})
    return pd.DataFrame(data)

# Fun√ß√£o para verificar a distribui√ß√£o das classes
def check_class_distribution(dataDir):
    class_counts = Counter()
    for root, dirs, files in os.walk(dataDir):
        # Ignora diret√≥rios de split e __pycache__
        dirs[:] = [d for d in dirs if d not in ['train_data', 'valid_data', 'test_data', '__pycache__']]
        for dir_name in dirs:
            class_path = os.path.join(root, dir_name)
            if os.path.isdir(class_path):
                num_samples = len([f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
                class_counts[dir_name] = num_samples
    return class_counts

# Fun√ß√£o para filtrar o dataset
def filter_dataset(dataDir, valid_classes):
    filtered_data = []
    for root, dirs, files in os.walk(dataDir):
        # Ignora diret√≥rios de split e __pycache__
        dirs[:] = [d for d in dirs if d not in ['train_data', 'valid_data', 'test_data', '__pycache__']]
        for dir_name in dirs:
            if dir_name in valid_classes:
                class_path = os.path.join(root, dir_name)
                filtered_data.extend([os.path.join(class_path, f) for f in os.listdir(class_path)
                                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))])  # Filtra apenas imagens
    return filtered_data

# Verificar a distribui√ß√£o das classes
class_distribution = check_class_distribution(dataDir)
print("Distribui√ß√£o das classes:")
print(class_distribution)

# Remover classes com menos de 2 exemplos
min_samples = 2
valid_classes = [cls for cls, count in class_distribution.items() if count >= min_samples]

# ‚úÖ **# Debug: Verifica quais classes foram mantidas ‚Üì**
print(f"Classes v√°lidas: {valid_classes}")  # Debug: Verifica quais classes foram mantidas

# Verifica se h√° classes suficientes para divis√£o estratificada
if len(valid_classes) < 2:
    raise ValueError("‚ö†Ô∏è Menos de 2 classes v√°lidas ap√≥s filtragem. A divis√£o estratificada n√£o √© poss√≠vel.")
# ‚úÖ **FIM DA INSER√á√ÉO**

filtered_data = filter_dataset(dataDir, valid_classes)
print(f"N√∫mero de exemplos ap√≥s filtragem: {len(filtered_data)}")

# Converter filtered_data em DataFrame
#df = create_dataframe_from_filtered_data(filtered_data)

# Divis√£o estratificada
#train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df['labels'], random_state=42)
#valid_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['labels'], random_state=42)

#print(f"Treino: {len(train_df)} exemplos")
#print(f"Valida√ß√£o: {len(valid_df)} exemplos")
#print(f"Teste: {len(test_df)} exemplos")

# Exibir resumo do dataset carregado
#print(f"üìä Conjunto de Treinamento: {len(train_df)} imagens")
#print(f"üìä Conjunto de Valida√ß√£o: {len(valid_df)} imagens")
#print(f"üìä Conjunto de Teste: {len(test_df)} imagens")

# Verificar o uso de mem√≥ria (executar como uma c√©lula separada no Colab)
print("\nüñ•Ô∏è Verificando uso de mem√≥ria:")
get_ipython().system('free -h')


# =============================================================================#
# FUN√á√ïES PRINCIPAIS
# =============================================================================#

# Fun√ß√£o para selecionar uma imagem aleat√≥ria do diret√≥rio
def get_sample_image_path_from_original(dataDir):  # Define fun√ß√£o para selecionar imagem aleat√≥ria
    """
    Seleciona uma imagem aleat√≥ria de um diret√≥rio fornecido, incluindo subdiret√≥rios.

    Par√¢metros:
    - dataDir: Caminho para o diret√≥rio onde as imagens est√£o armazenadas.

    Retorna:
    - Caminho completo de uma imagem aleat√≥ria.

    Lan√ßa:
    - ValueError: Se nenhum arquivo de imagem for encontrado no diret√≥rio.
    """
    all_files = []  # Inicializa lista para todos os arquivos
    for root, dirs, files in os.walk(dataDir):  # Itera por diret√≥rios e subdiret√≥rios
        for file in files:  # Itera sobre arquivos em cada diret√≥rio
            all_files.append(os.path.join(root, file))  # Adiciona caminho completo √† lista

    image_files = [f for f in all_files if f.lower().endswith(('.jpg', '.jpeg', '.png'))]  # Filtra arquivos de imagem
    if not image_files:  # Verifica se h√° imagens
        raise ValueError("Nenhuma imagem foi encontrada no diret√≥rio especificado.")  # Lan√ßa erro se vazio

    return random.choice(image_files)  # Retorna caminho de imagem aleat√≥ria

# Fun√ß√£o para criar um DataFrame com caminhos e r√≥tulos
def create_dataframe_from_filtered_data(filtered_data):  # Define fun√ß√£o para criar DataFrame
    """
    Cria um DataFrame com caminhos e r√≥tulos a partir da lista filtrada.

    Args:
        filtered_data: Lista de caminhos de arquivos filtrados.

    Returns:
        pd.DataFrame: DataFrame com colunas 'filepaths' e 'labels'.
    """
    data = []  # Inicializa lista para armazenar dados
    for file_path in filtered_data:  # Itera sobre caminhos filtrados
        label = os.path.basename(os.path.dirname(file_path))  # Extrai r√≥tulo do nome do diret√≥rio pai
        data.append({"filepaths": file_path, "labels": label})  # Adiciona dicion√°rio com caminho e r√≥tulo
    return pd.DataFrame(data)  # Retorna DataFrame criado a partir da lista

# Fun√ß√£o para gerar a lista de neur√¥nios por camada
def generate_neurons_per_layer(num_layers, initial_neurons, decay_factor):  # Define fun√ß√£o para gerar lista de neur√¥nios
    """
    Gera uma lista de neur√¥nios por camada, onde o n√∫mero de neur√¥nios diminui progressivamente.

    Args:
        num_layers (int): N√∫mero total de camadas.
        initial_neurons (int): N√∫mero de neur√¥nios na primeira camada.
        decay_factor (float): Fator de decaimento (0 < decay_factor <= 1) para reduzir os neur√¥nios por camada.

    Returns:
        list: Lista de neur√¥nios por camada.
    """
    neurons_per_layer = []  # Inicializa lista para neur√¥nios por camada
    for i in range(num_layers):  # Itera pelo n√∫mero de camadas
        neurons = int(initial_neurons * (decay_factor ** i))  # Calcula neur√¥nios com decaimento
        # Garante que o n√∫mero de neur√¥nios n√£o seja inferior a 1
        neurons = max(neurons, 1)  # Define m√≠nimo de 1 neur√¥nio
        neurons_per_layer.append(neurons)  # Adiciona n√∫mero √† lista
    return neurons_per_layer  # Retorna lista de neur√¥nios

# Fun√ß√£o para carregar e dividir o dataset
def load_and_split_dataset(dataDir):  # Define fun√ß√£o para carregar e dividir dataset
    """
    Carrega as imagens, divide em treino/valida√ß√£o/teste (80-10-10) e organiza em diret√≥rios separados.

    Args:
        dataDir (str): Caminho para o diret√≥rio que cont√©m as pastas com as imagens.

    Returns:
        Tuple: DataFrames de treino, valida√ß√£o e teste.
    """
    print("Coletando caminhos das imagens...")  # Exibe mensagem de in√≠cio
    filepaths = []  # Lista para caminhos das imagens
    labels = []  # Lista para r√≥tulos das imagens
    valid_folders = ['Parte1', 'Parte2', 'Parte3', 'Parte4']  # Define pastas v√°lidas
    for fold in os.listdir(dataDir):  # Itera sobre itens no diret√≥rio
        if fold in valid_folders:  # Verifica se pasta √© v√°lida
            fold_path = os.path.join(dataDir, fold)  # Define caminho da pasta
            if os.path.isdir(fold_path):  # Confirma que √© um diret√≥rio
                print(f"Processando pasta: {fold}")  # Exibe pasta sendo processada
                for file in os.listdir(fold_path):  # Itera sobre arquivos na pasta
                    if file.lower().endswith(('.jpg', '.jpeg', '.png')):  # Filtra por extens√µes de imagem
                        filepaths.append(os.path.join(fold_path, file))  # Adiciona caminho √† lista
                        labels.append(fold)  # Adiciona r√≥tulo √† lista
    print(f"Total de imagens coletadas: {len(filepaths)}")  # Exibe total de imagens coletadas

    train_dir = os.path.join(dataDir, 'train_data')  # Define diret√≥rio de treino
    valid_dir = os.path.join(dataDir, 'valid_data')  # Define diret√≥rio de valida√ß√£o
    test_dir = os.path.join(dataDir, 'test_data')  # Define diret√≥rio de teste
    os.makedirs(train_dir, exist_ok=True)  # Cria diret√≥rio de treino, se necess√°rio
    os.makedirs(valid_dir, exist_ok=True)  # Cria diret√≥rio de valida√ß√£o, se necess√°rio
    os.makedirs(test_dir, exist_ok=True)  # Cria diret√≥rio de teste, se necess√°rio

    df = pd.DataFrame({'filepaths': filepaths, 'labels': labels})  # Cria DataFrame com caminhos e r√≥tulos
    train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df['labels'], random_state=42)  # Divide em treino (80%) e temp (20%)
    valid_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['labels'], random_state=42)  # Divide temp em valida√ß√£o (10%) e teste (10%)

    def copy_images(df, target_dir):  # Fun√ß√£o para copiar imagens ao diret√≥rio
        new_filepaths = []  # Lista para novos caminhos
        for _, row in df.iterrows():  # Itera sobre linhas do DataFrame
            src = row['filepaths']  # Obt√©m caminho original
            dst_dir = os.path.join(target_dir, row['labels'])  # Define subdiret√≥rio por r√≥tulo
            os.makedirs(dst_dir, exist_ok=True)  # Cria subdiret√≥rio, se necess√°rio
            dst = os.path.join(dst_dir, os.path.basename(src))  # Define novo caminho da imagem
            shutil.copy(src, dst)  # Copia imagem para novo local
            new_filepaths.append(dst)  # Adiciona novo caminho √† lista
        return df.assign(filepaths=new_filepaths)  # Retorna DataFrame com caminhos atualizados

    train_df = copy_images(train_df, train_dir)  # Copia imagens de treino
    valid_df = copy_images(valid_df, valid_dir)  # Copia imagens de valida√ß√£o
    test_df = copy_images(test_df, test_dir)  # Copia imagens de teste

    return train_df, valid_df, test_df  # Retorna os tr√™s DataFrames


# =============================================================================#
# √ÅREA DE CONFIGURA√á√ÉO DE FUN√á√ïES AUXILIARES E CARREGAR AS IMAGENS
# =============================================================================#

# Function to collect some augmented images from the ROI crop
def collect_images(train_generator, model_name, roi_dir='roi_images', num_samples=5, roi_coords=None):
    from PIL import Image  # Imports PIL to load images manually if needed
    import numpy as np  # Imports numpy for array manipulation
    import os  # Imports os for checking file paths
    dataDir = '/content/drive/MyDrive/Colab Notebooks/PeneiraDataSetJPG4Partes/'  # Defines base directory where data is stored on Google Drive
    roi_path = os.path.join(dataDir, roi_dir)  # Concatenates base directory with ROI subdirectory to form the full path
    print(f"Checking images in the generator for model: {model_name}")  # Prints an initial message indicating that images are being checked for the specified model

    if not os.path.exists(roi_path) or not os.listdir(roi_path):  # Checks if the ROI directory exists and contains files
        print(f"üö´ Error: Directory {roi_path} not found or empty.")  # Prints error if directory does not exist or is empty
        return {model_name: []}  # Returns a dictionary with the model name and an empty list, indicating collection failure

    # Addition: Validate the type of train_generator (corrected)
    if not hasattr(train_generator, 'class_indices') or not callable(getattr(train_generator, '__iter__', None)):
        print(f"‚ùå Error: train_generator is not a valid iterator. Received type: {type(train_generator)}, Value: {train_generator}")
        return {model_name: []}

    if hasattr(train_generator, 'filepaths'):  # Checks if the generator has the 'filepaths' attribute (useful for generators like flow_from_dataframe)
        print(f"Example paths in generator: {train_generator.filepaths[:2]}")  # Prints the first two file paths for debugging

    collected_data = []  # Initializes an empty list to store collected data (images and their labels)
    expected_size = None  # Initializes the variable for the expected ROI size as None
    if roi_coords:  # Checks if ROI coordinates were provided as an argument
        expected_size = (roi_coords[2] - roi_coords[0], roi_coords[3] - roi_coords[1])  # Calculates the expected size (width, height) from coordinates (x_max - x_min, y_max - y_min)
        print(f"üìè Expected ROI size: {expected_size}")  # Prints the expected ROI size for debugging

    iterator = iter(train_generator)  # Creates an iterator from the training generator to fetch batches of data

    batch_data = next(iterator)  # Gets the next batch from the generator
    print(f"batch_data type: {type(batch_data)}")  # Prints the type of the variable (usually tuple)
    print(f"batch_data length: {len(batch_data)}")  # Prints how many items are in the batch (usually 2: images and labels)
    for i, item in enumerate(batch_data):
        print(f"Item {i}: type={type(item)}, value={item if isinstance(item, str) else item.shape if hasattr(item, 'shape') else item}")  # Prints type and shape of each item

    try:  # Starts a try block to catch exceptions during image collection
        while len(collected_data) < num_samples:  # Loop continues until the number of collected samples reaches the specified amount (5)
            batch_data = next(iterator)  # Gets the next batch of data from the generator using the iterator
            print(f"üîç Debug: batch_data contains {len(batch_data)} elements")  # Prints the number of elements in the batch for debugging
            print(f"üîç Batch_data content: {[type(x).__name__ + ': ' + (str(x.shape) if hasattr(x, 'shape') else str(x)[:50]) for x in batch_data]}")  # Prints type and shape/content of each element

            if len(batch_data) != 2 or not isinstance(batch_data[0], np.ndarray) or not isinstance(batch_data[1], np.ndarray):  # Checks if batch_data has 2 elements and both are arrays
                raise ValueError(f"Invalid batch_data format: expected 2 arrays (images, labels), got {len(batch_data)} elements with types {[(type(x).__name__, x.shape if hasattr(x, 'shape') else str(x)[:50]) for x in batch_data]}")  # Raises error with details

            images = batch_data[0]  # Extracts the first element as images
            labels = batch_data[1]  # Extracts the second element as labels
            if len(batch_data) > 2:  # Checks if there are extra elements beyond images and labels
                print(f"‚ö†Ô∏è Extra elements detected: {len(batch_data) - 2} ignored")  # Prints warning that extra elements will be ignored

            print(f"üîç Adjusted format: images={images.shape}, labels={labels.shape}")  # Prints formats after adjustments
            num_to_collect = min(num_samples - len(collected_data), len(images))  # Calculates how many images to collect from this batch
            class_labels = list(train_generator.class_indices.keys())  # Gets list of class names from the generator

            for i in range(num_to_collect):  # Iterates over the number of images to collect from this batch
                img_array = (images[i] * 255).astype(np.uint8) if images.max() <= 1 else images[i].astype(np.uint8)  # Converts to uint8, adjusting normalization if needed
                class_idx = np.argmax(labels[i])  # Gets the index of the most likely class from the one-hot encoded label
                class_name = class_labels[class_idx]  # Converts the index to the corresponding class name

                if expected_size and (img_array.shape[1], img_array.shape[0]) != expected_size:  # Checks if the image size matches the expected ROI size
                    print(f"‚ö†Ô∏è Image {len(collected_data) + i} has size {(img_array.shape[1], img_array.shape[0])}, expected {expected_size}")  # Prints warning if size does not match

                if len(collected_data) == 0:  # If this is the first collected image
                    print(f"Model: {model_name}, Cropped ROI image size: {img_array.shape}")  # Prints size of the first image for debugging

                collected_data.append((img_array, class_name))  # Adds tuple (image, class name) to the collected data list
    except Exception as e:  # Catches any exception during the process
        print(f"‚ö†Ô∏è Error collecting images from generator: {str(e)}")  # Prints error message with exception details
        return {model_name: []}  # Returns dictionary with empty list in case of error

    return {model_name: collected_data}  # Returns dictionary with model name as key and collected data list as value

# Function to collect actual and predicted images from the ROI crop (without displaying)
def collect_actual_vs_predicted(model, test_df, test_generator, model_name, roi_dir='roi_images', num_samples=5):  # Defines function to collect actual and predicted images; parameters: trained model, test DataFrame, test generator, model name, ROI directory, number of samples (default 5)
    from PIL import Image  # Imports PIL to load images manually if needed
    import numpy as np  # Imports numpy for array manipulation
    import os  # Imports os for checking file paths
    dataDir = '/content/drive/MyDrive/Colab Notebooks/PeneiraDataSetJPG4Partes/'  # Defines base directory where data is stored on Google Drive
    roi_path = os.path.join(dataDir, roi_dir)  # Concatenates base directory with ROI subdirectory to form the full path

    if not os.path.exists(roi_path) or not os.listdir(roi_path):  # Checks if the ROI directory exists and contains files
        print(f"üö´ Error: Directory {roi_path} not found or empty.")  # Prints error if directory does not exist or is empty
        return {model_name: []}  # Returns a dictionary with the model name and an empty list, indicating collection failure

    collected_data = []  # Initializes an empty list to store collected data (images, actual labels, predicted labels, confidence, and probabilities)

    try:  # Starts a try block to catch exceptions during image and prediction collection
        iterator = iter(test_generator)  # Creates an iterator from the test generator to fetch batches of data
        while len(collected_data) < num_samples:  # Loop continues until the number of collected samples reaches the specified amount (5)
            batch_data = next(iterator)  # Gets the next batch of data from the generator using the iterator
            print(f"üîç Debug: batch_data contains {len(batch_data)} elements")  # Prints the number of elements in the batch for debugging
            if len(batch_data) < 2:  # Checks if the batch has fewer than 2 elements (images and labels are required)
                raise ValueError(f"Unexpected format: batch_data has fewer than 2 elements ({len(batch_data)})")  # Raises error if format is insufficient

            # Detailed inspection of batch_data content
            print(f"üîç Batch_data content: {[type(x).__name__ + ': ' + (str(x.shape) if hasattr(x, 'shape') else str(x)[:50]) for x in batch_data]}")  # Prints type and shape/content of each element

            test_images = batch_data[0]  # Extracts the first element as images
            test_labels = batch_data[1]  # Extracts the second element as labels
            if len(batch_data) > 2:  # Checks if there are extra elements beyond images and labels
                print(f"‚ö†Ô∏è Extra elements detected: {len(batch_data) - 2} ignored")  # Prints warning that extra elements will be ignored

            # Checks if test_images is a string (path) and converts to array if valid
            if isinstance(test_images, str):  # If test_images is a string
                print(f"‚ö†Ô∏è test_images is a string ({test_images[:50]}), checking if valid path")  # Warning about conversion
                if os.path.isfile(test_images):  # Checks if it is a valid file path
                    test_images = np.array(Image.open(test_images))  # Loads image as array
                else:
                    raise ValueError(f"String 'test_images' is not a valid file path: {test_images}")  # Raises error if not a valid path
            elif not isinstance(test_images, np.ndarray):  # If not a string nor ndarray, error
                raise ValueError(f"Unexpected format for test_images: {type(test_images)}")  # Raises error

            # Checks if test_labels is a string or valid array
            if isinstance(test_labels, str):  # If test_labels is a raw string
                print(f"‚ö†Ô∏è test_labels is a string ({test_labels}), expected one-hot array")  # Warning about unexpected format
                class_labels = list(test_generator.class_indices.keys())  # Gets available classes
                test_labels = np.array([1 if cls == test_labels else 0 for cls in class_labels], dtype=np.float32)  # Converts to one-hot manually
                test_labels = test_labels[np.newaxis, :]  # Adds batch dimension (1, num_classes)
            elif not isinstance(test_labels, np.ndarray):  # If not a string nor ndarray, error
                raise ValueError(f"Unexpected format for test_labels: {type(test_labels)}")  # Raises error

            print(f"üîç Adjusted format: images={test_images.shape}, labels={test_labels.shape}")  # Prints formats after adjustments
            predictions = model.predict(test_images)  # Uses model to predict classes for batch images
            class_labels = list(test_generator.class_indices.keys())  # Gets list of class names from test generator
            num_to_collect = min(num_samples - len(collected_data), len(test_images))  # Calculates how many images to collect from this batch (minimum of remaining needed and batch size)

            for i in range(num_to_collect):  # Iterates over the number of images to collect from this batch
                img_array = (test_images[i] * 255).astype(np.uint8) if test_images.max() <= 1 else test_images[i].astype(np.uint8)  # Converts to uint8, adjusting normalization if needed
                actual_label = class_labels[np.argmax(test_labels[i])]  # Gets actual label by converting the highest probability index from one-hot to class name
                predicted_label = class_labels[np.argmax(predictions[i])]  # Gets predicted label by converting the highest probability index from prediction to class name
                confidence = np.max(predictions[i])  # Calculates prediction confidence as the maximum probability value
                prediction_probs = {class_labels[j]: predictions[i][j] for j in range(len(class_labels))}  # Creates dictionary with probabilities for each class for the current image

                if len(collected_data) == 0:  # If this is the first collected image
                    print(f"Model: {model_name}, Cropped ROI image size: {img_array.shape}")  # Prints size of the first image for debugging
                collected_data.append((img_array, actual_label, predicted_label, confidence, prediction_probs))  # Adds tuple (image, actual label, predicted label, confidence, probabilities) to collected data list
    except Exception as e:  # Catches any exception during the process
        print(f"‚ö†Ô∏è Error collecting images from generator: {str(e)}")  # Prints error message with exception details
        return {model_name: []}  # Returns dictionary with empty list in case of error

    return {model_name: collected_data}  # Returns dictionary with model name as key and collected data list as value

# Function to display collected images grouped by model
def display_collected_images(collected_data, save_dir=None, title="Collected Images"):  # Defines function with 3 parameters: collected_data (required), save_dir (optional, default None), and title (optional, default "Collected Images")
    import os  # Imports os module for directory and file manipulation
    import matplotlib.pyplot as plt  # Imports matplotlib.pyplot as plt for creating and displaying plots

    if save_dir and not os.path.exists(save_dir):  # Checks if save_dir is provided and the directory does not exist
        os.makedirs(save_dir)  # Creates the specified directory in save_dir if it does not exist

    for model_name, data in collected_data.items():  # Iterates over the collected_data dictionary, unpacking each key-value pair into model_name (model name) and data (list of data)
        print(f"\nüì∏ {title} for {model_name}:")  # Prints a console message with the customized title and model name, preceded by a camera emoji and a newline
        num_samples = len(data)  # Calculates the number of samples (images) in the data list for the current model

        if num_samples == 0:  # Checks if there are no samples in the data list
            print("‚ö†Ô∏è No images collected.")  # Prints a warning in the console if no images were collected
            continue  # Skips to the next iteration of the loop (next model), bypassing the rest of the code for this model

        print(f"üîç Data format: {len(data[0])} elements per sample")  # Prints the number of elements per sample in the console (e.g., 2 for augmented images, 5 for predictive images) for debugging

        if len(data[0]) == 2:  # Checks if each sample has 2 elements (format for augmented images: image and label)
            fig, axes = plt.subplots(1, min(num_samples, 5), figsize=(min(num_samples, 5) * 6, 8))  # Creates a figure with subplots in one row, limiting to 5 columns max, with width proportional to the number of images (6 per image) and fixed height of 8
            if num_samples == 1:  # Checks if there is only one sample
                axes = [axes]  # Converts the axes object (single subplot) to a list for consistent indexing

            for i, (img_array, label) in enumerate(data[:5]):  # Iterates over up to the first 5 samples, unpacking each tuple into index i, img_array (image array), and label
                axes[i].imshow(img_array)  # Displays the image in the corresponding subplot at index i
                axes[i].set_title(f"Label: {label}\nSize: {img_array.shape[1]}x{img_array.shape[0]}\nSample: {i+1}",  # Sets the subplot title with the label, image size (width x height), and sample number
                                  fontsize=12, color='darkblue', pad=5)  # Sets font size (12), color (dark blue), and top padding (5) for the title
                axes[i].axis('off')  # Removes axes (lines and labels) from the subplot for a cleaner visualization

            plt.suptitle(f"{title} - {model_name}", y=1.02, fontsize=16)  # Sets an overall title above the figure, combining the customized title and model name, with larger font (16) and slight vertical offset (y=1.02)
            plt.tight_layout(pad=1.0)  # Automatically adjusts spacing between subplots with a padding of 1.0 to avoid overlap
            if save_dir:  # Checks if a save directory was provided
                plt.savefig(os.path.join(save_dir, f"{model_name}_augmented.png"), dpi=300, bbox_inches='tight')  # Saves the figure in high resolution (300 DPI) in the specified directory, with a name based on the model and "_augmented" suffix
            plt.show()  # Displays the figure with all subplots on the screen

        elif len(data[0]) == 5:  # Checks if each sample has 5 elements (format for predictive images: image, actual label, predicted label, confidence, and probabilities)
            correct_count = sum(1 for _, actual, predicted, _, _ in data[:5] if actual == predicted)  # Calculates the number of correct predictions by comparing actual and predicted labels in the first 5 samples
            total = min(num_samples, 5)  # Sets the total number of samples to consider, limiting to 5
            accuracy_text = f"Accuracy Rate: {correct_count}/{total} ({correct_count/total*100:.1f}%)"  # Creates a string with the accuracy rate (e.g., "3/5 (60.0%)"), formatted with one decimal place
            for i, (img_array, actual, predicted, confidence, probs) in enumerate(data[:5]):  # Iterates over up to the first 5 samples, unpacking into index i, img_array, actual (true label), predicted (predicted label), confidence, and probs (probabilities)
                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))  # Creates a figure with 2 side-by-side subplots (1 row, 2 columns), with a fixed size of 8x4 inches
                ax1.imshow(img_array)  # Displays the image in the first subplot (left)
                ax1.set_title(f"Actual: {actual}\nSize: {img_array.shape[1]}x{img_array.shape[0]}",  # Sets the first subplot title with the actual label and image size
                              fontsize=10, color='green', pad=3)  # Sets smaller font (10), green color, and reduced top padding (3)
                ax1.axis('off')  # Removes axes from the first subplot

                ax2.imshow(img_array)  # Displays the same image in the second subplot (right)
                sorted_probs = sorted(probs.items(), key=lambda x: x[1], reverse=True)  # Sorts probabilities in descending order based on values (x[1])
                alt_label, alt_prob = sorted_probs[1] if len(sorted_probs) > 1 else ("N/A", 0.0)  # Gets the label and probability of the second highest prediction, or "N/A" and 0.0 if there is only one
                ax2.set_title(f"Predicted: {predicted}\nConfidence: {confidence:.2f}\nAlternative: {alt_label} ({alt_prob:.2f})",  # Sets the second subplot title with predicted label, confidence (2 decimal places), and alternative
                              fontsize=10, color='purple', pad=3)  # Sets smaller font (10), purple color, and reduced top padding (3)
                border_color = 'green' if actual == predicted else 'red'  # Sets border color to green if prediction is correct, or red if incorrect
                for spine in ax2.spines.values():  # Iterates over the spines (borders) of the second subplot
                    spine.set_edgecolor(border_color)  # Applies the defined color (green or red) to the borders
                    spine.set_linewidth(2)  # Sets border thickness to 2 pixels
                ax2.axis('off')  # Removes axes from the second subplot

                plt.suptitle(f"{title} - {model_name} (Sample {i+1})\n{accuracy_text}", y=1.1, fontsize=12)  # Sets an overall title with the customized title, model name, sample number, and accuracy rate, with medium font (12) and vertical offset (y=1.1)
                plt.tight_layout(pad=0.5)  # Adjusts spacing between subplots with a reduced padding of 0.5
                if save_dir:  # Checks if a save directory was provided
                    plt.savefig(os.path.join(save_dir, f"{model_name}_predicted_{i+1}.png"), dpi=300, bbox_inches='tight')  # Saves the figure in high resolution (300 DPI) with a name based on the model, "_predicted" suffix, and sample number
                plt.show()  # Displays the figure with both subplots on the screen

        else:  # If the number of elements per sample is neither 2 nor 5
            print(f"‚ö†Ô∏è Unexpected data format for {model_name}: {len(data[0])} elements")  # Prints a warning in the console with the model name and number of elements found per sample


# =============================================================================#
# √ÅREA DE TRATAMENTO DA ROI
# =============================================================================#

# Fun√ß√£o para aplicar o recorte da ROI a uma imagem
def apply_roi(image, roi_coords):
    """
    Aplica o recorte da ROI a uma imagem.
    Verifica se as coordenadas da ROI s√£o v√°lidas.

    Args:
        image: Imagem original (objeto PIL.Image).
        roi_coords: Tupla com as coordenadas da ROI (x1, y1, x2, y2).

    Returns:
        ROI recortada (objeto PIL.Image).

    Raises:
        ValueError: Se as coordenadas da ROI forem inv√°lidas.
    """
    x1, y1, x2, y2 = roi_coords

    # Verificar se as coordenadas est√£o dentro dos limites da imagem
    width, height = image.size
    if x1 < 0 or y1 < 0 or x2 > width or y2 > height:
        raise ValueError("Coordenadas da ROI fora dos limites da imagem.")

    # Verificar se a ROI tem largura e altura maiores que zero
    if x2 <= x1 or y2 <= y1:
        raise ValueError("Coordenadas da ROI inv√°lidas: largura ou altura igual a zero.")

    # Recortar a imagem
    roi_image = image.crop((x1, y1, x2, y2))

    # Verificar se a imagem recortada √© v√°lida
    if roi_image.size[0] == 0 or roi_image.size[1] == 0:
        raise ValueError("‚ùå Imagem recortada est√° vazia.")

    return roi_image

# Aplicando ROI aos datasets com coordenadas
def on_roi_confirmed(coords, train_df, valid_df, test_df, config_params=None, batch_size_slider=None):  # Define fun√ß√£o para aplicar ROI
    """
    Aplica a ROI especificada por 'coords' aos DataFrames de treino, valida√ß√£o e teste, recortando as imagens e atualizando os caminhos nos DataFrames.
    """
    print(f"üîç Aplicando ROI aos datasets com coordenadas: {coords}")  # Exibe coordenadas da ROI
    x1, y1, x2, y2 = coords
    roi_width = x2 - x1
    roi_height = y2 - y1
    print(f"üìè Tamanho do recorte: {roi_width}x{roi_height} pixels")

    # Validar o tamanho m√°ximo (1080x1920)
    max_width, max_height = 1080, 1920
    if roi_width > max_width or roi_height > max_height:
        raise ValueError(f"‚ùå O tamanho do recorte ({roi_width}x{roi_height}) excede o m√°ximo permitido ({max_width}x{max_height}).")

    # Usar o tamanho do recorte como target_size
    target_size = (roi_width, roi_height)

    # Validar target_size antes de desempacotar
    if not isinstance(target_size, (tuple, list)) or len(target_size) != 2:
        raise ValueError(f"target_size deve ser uma tupla ou lista com 2 elementos (largura, altura). Recebido: {target_size}")

    # Calcular o batch size com base no recorte
    roi_width, roi_height = target_size
    estimated_batch_size = estimate_batch_size(
        roi_width,
        roi_height,
        max_memory_mb=8000,
        memory_safety_factor=0.7,
        bytes_per_pixel=4 if tf.keras.mixed_precision.global_policy().name == 'float32' else 2
    )
    print(f"üìè Batch size estimado para recorte {roi_width}x{roi_height}: {estimated_batch_size}")

    # Atualizar o batch size no config_params (se dispon√≠vel no escopo)
    if config_params is not None:
        config_params['batch_size'] = estimated_batch_size
        print(f"‚úÖ Batch size ajustado para: {config_params['batch_size']}")
    else:
        print("‚ö†Ô∏è config_params n√£o encontrado no escopo global. Batch size n√£o ajustado automaticamente.")

    # Atualizar o valor do slider de batch size, se dispon√≠vel
    if batch_size_slider is not None:
        batch_size_slider.value = estimated_batch_size
        print(f"‚úÖ Slider de batch size atualizado para: {estimated_batch_size}")
    else:
        print("‚ö†Ô∏è batch_size_slider n√£o foi fornecido. O slider n√£o foi atualizado.")

    def apply_roi_to_df(df, coords, output_dir="roi_images"):  # Fun√ß√£o interna para processar DataFrame
        os.makedirs(output_dir, exist_ok=True)  # Cria diret√≥rio de sa√≠da, se necess√°rio
        new_filepaths = []  # Inicializa lista para novos caminhos
        expected_size = (coords[2] - coords[0], coords[3] - coords[1])  # Calcula tamanho esperado da ROI usando coords
        for filepath in df['filepaths']:  # Itera sobre caminhos do DataFrame
            img = Image.open(filepath)  # Abre imagem do caminho atual
            roi_img = img.crop((coords[0], coords[1], coords[2], coords[3]))  # Recorta imagem com ROI
            # Opcional: Verificar se o tamanho da imagem recortada corresponde ao esperado
            if roi_img.size != expected_size:
                print(f"‚ö†Ô∏è Imagem {os.path.basename(filepath)} tem tamanho {roi_img.size}, esperado {expected_size}")
            new_filepath = os.path.join(output_dir, os.path.basename(filepath))  # Define novo caminho
            roi_img.save(new_filepath)  # Salva imagem recortada
            new_filepaths.append(new_filepath)  # Adiciona novo caminho √† lista
        new_df = df.copy()  # Cria c√≥pia do DataFrame
        new_df['filepaths'] = new_filepaths  # Atualiza coluna 'filepaths'
        return new_df  # Retorna DataFrame atualizado

    train_df_roi = apply_roi_to_df(train_df, coords)  # Aplica ROI ao DataFrame de treino
    valid_df_roi = apply_roi_to_df(valid_df, coords)  # Aplica ROI ao DataFrame de valida√ß√£o
    test_df_roi = apply_roi_to_df(test_df, coords)  # Aplica ROI ao DataFrame de teste
    print("‚úÖ ROI aplicada aos DataFrames!")  # Confirma aplica√ß√£o da ROI
    return train_df_roi, valid_df_roi, test_df_roi, target_size  # Retorna DataFrames atualizados

# Allows the user to select a ROI using sliders and returns the ROI coordinates
def select_roi_with_sliders(image, roi_path, train_df, valid_df, test_df, after_augmentation, on_roi_confirmed):  # Defines function to select ROI with sliders
    """
    Allows the user to select a ROI using sliders and returns the ROI coordinates via callback.
    After ROI confirmation, proceeds with the flow via callback.
    """
    image_np = np.array(image)  # Converts PIL image to NumPy array
    height, width, _ = image_np.shape  # Gets image height, width, and channels
    roi_coords = [0, 0, width, height]  # Initializes ROI coordinates with the entire image

    output = Output()  # Creates output widget to display plots
    x1_slider = IntSlider(min=0, max=width - 1, step=1, value=0, description='X1:')  # Slider for x1 coordinate
    y1_slider = IntSlider(min=0, max=height - 1, step=1, value=0, description='Y1:')  # Slider for y1 coordinate
    x2_slider = IntSlider(min=1, max=width, step=1, value=width, description='X2:')  # Slider for x2 coordinate
    y2_slider = IntSlider(min=1, max=height, step=1, value=height, description='Y2:')  # Slider for y2 coordinate
    x1_label = Label(value=f"{x1_slider.value} pixels")  # Label to display x1 value
    y1_label = Label(value=f"{y1_slider.value} pixels")  # Label to display y1 value
    x2_label = Label(value=f"{x2_slider.value} pixels")  # Label to display x2 value
    y2_label = Label(value=f"{y2_slider.value} pixels")  # Label to display y2 value
    img_size_label = Label(value=f"Width: {width} pixels | Height: {height} pixels")  # Label with image size
    pixel_info_label = Label(value="Average RGB Values: (0, 0, 0)")  # Label for average RGB values
    confirm_button = Button(description="Confirm ROI", button_style='success')  # Button to confirm ROI
    reset_button = Button(description="Reset ROI", button_style='warning')  # Button to reset ROI

    def update_roi(x1, y1, x2, y2):  # Function to update ROI visualization
        nonlocal roi_coords  # Accesses roi_coords from outer scope
        roi_coords = [x1, y1, x2, y2]  # Updates ROI coordinates
        x1, x2 = min(x1, x2), max(x1, x2)  # Ensures x1 < x2
        y1, y2 = min(y1, y2), max(y1, y2)  # Ensures y1 < y2
        x1_label.value = f"{x1} pixels"  # Updates x1 label
        y1_label.value = f"{y1} pixels"  # Updates y1 label
        x2_label.value = f"{x2} pixels"  # Updates x2 label
        y2_label.value = f"{y2} pixels"  # Updates y2 label
        width_roi = x2 - x1  # Calculates ROI width
        height_roi = y2 - y1  # Calculates ROI height
        roi_image = image.crop((x1, y1, x2, y2))  # Crops the ROI from the image
        roi_image_np = np.array(roi_image)  # Converts ROI to NumPy array

        if roi_image_np.size > 0:  # Checks if ROI has pixels
            rgb_mean = np.mean(roi_image_np, axis=(0, 1)).astype(int)  # Calculates RGB mean
            pixel_info_label.value = f"Average RGB Values: ({rgb_mean[0]}, {rgb_mean[1]}, {rgb_mean[2]})"  # Updates RGB label
        else:
            pixel_info_label.value = "Average RGB Values: (N/A)"  # Sets RGB as N/A if empty

        with output:  # Uses output widget
            clear_output(wait=True)  # Clears previous output
            fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6), gridspec_kw={'width_ratios': [1, 0.5, 1]})  # Creates figure with 3 subplots
            ax1.imshow(image_np, aspect='equal')  # Shows original image
            ax1.add_patch(plt.Rectangle((x1, y1), width_roi, height_roi, edgecolor='red', linewidth=2, fill=False, linestyle='--'))  # Draws ROI rectangle
            ax1.set_title(f"Image with ROI\n(x1={x1}, y1={y1}, x2={x2}, y2={y2})")  # Sets subplot 1 title
            ax1.set_xlabel(f'Total Width: {width} pixels')  # Subplot 1 x-label
            ax1.set_ylabel(f'Total Height: {height} pixels')  # Subplot 1 y-label
            ax1.grid(True, linestyle='--', alpha=0.5)  # Adds grid to subplot 1
            ax2.imshow(roi_image_np, aspect='equal')  # Shows cropped image
            ax2.set_title("ROI Sample")  # Sets subplot 2 title
            ax2.set_xlabel(f'Width: {width_roi} pixels')  # Subplot 2 x-label
            ax2.set_ylabel(f'Height: {height_roi} pixels')  # Subplot 2 y-label
            ax2.grid(True, linestyle='--', alpha=0.5)  # Adds grid to subplot 2
            ax3.imshow(image_np, aspect='equal')  # Shows original image (reference)
            ax3.set_title("Original Image (Reference)")  # Sets subplot 3 title
            ax3.set_xlabel(f'Total Width: {width} pixels')  # Subplot 3 x-label
            ax3.set_ylabel(f'Total Height: {height} pixels')  # Subplot 3 y-label
            ax3.grid(True, linestyle='--', alpha=0.5)  # Adds grid to subplot 3
            plt.tight_layout()  # Adjusts figure layout
            plt.show()  # Displays the figure

    def on_reset(b):  # Function to reset sliders
        x1_slider.value = 0  # Resets x1 to 0
        y1_slider.value = 0  # Resets y1 to 0
        x2_slider.value = width  # Resets x2 to full width
        y2_slider.value = height  # Resets y2 to full height
        update_roi(x1_slider.value, y1_slider.value, x2_slider.value, y2_slider.value)  # Updates ROI
        print("‚úÖ ROI reset to initial state!")  # Confirms reset

    def on_confirm(b):  # Function to confirm ROI
        nonlocal roi_coords, train_df, valid_df, test_df  # Accesses outer variables
        x1, y1, x2, y2 = roi_coords  # Extracts coordinates
        # Corrects coordinate order to ensure x1 < x2 and y1 < y2
        x1, x2 = min(x1, x2), max(x1, x2)
        y1, y2 = min(y1, y2), max(y1, y2)
        roi_coords = [x1, y1, x2, y2]  # Updates roi_coords with correct order

        if x1 >= x2 or y1 >= y2 or (x1 == 0 and y1 == 0 and x2 == width and y2 == height):  # Checks if ROI is invalid
            print(f"‚ùå Invalid ROI: {roi_coords}. Select a region smaller than the entire image.")  # Warns about invalid ROI
            override_output = Output()  # Creates output widget for override
            override_button = Button(description="Proceed Anyway", button_style='danger')  # Button to force proceed

            def on_override(b, coords=roi_coords):  # Function for override
                nonlocal train_df, valid_df, test_df  # Accesses DataFrames
                with override_output:  # Uses output widget
                    clear_output(wait=True)  # Clears output
                    print(f"‚ö†Ô∏è Proceeding with invalid ROI: {coords}")  # Warns about override
                    roi_image = image.crop((coords[0], coords[1], coords[2], coords[3]))  # Crops ROI
                    roi_image.save(roi_path)  # Saves ROI
                    print(f"‚úÖ ROI saved to {roi_path}")  # Confirms save
                    try:
                        # Passes coordinates directly as list [x1, y1, x2, y2]
                        on_roi_confirmed(coords)  # Calls confirmation callback
                        print("‚úÖ DataFrames updated with ROI applied (override)!")  # Confirms update
                        confirm_button.disabled = True  # Disables confirm button
                        reset_button.disabled = True  # Disables reset button
                        print("‚úÖ Confirm ROI and Reset ROI buttons disabled!")  # Confirms disable
                    except Exception as e:
                        print(f"‚ùå Error processing ROI (override): {str(e)}")  # Displays error
                        raise  # Re-raises exception

            override_button.on_click(lambda b: on_override(b))  # Connects function to button
            with override_output:  # Uses output widget
                display(override_button)  # Displays override button
            display(override_output)  # Shows output widget
            return  # Exits function

        print(f"\nüñ±Ô∏è Selected ROI: (x1={roi_coords[0]}, y1={roi_coords[1]}), (x2={roi_coords[2]}, y2={roi_coords[3]})")  # Confirms selected ROI
        roi_image = image.crop((roi_coords[0], roi_coords[1], roi_coords[2], roi_coords[3]))  # Crops ROI
        roi_image.save(roi_path)  # Saves ROI to disk
        print(f"‚úÖ ROI saved to {roi_path}")  # Confirms save
        with output:  # Uses output widget
            clear_output(wait=True)  # Clears output
            fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6), gridspec_kw={'width_ratios': [1, 0.5, 1]})  # Creates figure with 3 subplots
            ax1.imshow(image_np, aspect='equal')  # Shows original image
            ax1.add_patch(plt.Rectangle((roi_coords[0], roi_coords[1]), roi_coords[2] - roi_coords[0], roi_coords[3] - roi_coords[1], edgecolor='red', linewidth=2, fill=False, linestyle='--'))  # Draws ROI
            ax1.set_title("Image with Selected ROI")  # Sets subplot 1 title
            ax1.set_xlabel(f'Total Width: {width} pixels')  # Subplot 1 x-label
            ax1.set_ylabel(f'Total Height: {height} pixels')  # Subplot 1 y-label
            ax1.grid(True, linestyle='--', alpha=0.5)  # Adds grid to subplot 1
            ax2.imshow(np.array(roi_image), aspect='equal')  # Shows cropped ROI
            ax2.set_title("Cropped Image")  # Sets subplot 2 title
            ax2.set_xlabel(f'Width: {roi_coords[2] - roi_coords[0]} pixels')  # Subplot 2 x-label
            ax2.set_ylabel(f'Height: {roi_coords[3] - roi_coords[1]} pixels')  # Subplot 2 y-label
            ax2.grid(True, linestyle='--', alpha=0.5)  # Adds grid to subplot 2
            ax3.imshow(image_np, aspect='equal')  # Shows original image (reference)
            ax3.set_title("Original Image (Reference)")  # Sets subplot 3 title
            ax3.set_xlabel(f'Total Width: {width} pixels')  # Subplot 3 x-label
            ax3.set_ylabel(f'Total Height: {height} pixels')  # Subplot 3 y-label
            ax3.grid(True, linestyle='--', alpha=0.5)  # Adds grid to subplot 3
            plt.tight_layout()  # Adjusts figure layout
            plt.show()  # Displays figure
        try:
            # Passes coordinates directly as list [x1, y1, x2, y2]
            on_roi_confirmed(roi_coords)  # Calls confirmation callback
            print("‚úÖ DataFrames updated with ROI applied!")  # Confirms update
            confirm_button.disabled = True  # Disables confirm button
            reset_button.disabled = True  # Disables reset button
            print("‚úÖ Confirm ROI and Reset ROI buttons disabled!")  # Confirms disable
        except Exception as e:
            print(f"‚ùå Error processing ROI: {str(e)}")  # Displays error
            raise  # Re-raises exception

    # Display interface
    display(VBox([  # Displays interface vertically
        img_size_label,  # Shows image size
        pixel_info_label,  # Shows pixel info
        output,  # Shows plots
        HBox([x1_slider, x1_label]),  # Shows x1 slider and label
        HBox([y1_slider, y1_label]),  # Shows y1 slider and label
        HBox([x2_slider, x2_label]),  # Shows x2 slider and label
        HBox([y2_slider, y2_label]),  # Shows y2 slider and label
        HBox([confirm_button, reset_button])  # Shows confirm and reset buttons
    ]))

    # Connect sliders and buttons
    x1_slider.observe(lambda change: update_roi(x1_slider.value, y1_slider.value, x2_slider.value, y2_slider.value), names='value')  # Connects x1 slider
    y1_slider.observe(lambda change: update_roi(x1_slider.value, y1_slider.value, x2_slider.value, y2_slider.value), names='value')  # Connects y1 slider
    x2_slider.observe(lambda change: update_roi(x1_slider.value, y1_slider.value, x2_slider.value, y2_slider.value), names='value')  # Connects x2 slider
    y2_slider.observe(lambda change: update_roi(x1_slider.value, y1_slider.value, x2_slider.value, y2_slider.value), names='value')  # Connects y2 slider
    confirm_button.on_click(on_confirm)  # Connects confirm button
    reset_button.on_click(on_reset)  # Connects reset button
    update_roi(0, 0, width, height)  # Initializes ROI with full image
    # Does not return here, waits for on_roi_confirmed callback  # Awaits user action via callback

# Function to apply ROI to all images in the dataset
def apply_roi_to_df(df, roi_coords, output_dir, sample_image_path=None):
    """
    Applies the ROI to all images in the DataFrame, dynamically adjusting the ROI position
    based on template matching with the sample image, without converting to grayscale.

    Args:
        df: DataFrame with image paths and labels.
        roi_coords: Fixed ROI coordinates [x1, y1, x2, y2] defined on the sample image.
        output_dir: Directory where cropped images will be saved.
        sample_image_path: Path to the sample image (optional, if None, uses the first image from df).

    Returns:
        Updated DataFrame with new paths to cropped images.
    """
    # Validates roi_coords format
    if not isinstance(roi_coords, list) or len(roi_coords) != 4:
        raise ValueError(f"‚ùå Invalid roi_coords: {roi_coords}. Must be a list [x1, y1, x2, y2].")

    import cv2  # Imports OpenCV inside the function to ensure availability

    os.makedirs(output_dir, exist_ok=True)  # Creates output directory if needed
    new_filepaths = []  # List for new paths to cropped images
    expected_size = (roi_coords[2] - roi_coords[0], roi_coords[3] - roi_coords[1])  # Calculates expected ROI size

    # Loads the sample image (if not provided, uses the first image from DataFrame)
    if sample_image_path is None:
        sample_image_path = df.iloc[0]['filepaths']
    sample_img = cv2.imread(sample_image_path)
    if sample_img is None:
        raise ValueError(f"Failed to load sample image: {sample_image_path}")
    sample_img = cv2.cvtColor(sample_img, cv2.COLOR_BGR2RGB)

    # Corrects coordinate order to ensure x1 < x2 and y1 < y2
    x1, y1, x2, y2 = [int(coord) for coord in roi_coords]
    x1, x2 = min(x1, x2), max(x1, x2)  # Corrects x order
    y1, y2 = min(y1, y2), max(y1, y2)  # Corrects y order

    # Applies fixed ROI to the sample image to create the template
    x1, y1 = max(0, x1), max(0, y1)
    x2, y2 = min(sample_img.shape[1], x2), min(sample_img.shape[0], y2)
    if x1 >= x2 or y1 >= y2:
        raise ValueError(f"Invalid ROI coordinates for sample image: ({x1}, {y1}, {x2}, {y2})")
    template = sample_img[y1:y2, x1:x2]  # The template is the ROI from the sample image (in RGB)

    # Checks if the template has a valid size
    if template.shape[0] == 0 or template.shape[1] == 0:
        raise ValueError("The template (ROI of the sample image) has an invalid size.")

    new_filepaths = []
    for idx, row in df.iterrows():
        img_path = row['filepaths']
        label = row['labels']
        img = cv2.imread(img_path)
        if img is None:
            print(f"Error loading image: {img_path}")
            new_filepaths.append(img_path)
            continue
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # Applies template matching to find the best match
        # Uses TM_CCOEFF_NORMED method (normalized correlation coefficient)
        result = cv2.matchTemplate(img, template, cv2.TM_CCOEFF_NORMED)
        _, _, _, max_loc = cv2.minMaxLoc(result)  # Finds the position with the highest match

        # The max_loc position is the top-left corner of the matching region
        adjusted_x1 = max_loc[0]
        adjusted_y1 = max_loc[1]
        adjusted_x2 = adjusted_x1 + (x2 - x1)  # Maintains the same ROI size
        adjusted_y2 = adjusted_y1 + (y2 - y1)

        # Ensures adjusted coordinates are within image bounds
        adjusted_x1, adjusted_y1 = max(0, adjusted_x1), max(0, adjusted_y1)
        adjusted_x2, adjusted_y2 = min(img.shape[1], adjusted_x2), min(img.shape[0], adjusted_y2)

        # Checks if the adjusted ROI is valid
        if adjusted_x1 < adjusted_x2 and adjusted_y1 < adjusted_y2:
            cropped_img = img[adjusted_y1:adjusted_y2, adjusted_x1:adjusted_x2]
        else:
            print(f"Invalid adjusted ROI for {img_path}. Using fixed ROI.")
            adjusted_x1, adjusted_y1 = max(0, x1), max(0, y1)
            adjusted_x2, adjusted_y2 = min(img.shape[1], x2), min(img.shape[0], y2)
            if adjusted_x1 < adjusted_x2 and adjusted_y1 < adjusted_y2:
                cropped_img = img[adjusted_y1:adjusted_y2, adjusted_x1:adjusted_x2]  # Corrects indices for proper cropping
            else:
                cropped_img = img  # Fallback: uses the entire image

        # Saves the cropped image
        class_dir = os.path.join(output_dir, label.lower())
        os.makedirs(class_dir, exist_ok=True)
        output_path = os.path.join(class_dir, os.path.basename(img_path))
        cv2.imwrite(output_path, cv2.cvtColor(cropped_img, cv2.COLOR_RGB2BGR))
        new_filepaths.append(output_path)

    return df.assign(filepaths=new_filepaths)

# Function to visualize cropped images
def visualize_recorted_images(train_df, sample_img_path, roi_coords):
    x1, y1, x2, y2 = roi_coords
    x1, x2 = min(x1, x2), max(x1, x2)
    y1, y2 = min(y1, y2), max(y1, y2)
    num_images = min(5, len(train_df))  # Limits to available images, up to 5
    if num_images > 0:  # Checks if there are images to display
        figstratosphere, axes = plt.subplots(1, num_images, figsize=(num_images * 3, 4))  # Creates horizontal subplots
        if num_images == 1:  # Special case for a single image
            axes = [axes]  # Converts to list for iteration
        sample_img = cv2.imread(sample_img_path)
        template = sample_img[y1:y2, x1:x2]
        for ax, (_, row) in zip(axes, train_df.head(num_images).iterrows()):
            img_path = row['filepaths']
            img = cv2.imread(img_path)
            if img is not None:  # Checks if image was loaded correctly
                result = cv2.matchTemplate(img, template, cv2.TM_CCOEFF_NORMED)
                _, _, _, max_loc = cv2.minMaxLoc(result)
                top_left = max_loc
                bottom_right = (top_left[0] + (x2 - x1), top_left[1] + (y2 - y1))
                roi_img = img[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]
                roi_img = cv2.cvtColor(roi_img, cv2.COLOR_BGR2RGB)
                ax.imshow(roi_img)
                ax.set_title(f"Cropped Image: {row['labels']}")
                ax.axis('off')
            else:
                ax.text(0.5, 0.5, "Error loading", ha='center', va='center')
                ax.axis('off')
        plt.tight_layout()  # Adjusts layout to avoid overlap
        plt.show()

# Fun√ß√£o para aplicar aumenta√ß√£o de dados e criar geradores
def augment_data(train_df, valid_df, test_df, roi_coords=None, batch_size=32,
                 rotation_range=0, width_shift_range=0, height_shift_range=0,
                 zoom_range=0, horizontal_flip=False, shear_range=0, brightness_range=None, fill_mode='nearest', target_size=None):
    """
    Aplica aumenta√ß√£o de dados e cria geradores para treino, valida√ß√£o e teste.

    Args:
        train_df: DataFrame de treino.
        valid_df: DataFrame de valida√ß√£o.
        test_df: DataFrame de teste.
        roi_coords: Coordenadas da ROI (x1, y1, x2, y2) para definir o tamanho alvo (opcional).
        batch_size: Tamanho do batch. # Padr√£o √© 32, mas pode ser sobrescrito por um valor passado explicitamente.
        rotation_range: Faixa de rota√ß√£o para aumenta√ß√£o (em graus).
        width_shift_range: Faixa de deslocamento horizontal (fra√ß√£o da largura).
        height_shift_range: Faixa de deslocamento vertical (fra√ß√£o da altura).
        zoom_range: Faixa de zoom.
        horizontal_flip: Se deve aplicar flip horizontal.
        shear_range: Faixa de cisalhamento (em graus).
        brightness_range: Intervalo de ajuste de brilho (ex.: (0.8, 1.2)).
        fill_mode: Modo de preenchimento para √°reas fora da imagem ap√≥s transforma√ß√µes.
        target_size: Tamanho alvo das imagens (height, width). Se None, usa roi_coords ou padr√£o.

    Returns:
        Tuple: Geradores de treino, valida√ß√£o e teste, e n√∫mero de classes.
    """
    try:  # Inicia um bloco try para capturar exce√ß√µes durante a execu√ß√£o da fun√ß√£o
        from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Importa o ImageDataGenerator do TensorFlow para criar geradores de imagens

        # Verificar os DataFrames
        for df, name in [(train_df, 'train_df'), (valid_df, 'valid_df'), (test_df, 'test_df')]:  # Itera sobre os DataFrames e seus nomes associados
            if df is None or df.empty:  # Verifica se o DataFrame √© None ou est√° vazio
                print(f"‚ùå Erro: {name} est√° vazio ou n√£o foi inicializado.")  # Exibe mensagem de erro se o DataFrame estiver inv√°lido
                return None, None, None, 0  # Retorna valores nulos e 0 classes para indicar falha
            if 'filepaths' not in df.columns or 'labels' not in df.columns:  # Verifica se as colunas 'filepaths' e 'labels' est√£o presentes no DataFrame
                print(f"‚ùå Erro: {name} n√£o cont√©m as colunas 'filepaths' e 'labels'.")  # Exibe erro se as colunas necess√°rias estiverem ausentes
                return None, None, None, 0  # Retorna valores nulos e 0 classes para indicar falha
            # Adi√ß√£o: Verifica se a coluna 'labels' cont√©m valores v√°lidos (n√£o nulos ou vazios)
            if df['labels'].isnull().all() or df['labels'].str.strip().eq('').all():  # Checa se todos os r√≥tulos s√£o nulos ou strings vazias
                print(f"‚ùå Erro: {name} tem a coluna 'labels' com valores inv√°lidos (todos nulos ou vazios).")  # Exibe erro se os r√≥tulos forem inv√°lidos
                return None, None, None, 0  # Retorna valores nulos e 0 classes para indicar falha
            print(f"‚úÖ {name} validado: {len(df)} amostras, Exemplo de r√≥tulos: {df['labels'].head().tolist()}")  # Confirma valida√ß√£o do DataFrame e exibe n√∫mero de amostras e exemplos de r√≥tulos

        # Calcular o tamanho da ROI a partir das coordenadas ou usar target_size
        if target_size is not None:  # Verifica se o par√¢metro target_size foi fornecido explicitamente
            print(f"‚úÖ Usando target_size fornecido: {target_size}")  # Confirma que o target_size fornecido ser√° usado
            if not isinstance(target_size, (tuple, list)) or len(target_size) != 2 or target_size[0] <= 0 or target_size[1] <= 0:  # Valida o formato e valores de target_size
                raise ValueError(f"‚ùå target_size inv√°lido: {target_size}. Deve ser uma tupla (altura, largura) com valores positivos.")  # Lan√ßa erro se target_size for inv√°lido
        elif roi_coords is not None:  # Verifica se as coordenadas da ROI foram fornecidas
            x1, y1, x2, y2 = roi_coords  # Desempacota as coordenadas da ROI em x1, y1, x2, y2
            if x2 <= x1 or y2 <= y1:  # Verifica se as coordenadas s√£o consistentes (x2 > x1 e y2 > y1)
                raise ValueError(f"‚ùå Coordenadas da ROI inv√°lidas: (x1={x1}, y1={y1}, x2={x2}, y2={y2})")  # Lan√ßa erro se as coordenadas forem inv√°lidas
            target_size = (y2 - y1, x2 - x1)  # Calcula o tamanho alvo (altura, largura) a partir das coordenadas da ROI
            print(f"‚úÖ Usando tamanho da ROI selecionada: {target_size}")  # Confirma o tamanho calculado da ROI
        else:  # Caso nem target_size nem roi_coords sejam fornecidos
            from PIL import Image  # Importa a biblioteca PIL para manipula√ß√£o de imagens
            sample_image_path = train_df['filepaths'].iloc[0]  # Obt√©m o caminho da primeira imagem no DataFrame de treino
            try:  # Inicia um bloco try para capturar erros ao abrir a imagem
                with Image.open(sample_image_path) as img:  # Abre a imagem usando PIL
                    original_size = img.size  # Obt√©m o tamanho original da imagem (largura, altura)
                    target_size = (original_size[1], original_size[0])  # Define target_size como (altura, largura) baseado no tamanho original
                print(f"‚ö†Ô∏è Nem ROI nem target_size fornecidos. Usando tamanho original da imagem: {target_size}")  # Avisa que o tamanho original ser√° usado
            except Exception as e:  # Captura qualquer erro ao abrir a imagem
                print(f"‚ùå Erro ao abrir imagem de amostra {sample_image_path}: {str(e)}. Usando padr√£o (224, 224)")  # Exibe erro e usa tamanho padr√£o
                target_size = (224, 224)  # Define um tamanho padr√£o (224x224) em caso de falha

        # Validar o batch_size com base no tamanho do dataset
        min_dataset_size = min(len(train_df), len(valid_df), len(test_df))  # Calcula o menor n√∫mero de amostras entre os DataFrames
        if batch_size > min_dataset_size:  # Verifica se o batch_size √© maior que o menor conjunto de dados
            batch_size = max(1, min_dataset_size // 2)  # Ajusta o batch_size para no m√°ximo metade do menor conjunto, garantindo pelo menos 1
            print(f"‚ö†Ô∏è Batch size original maior que o menor conjunto de dados ({min_dataset_size}). Ajustado para: {batch_size}")  # Exibe aviso sobre o ajuste do batch_size

        # Configurar o gerador de dados com aumenta√ß√£o para treino
        train_datagen = ImageDataGenerator(  # Inicializa o gerador de dados para treino com par√¢metros de aumenta√ß√£o
            rescale=1./255,  # Normaliza os valores dos pixels dividindo por 255 (escala de 0 a 1)
            rotation_range=rotation_range,  # Define o intervalo de rota√ß√£o aleat√≥ria em graus
            width_shift_range=width_shift_range,  # Define a fra√ß√£o de deslocamento horizontal aleat√≥rio
            height_shift_range=height_shift_range,  # Define a fra√ß√£o de deslocamento vertical aleat√≥rio
            shear_range=shear_range,  # Define o intervalo de cisalhamento (deforma√ß√£o) em graus
            zoom_range=zoom_range,  # Define o intervalo de zoom aleat√≥rio
            horizontal_flip=horizontal_flip,  # Habilita ou desabilita flip horizontal aleat√≥rio
            brightness_range=brightness_range,  # Define o intervalo de ajuste de brilho (ex.: [0.8, 1.2])
            fill_mode=fill_mode  # Define o modo de preenchimento para √°reas fora da imagem ap√≥s transforma√ß√µes
        )

        # Geradores para valida√ß√£o e teste (sem aumenta√ß√£o)
        valid_datagen = ImageDataGenerator(rescale=1./255)  # Inicializa o gerador de valida√ß√£o apenas com normaliza√ß√£o (sem aumenta√ß√£o)
        test_datagen = ImageDataGenerator(rescale=1./255)   # Inicializa o gerador de teste apenas com normaliza√ß√£o (sem aumenta√ß√£o)

        # Criar geradores
        train_generator = train_datagen.flow_from_dataframe(  # Cria o gerador de treino usando o DataFrame de treino
            dataframe=train_df,  # Define o DataFrame de treino como fonte de dados
            x_col='filepaths',  # Especifica a coluna com os caminhos das imagens
            y_col='labels',  # Especifica a coluna com os r√≥tulos das imagens
            target_size=target_size,  # Define o tamanho alvo das imagens (calculado ou padr√£o)
            batch_size=batch_size,  # Define o tamanho do batch (ajustado se necess√°rio)
            class_mode='categorical',  # Configura o modo categ√≥rico para retornar r√≥tulos em one-hot encoding
            shuffle=True  # Habilita o embaralhamento das imagens para o treinamento
        )

        valid_generator = valid_datagen.flow_from_dataframe(  # Cria o gerador de valida√ß√£o usando o DataFrame de valida√ß√£o
            dataframe=valid_df,  # Define o DataFrame de valida√ß√£o como fonte de dados
            x_col='filepaths',  # Especifica a coluna com os caminhos das imagens
            y_col='labels',  # Especifica a coluna com os r√≥tulos das imagens
            target_size=target_size,  # Define o tamanho alvo das imagens (calculado ou padr√£o)
            batch_size=batch_size,  # Define o tamanho do batch (ajustado se necess√°rio)
            class_mode='categorical',  # Configura o modo categ√≥rico para retornar r√≥tulos em one-hot encoding
            shuffle=False  # Desabilita o embaralhamento para manter a ordem na valida√ß√£o
        )

        test_generator = test_datagen.flow_from_dataframe(  # Cria o gerador de teste usando o DataFrame de teste
            dataframe=test_df,  # Define o DataFrame de teste como fonte de dados
            x_col='filepaths',  # Especifica a coluna com os caminhos das imagens
            y_col='labels',  # Especifica a coluna com os r√≥tulos das imagens
            target_size=target_size,  # Define o tamanho alvo das imagens (calculado ou padr√£o)
            batch_size=batch_size,  # Define o tamanho do batch (ajustado se necess√°rio)
            class_mode='categorical',  # Configura o modo categ√≥rico para retornar r√≥tulos em one-hot encoding
            shuffle=False  # Desabilita o embaralhamento para manter a ordem no teste
        )

        # N√∫mero de classes
        num_classes = len(train_generator.class_indices)  # Calcula o n√∫mero de classes √∫nicas com base no mapeamento do gerador de treino
        print(f"Classes encontradas: {train_generator.class_indices}")  # Exibe o dicion√°rio que mapeia r√≥tulos para √≠ndices num√©ricos

        # Adi√ß√£o: Teste para garantir que os geradores retornam r√≥tulos corretamente
        for generator, name in [(train_generator, 'train_generator'), (valid_generator, 'valid_generator'), (test_generator, 'test_generator')]:  # Itera sobre os geradores criados
            batch = next(iter(generator))  # Obt√©m o primeiro lote de dados do gerador
            if not isinstance(batch, tuple) or len(batch) != 2:  # Verifica se o lote √© uma tupla com 2 elementos (imagens e r√≥tulos)
                print(f"‚ùå Erro: {name} n√£o retornou uma tupla (imagens, r√≥tulos). Tipo retornado: {type(batch)}")  # Exibe erro se o formato estiver incorreto
                return None, None, None, 0  # Retorna valores nulos e 0 classes para indicar falha
            print(f"‚úÖ {name} validado: Imagens = {batch[0].shape}, R√≥tulos = {batch[1].shape}")  # Confirma que o gerador retorna imagens e r√≥tulos com os formatos esperados

        print(f"N√∫mero de classes detectadas: {num_classes}")  # Exibe o n√∫mero total de classes detectadas
        # Verifica√ß√µes adicionais para consist√™ncia
        if num_classes != len(test_generator.class_indices):  # Compara o n√∫mero de classes entre os geradores de treino e teste
            print(f"‚ö†Ô∏è Aviso: N√∫mero de classes inconsistente entre train_generator ({num_classes}) e test_generator ({len(test_generator.class_indices)})")  # Alerta sobre poss√≠vel inconsist√™ncia
        print(f"üîç Classes detectadas no test_generator: {test_generator.class_indices}")  # Exibe o mapeamento de classes do gerador de teste
        print(f"üîç test_generator.classes: {test_generator.classes}")  # Exibe os r√≥tulos reais do conjunto de teste como array de √≠ndices
        print(f"üîç N√∫mero de amostras: train={train_generator.samples}, valid={valid_generator.samples}, test={test_generator.samples}")  # Exibe o n√∫mero total de amostras em cada gerador
        print(f"‚úÖ Batch Size configurado nos geradores: train={train_generator.batch_size}, valid={valid_generator.batch_size}, test={test_generator.batch_size}")  # Confirma o batch_size configurado em cada gerador

        return train_generator, valid_generator, test_generator, num_classes  # Retorna os geradores validados e o n√∫mero de classes

    except Exception as e:  # Captura qualquer exce√ß√£o que ocorra durante a execu√ß√£o da fun√ß√£o
        print(f"‚ùå Erro durante a execu√ß√£o da fun√ß√£o augment_data: {str(e)}")  # Exibe a mensagem de erro com detalhes da exce√ß√£o
        return None, None, None, 0  # Retorna valores nulos e 0 classes em caso de erro

# Estimar o batch size com base no tamanho do recorte
def estimate_batch_size(roi_width, roi_height, max_memory_mb=8000, memory_safety_factor=0.7, bytes_per_pixel=4, max_batch_size=64):
    """
    Estima o tamanho ideal do batch com base na mem√≥ria dispon√≠vel e no tamanho do recorte da imagem.

    Args:
        roi_width (int): Largura da regi√£o de interesse (ROI) da imagem.
        roi_height (int): Altura da regi√£o de interesse (ROI) da imagem.
        max_memory_mb (int, opcional): Mem√≥ria m√°xima dispon√≠vel em MB. Padr√£o: 8000 MB (8 GB).
        memory_safety_factor (float, opcional): Fator de seguran√ßa para reservar mem√≥ria adicional (0 a 1). Padr√£o: 0.7 (70%).
        bytes_per_pixel (int, opcional): Bytes por pixel (4 para float32, 2 para float16). Padr√£o: 4.
        max_batch_size (int, opcional): Tamanho m√°ximo do batch. Padr√£o: 64.

    Returns:
        int: Batch size estimado, limitado ao intervalo de 1 a max_batch_size.
    """
    # Validar entradas
    if not isinstance(roi_width, (int, float)) or not isinstance(roi_height, (int, float)):
        raise ValueError("roi_width e roi_height devem ser n√∫meros.")
    if roi_width <= 0 or roi_height <= 0:
        raise ValueError("roi_width e roi_height devem ser maiores que zero.")
    if max_memory_mb <= 0:
        raise ValueError("max_memory_mb deve ser maior que zero.")
    if not 0 < memory_safety_factor <= 1:
        raise ValueError("memory_safety_factor deve estar entre 0 e 1.")
    if bytes_per_pixel not in [2, 4]:
        raise ValueError("bytes_per_pixel deve ser 2 (float16) ou 4 (float32).")

    # Calcular o consumo de mem√≥ria por imagem (em MB)
    image_memory_mb = (roi_width * roi_height * 3 * bytes_per_pixel) / (1024 * 1024)  # 3 canais (RGB)

    # Ajustar a mem√≥ria dispon√≠vel com o fator de seguran√ßa
    effective_memory_mb = max_memory_mb * memory_safety_factor

    # Estimar o n√∫mero m√°ximo de imagens que cabem na mem√≥ria
    max_images = int(effective_memory_mb / image_memory_mb)

    # Garantir que o batch size esteja dentro do intervalo permitido (1 a max_batch_size)
    estimated_batch_size = min(max(1, max_images), max_batch_size)

    # Exibir informa√ß√µes sobre o c√°lculo do batch size
    print(f"üìè Tamanho do recorte: {roi_width}x{roi_height} pixels")
    print(f"üìè Tamanho estimado por imagem: {image_memory_mb:.2f} MB")
    print(f"üìè Mem√≥ria efetiva dispon√≠vel: {effective_memory_mb:.2f} MB (ap√≥s fator de seguran√ßa {memory_safety_factor:.2f})")
    print(f"üìè Batch size estimado: {estimated_batch_size} (baseado no limite de {max_memory_mb} MB)")

    return estimated_batch_size


# =============================================================================#
# √ÅREA DE TRATAMENTO DOS GERADORES DE DADOS
# =============================================================================#

# Ap√≥s as importa√ß√µes
augmented_images_data = {}
actual_vs_predicted_data = {}

# ============================
# Geradores de Dados
# ============================

# üìÇ **Defina o diret√≥rio de dados**
dataDir = '/content/drive/MyDrive/Colab Notebooks/PeneiraDataSetJPG4Partes/'

# üñºÔ∏è **Defina o caminho onde a ROI ser√° salva**
roi_path = '/content/drive/MyDrive/Colab Notebooks/PeneiraDataSetJPG4Partes/roi_image.jpg'

# üöÄ **Carregar e dividir o dataset**
train_df, valid_df, test_df = load_and_split_dataset(dataDir)

# Criar o dicion√°rio de pesos
#class_weights_dict = dict(zip(classes, class_weights))
#print("Pesos das classes:", class_weights_dict)

# Fun√ß√£o para criar geradores de dados a partir de um DataFrame
def create_data_generator(dataframe, datagen, img_size=(224, 224), batch_size=32, shuffle=True, class_mode='categorical'):
    """
    Cria um gerador de dados a partir de um DataFrame.

    Args:
        dataframe (pd.DataFrame): DataFrame contendo os caminhos das imagens e r√≥tulos.
        datagen (ImageDataGenerator): Gerador de dados com ou sem aumenta√ß√£o.
        img_size (tuple): Tamanho das imagens de sa√≠da (altura, largura).
        batch_size (int): N√∫mero de imagens por batch.
        shuffle (bool): Se True, embaralha as imagens.
        class_mode (str): Modo de classifica√ß√£o ('categorical', 'binary', etc.).

    Returns:
        DataFrameIterator: Gerador de dados.
    """
    return datagen.flow_from_dataframe(  # Cria√ß√£o do gerador de dados a partir do DataFrame
        dataframe=dataframe,
        x_col='filepaths',  # Coluna com os caminhos das imagens
        y_col='labels',  # Coluna com os r√≥tulos das imagens
        target_size=img_size,  # Ajusta o tamanho das imagens
        color_mode='rgb',  # Mant√©m as imagens coloridas
        batch_size=batch_size,  # Define o tamanho do batch
        shuffle=shuffle,  # Define se as imagens ser√£o embaralhadas
        class_mode=class_mode  # Define o modo de classifica√ß√£o dos r√≥tulos
    )

# Fun√ß√£o para criar sliders de forma simplificada
def create_slider(min_val, max_val, step, value, description):
    """
    Cria um slider para ajustar par√¢metros de aumenta√ß√£o.

    Args:
        min_val (float): Valor m√≠nimo.
        max_val (float): Valor m√°ximo.
        step (float): Passo de incremento.
        value (float): Valor inicial.
        description (str): Descri√ß√£o do slider.

    Returns:
        widgets.FloatSlider ou widgets.IntSlider: Slider configurado.
    """
    #if isinstance(value, int):
    #    return widgets.IntSlider(min=min_val, max=max_val, step=step, value=value, description=description)
    #else:
    #    return widgets.FloatSlider(min=min_val, max=max_val, step=step, value=value, description=description)

    # Retorna um slider de inteiro se 'value' for int, sen√£o retorna um slider de float
    return widgets.IntSlider(min=min_val, max=max_val, step=step, value=value, description=description) if isinstance(value, int) else \
          widgets.FloatSlider(min=min_val, max=max_val, step=step, value=value, description=description)


# Fun√ß√£o para definir os par√¢metros de aumenta√ß√£o (ajustada para corrigir nomes das colunas)
def define_augmentation_parameters(train_df, valid_df, test_df, after_augmentation, roi_coords=None):  # Define fun√ß√£o para configurar aumenta√ß√£o
    """
    Exibe sliders para configurar os par√¢metros de aumenta√ß√£o de dados e prossegue com os geradores configurados.

    Args:
        train_df: DataFrame de treino.
        valid_df: DataFrame de valida√ß√£o.
        test_df: DataFrame de teste.
        after_augmentation: Callback a ser chamado ap√≥s a configura√ß√£o.
        roi_coords: Coordenadas da ROI (x1, y1, x2, y2) para definir o tamanho alvo (opcional).
    """
    augmentation_output = widgets.Output()  # Cria widget de sa√≠da para logs

    # Sliders para os par√¢metros de aumenta√ß√£o
    rotation_range_slider = widgets.IntSlider(min=0, max=180, step=1, value=20, description='Rota√ß√£o:')  # Slider para rota√ß√£o
    width_shift_range_slider = widgets.FloatSlider(min=0.0, max=0.5, step=0.01, value=0.2, description='Desloc. H:')  # Slider para deslocamento horizontal
    height_shift_range_slider = widgets.FloatSlider(min=0.0, max=0.5, step=0.01, value=0.2, description='Desloc. V:')  # Slider para deslocamento vertical
    shear_range_slider = widgets.FloatSlider(min=0.0, max=0.5, step=0.01, value=0.2, description='Cisalhamento:')  # Slider para cisalhamento
    zoom_range_slider = widgets.FloatSlider(min=0.0, max=0.5, step=0.01, value=0.2, description='Zoom:')  # Slider para zoom
    horizontal_flip_checkbox = widgets.Checkbox(value=True, description='Flip Horizontal')  # Checkbox para flip horizontal
    brightness_min_slider = widgets.FloatSlider(min=0.5, max=1.0, step=0.05, value=0.8, description='Brilho M√≠n:')  # Slider para brilho m√≠nimo
    brightness_max_slider = widgets.FloatSlider(min=1.0, max=1.5, step=0.05, value=1.2, description='Brilho M√°x:')  # Slider para brilho m√°ximo
    fill_mode_dropdown = widgets.Dropdown(options=['nearest', 'constant', 'reflect', 'wrap'], value='nearest', description='Modo de Preenchimento:')  # Dropdown para modo de preenchimento

    # Bot√µes de confirmar e resetar
    confirm_augmentation_button = widgets.Button(description="Confirmar Aumenta√ß√£o", button_style='success')  # Bot√£o para confirmar aumenta√ß√£o
    reset_augmentation_button = widgets.Button(description="Resetar Aumenta√ß√£o", button_style='warning')  # Bot√£o para resetar aumenta√ß√£o

    # Fun√ß√£o para resetar os valores dos sliders de aumenta√ß√£o
    def on_reset_augmentation(b):  # Define fun√ß√£o de reset
        rotation_range_slider.value = 20  # Reseta rota√ß√£o
        width_shift_range_slider.value = 0.2  # Reseta deslocamento horizontal
        height_shift_range_slider.value = 0.2  # Reseta deslocamento vertical
        shear_range_slider.value = 0.2  # Reseta cisalhamento
        zoom_range_slider.value = 0.2  # Reseta zoom
        horizontal_flip_checkbox.value = True  # Reseta flip horizontal
        brightness_min_slider.value = 0.8  # Reseta brilho m√≠nimo
        brightness_max_slider.value = 1.2  # Reseta brilho m√°ximo
        fill_mode_dropdown.value = 'nearest'  # Reseta modo de preenchimento
        with augmentation_output:  # Usa widget de sa√≠da
            clear_output(wait=True)  # Limpa sa√≠da anterior
            print("üîÑ Par√¢metros de aumenta√ß√£o resetados.")  # Confirma reset

    # Callback para confirma√ß√£o dos par√¢metros de aumenta√ß√£o
    def on_confirm_augmentation(b):  # Define fun√ß√£o de confirma√ß√£o
        confirm_augmentation_button.disabled = True  # Desabilita bot√£o de confirma√ß√£o
        reset_augmentation_button.disabled = True  # Desabilita bot√£o de reset
        with augmentation_output:  # Usa widget de sa√≠da
            clear_output(wait=True)  # Limpa sa√≠da anterior
            print(f"üîß Par√¢metros de aumenta√ß√£o confirmados: Rota√ß√£o={rotation_range_slider.value}, "  # Exibe par√¢metros confirmados
                  f"Desloc. H={width_shift_range_slider.value}, Desloc. V={height_shift_range_slider.value}, "
                  f"Cisalhamento={shear_range_slider.value}, Zoom={zoom_range_slider.value}, "
                  f"Flip Horizontal={horizontal_flip_checkbox.value}, "
                  f"Brilho=({brightness_min_slider.value}, {brightness_max_slider.value}), "
                  f"Modo de Preenchimento={fill_mode_dropdown.value}")

            # Verificar colunas dos DataFrames (debug)
            print("Colunas de train_df:", train_df.columns)  # Exibe colunas de train_df
            print("Colunas de valid_df:", valid_df.columns)  # Exibe colunas de valid_df
            print("Colunas de test_df:", test_df.columns)  # Exibe colunas de test_df

            try:
                # Usar a fun√ß√£o augment_data ajustada para criar os geradores
                train_generator, valid_generator, test_generator, num_classes = augment_data(  # Cria geradores de dados
                    train_df=train_df,  # Passa DataFrame de treino
                    valid_df=valid_df,  # Passa DataFrame de valida√ß√£o
                    test_df=test_df,  # Passa DataFrame de teste
                    roi_coords=roi_coords,  # Passa coordenadas da ROI, se fornecidas
                    batch_size=32,  # Define tamanho do batch
                    rotation_range=rotation_range_slider.value,  # Define rota√ß√£o
                    width_shift_range=width_shift_range_slider.value,  # Define deslocamento horizontal
                    height_shift_range=height_shift_range_slider.value,  # Define deslocamento vertical
                    zoom_range=zoom_range_slider.value,  # Define zoom
                    horizontal_flip=horizontal_flip_checkbox.value,  # Define flip horizontal
                    shear_range=shear_range_slider.value,  # Define cisalhamento
                    brightness_range=(brightness_min_slider.value, brightness_max_slider.value),  # Define faixa de brilho
                    fill_mode=fill_mode_dropdown.value  # Define modo de preenchimento
                )

                if train_generator is None:  # Verifica se geradores foram criados
                    raise ValueError("Erro ao criar os geradores. Verifique os logs acima.")  # Lan√ßa erro se falhar

                # Verificar o tamanho das imagens recortadas
                print("\nüìè Verificando o uso de imagens recortadas (ROI)...")  # Inicia verifica√ß√£o de tamanho
                sample_image_path = train_df['filepaths'].iloc[0]  # Pega caminho da primeira imagem
                sample_image = Image.open(sample_image_path)  # Abre imagem de exemplo
                print(f"üìè Tamanho original da primeira imagem recortada (antes do redimensionamento): {sample_image.size} pixels")  # Exibe tamanho original

                # Verificar o tamanho das imagens ap√≥s o carregamento pelo gerador
                images, _ = next(train_generator)  # Obt√©m pr√≥ximo batch do gerador
                print(f"üìè Tamanho das imagens no train_generator (ap√≥s redimensionamento): {images.shape[1:3]} pixels")  # Exibe tamanho ap√≥s gerador

                # Confirmar a quantidade de imagens em cada conjunto
                print("\nüìä Contagem de imagens em cada conjunto de dados (ap√≥s aumenta√ß√£o):")  # Inicia contagem
                print(f"Imagens de Treinamento: {train_generator.samples}")  # Exibe total de treino
                print(f"Imagens de Valida√ß√£o: {valid_generator.samples}")  # Exibe total de valida√ß√£o
                print(f"Imagens de Teste: {test_generator.samples}")  # Exibe total de teste

                print(f"‚úÖ Geradores criados - N√∫mero de classes: {num_classes}")  # Confirma cria√ß√£o dos geradores
                print(f"üöÄ Prosseguindo para o pr√≥ximo passo (after_augmentation)...")  # Confirma pr√≥xima etapa

                # Chamar o callback com os geradores
                after_augmentation(train_generator, valid_generator, test_generator, num_classes)  # Executa callback

            except Exception as e:
                print(f"‚ùå Erro ao criar os geradores ou chamar after_augmentation: {str(e)}")  # Exibe erro
                confirm_augmentation_button.disabled = False  # Reabilita bot√£o de confirma√ß√£o
                reset_augmentation_button.disabled = False  # Reabilita bot√£o de reset

    confirm_augmentation_button.on_click(on_confirm_augmentation)  # Conecta fun√ß√£o ao bot√£o de confirma√ß√£o
    reset_augmentation_button.on_click(on_reset_augmentation)  # Conecta fun√ß√£o ao bot√£o de reset

    # Exibir os widgets
    display(widgets.VBox([  # Exibe interface verticalmente
        widgets.Label("Par√¢metros de Aumenta√ß√£o:"),  # R√≥tulo da interface
        rotation_range_slider, width_shift_range_slider, height_shift_range_slider,  # Sliders de deslocamento
        shear_range_slider, zoom_range_slider, horizontal_flip_checkbox,  # Sliders de transforma√ß√£o
        brightness_min_slider, brightness_max_slider, fill_mode_dropdown,  # Sliders de brilho e preenchimento
        widgets.HBox([confirm_augmentation_button, reset_augmentation_button]),  # Bot√µes em linha horizontal
        augmentation_output  # Widget de sa√≠da
    ]))


# =============================================================================#
# √ÅREA DE CONFIGURA√á√ÉO DE WIDGETS INTERATIVOS
# =============================================================================#

# ============================
# Fun√ß√µes para Configura√ß√£o de Widgets Interativos e dos Pesos das Classes
# ============================

# Fun√ß√£o para configurar a aumenta√ß√£o
def configure_augmentation():  # Define fun√ß√£o para configurar aumenta√ß√£o
    print("üöÄ Configurando aumenta√ß√£o...")  # Exibe mensagem de in√≠cio
    augmentation_output = widgets.Output()  # Cria widget de sa√≠da para logs
    augmentation_params = {}  # Inicializa dicion√°rio para par√¢metros

    # Controles de aumenta√ß√£o
    toggle_augmentation = widgets.ToggleButton(value=False, description='Habilitar Aumenta√ß√£o', button_style='info')  # Bot√£o para habilitar/desabilitar aumenta√ß√£o
    rotation_slider = widgets.FloatSlider(min=0, max=90, value=20, description='Rota√ß√£o:', disabled=True)  # Slider para rota√ß√£o (inicialmente desabilitado)
    horizontal_shift_slider = widgets.FloatSlider(min=0.0, max=0.5, value=0.20, description='Desloc. H:', disabled=True)  # Slider para deslocamento horizontal
    vertical_shift_slider = widgets.FloatSlider(min=0.0, max=0.5, value=0.20, description='Desloc. V:', disabled=True)  # Slider para deslocamento vertical
    shear_slider = widgets.FloatSlider(min=0.0, max=0.5, value=0.20, description='Cisalhamento:', disabled=True)  # Slider para cisalhamento
    zoom_slider = widgets.FloatSlider(min=0.0, max=0.5, value=0.20, description='Zoom:', disabled=True)  # Slider para zoom
    flip_horizontal_toggle = widgets.ToggleButton(value=False, description='Flip Horizontal', disabled=True)  # Bot√£o para flip horizontal
    fill_mode_dropdown = widgets.Dropdown(options=['nearest', 'reflect', 'constant'], value='nearest', description='Modo:', disabled=True)  # Dropdown para modo de preenchimento
    confirm_augmentation_button = widgets.Button(description="Confirmar Aumenta√ß√£o", button_style='success', disabled=True)  # Bot√£o para confirmar aumenta√ß√£o
    reset_augmentation_button = widgets.Button(description="Reset Aumenta√ß√£o", button_style='warning', disabled=True)  # Bot√£o para resetar aumenta√ß√£o

    def on_toggle_augmentation(change):  # Define fun√ß√£o para toggle de aumenta√ß√£o
        is_enabled = change['new']  # Obt√©m novo estado do toggle
        print(f"üîç Toggle Aumenta√ß√£o: {is_enabled}")  # Exibe estado do toggle
        for widget in [rotation_slider, horizontal_shift_slider, vertical_shift_slider, shear_slider, zoom_slider,  # Itera sobre widgets
                       flip_horizontal_toggle, fill_mode_dropdown, confirm_augmentation_button, reset_augmentation_button]:
            widget.disabled = not is_enabled  # Habilita/desabilita widgets conforme toggle
        with augmentation_output:  # Usa widget de sa√≠da
            clear_output(wait=True)  # Limpa sa√≠da anterior
            if is_enabled:  # Verifica se aumenta√ß√£o est√° habilitada
                display(widgets.VBox([  # Exibe interface de par√¢metros
                    widgets.Label("üîß Par√¢metros de aumenta√ß√£o:"),  # R√≥tulo da interface
                    rotation_slider, horizontal_shift_slider, vertical_shift_slider, shear_slider, zoom_slider,  # Sliders de transforma√ß√£o
                    flip_horizontal_toggle, fill_mode_dropdown,  # Controles adicionais
                    widgets.HBox([confirm_augmentation_button, reset_augmentation_button])  # Bot√µes em linha horizontal
                ]))
            else:
                print("üö´ Aumenta√ß√£o desabilitada!")  # Confirma desabilita√ß√£o

    def on_confirm_augmentation(b):  # Define fun√ß√£o para confirmar aumenta√ß√£o
        nonlocal augmentation_params  # Acessa dicion√°rio externo
        print("üîç Bot√£o 'Confirmar Aumenta√ß√£o' clicado!")  # Confirma clique
        augmentation_params = {  # Define par√¢metros de aumenta√ß√£o
            'rotation_range': rotation_slider.value,  # Define rota√ß√£o
            'width_shift_range': horizontal_shift_slider.value,  # Define deslocamento horizontal
            'height_shift_range': vertical_shift_slider.value,  # Define deslocamento vertical
            'shear_range': shear_slider.value,  # Define cisalhamento
            'zoom_range': zoom_slider.value,  # Define zoom
            'horizontal_flip': flip_horizontal_toggle.value,  # Define flip horizontal
            'fill_mode': fill_mode_dropdown.value  # Define modo de preenchimento
        }
        confirm_augmentation_button.disabled = True  # Desabilita bot√£o de confirma√ß√£o
        reset_augmentation_button.disabled = True  # Desabilita bot√£o de reset
        with augmentation_output:  # Usa widget de sa√≠da
            clear_output(wait=True)  # Limpa sa√≠da anterior
            print(f"‚úÖ Aumenta√ß√£o confirmada: {augmentation_params}")  # Exibe par√¢metros confirmados

    def on_reset_augmentation(b):  # Define fun√ß√£o para resetar aumenta√ß√£o
        print("üîç Bot√£o 'Reset Aumenta√ß√£o' clicado!")  # Confirma clique
        rotation_slider.value = 20  # Reseta rota√ß√£o
        horizontal_shift_slider.value = 0.20  # Reseta deslocamento horizontal
        vertical_shift_slider.value = 0.20  # Reseta deslocamento vertical
        shear_slider.value = 0.20  # Reseta cisalhamento
        zoom_slider.value = 0.20  # Reseta zoom
        flip_horizontal_toggle.value = False  # Reseta flip horizontal
        fill_mode_dropdown.value = 'nearest'  # Reseta modo de preenchimento
        confirm_augmentation_button.disabled = False  # Reabilita bot√£o de confirma√ß√£o
        reset_augmentation_button.disabled = False  # Reabilita bot√£o de reset
        with augmentation_output:  # Usa widget de sa√≠da
            clear_output(wait=True)  # Limpa sa√≠da anterior
            print("üîÑ Aumenta√ß√£o resetada.")  # Confirma reset

    toggle_augmentation.observe(on_toggle_augmentation, names='value')  # Conecta toggle √† fun√ß√£o
    confirm_augmentation_button.on_click(on_confirm_augmentation)  # Conecta bot√£o de confirma√ß√£o
    reset_augmentation_button.on_click(on_reset_augmentation)  # Conecta bot√£o de reset

    display(widgets.VBox([toggle_augmentation, augmentation_output]))  # Exibe interface inicial
    return lambda: augmentation_params if toggle_augmentation.value else None  # Retorna fun√ß√£o para obter par√¢metros ou None

# Fun√ß√£o para configurar os pesos das classes
def configure_class_weights(train_generator):  # Define fun√ß√£o para configurar pesos
    print("üöÄ Configurando pesos das classes...")  # Exibe mensagem de in√≠cio
    if train_generator is None:  # Verifica se gerador √© nulo
        print("‚ùå Erro: train_generator √© None!")  # Exibe erro
        return lambda: None  # Retorna fun√ß√£o que retorna None

    weights_output = widgets.Output()  # Cria widget de sa√≠da para logs
    class_labels = train_generator.classes  # Obt√©m r√≥tulos das classes
    classes = np.unique(class_labels)  # Extrai classes √∫nicas
    print(f"üîç Classes detectadas: {classes}")  # Exibe classes detectadas

    # Calcular pesos autom√°ticos
    class_weights_auto = class_weight.compute_class_weight('balanced', classes=classes, y=class_labels)  # Calcula pesos balanceados
    class_weights_dict_auto = dict(enumerate(class_weights_auto))  # Converte pesos em dicion√°rio
    print(f"‚öñÔ∏è Pesos autom√°ticos calculados: {class_weights_dict_auto}")  # Exibe pesos autom√°ticos

    # Bot√µes
    enable_manual_weights_button = widgets.Button(description="Ajuste Manual", button_style='info')  # Bot√£o para ajuste manual
    enable_auto_weights_button = widgets.Button(description="Pesos Autom√°ticos", button_style='primary')  # Bot√£o para pesos autom√°ticos
    disable_weights_button = widgets.Button(description="Sem Pesos", button_style='danger')  # Bot√£o para desabilitar pesos

    # Sliders
    class_weight_sliders = [widgets.FloatSlider(min=0.1, max=10.0, value=class_weights_auto[i], step=0.1,  # Cria sliders para cada classe
                                                description=f'Peso Classe {class_name}:', readout_format='.1f')
                            for i, class_name in enumerate(classes)]
    confirm_weights_button = widgets.Button(description="Confirmar Pesos", button_style='success', disabled=True)  # Bot√£o para confirmar pesos
    reset_weights_button = widgets.Button(description="Reset Pesos", button_style='warning', disabled=True)  # Bot√£o para resetar pesos

    confirmed_class_weights = None  # Inicializa pesos confirmados como None

    def on_enable_manual_weights(b):  # Define fun√ß√£o para ajuste manual
        nonlocal confirmed_class_weights  # Acessa vari√°vel externa
        print("üîç Bot√£o 'Ajuste Manual' clicado!")  # Confirma clique
        confirm_weights_button.disabled = False  # Habilita bot√£o de confirma√ß√£o
        reset_weights_button.disabled = False  # Habilita bot√£o de reset
        enable_manual_weights_button.disabled = True  # Desabilita bot√£o manual
        enable_auto_weights_button.disabled = True  # Desabilita bot√£o autom√°tico
        disable_weights_button.disabled = True  # Desabilita bot√£o sem pesos
        with weights_output:  # Usa widget de sa√≠da
            clear_output(wait=True)  # Limpa sa√≠da anterior
            display(widgets.VBox([  # Exibe interface de ajuste
                widgets.Label("‚öñÔ∏è Ajuste os pesos das classes:"),  # R√≥tulo da interface
                *class_weight_sliders,  # Sliders para pesos
                widgets.HBox([confirm_weights_button, reset_weights_button])  # Bot√µes em linha
            ]))

    def on_enable_auto_weights(b):  # Define fun√ß√£o para pesos autom√°ticos
        nonlocal confirmed_class_weights  # Acessa vari√°vel externa
        print("üîç Bot√£o 'Pesos Autom√°ticos' clicado!")  # Confirma clique
        confirmed_class_weights = class_weights_dict_auto  # Define pesos autom√°ticos
        enable_manual_weights_button.disabled = True  # Desabilita bot√£o manual
        enable_auto_weights_button.disabled = True  # Desabilita bot√£o autom√°tico
        disable_weights_button.disabled = True  # Desabilita bot√£o sem pesos
        with weights_output:  # Usa widget de sa√≠da
            clear_output(wait=True)  # Limpa sa√≠da anterior
            formatted_weights = {k: round(v, 2) for k, v in confirmed_class_weights.items()}  # Formata pesos
            print(f"‚úÖ Pesos autom√°ticos confirmados: {formatted_weights}")  # Exibe pesos confirmados

    def on_disable_weights(b):  # Define fun√ß√£o para desabilitar pesos
        nonlocal confirmed_class_weights  # Acessa vari√°vel externa
        print("üîç Bot√£o 'Sem Pesos' clicado!")  # Confirma clique
        confirmed_class_weights = None  # Define pesos como None
        enable_manual_weights_button.disabled = True  # Desabilita bot√£o manual
        enable_auto_weights_button.disabled = True  # Desabilita bot√£o autom√°tico
        disable_weights_button.disabled = True  # Desabilita bot√£o sem pesos
        with weights_output:  # Usa widget de sa√≠da
            clear_output(wait=True)  # Limpa sa√≠da anterior
            print("‚úÖ Prosseguindo sem pesos de classe.")  # Confirma aus√™ncia de pesos

    def on_confirm_weights(b):  # Define fun√ß√£o para confirmar pesos manuais
        nonlocal confirmed_class_weights  # Acessa vari√°vel externa
        print("üîç Bot√£o 'Confirmar Pesos' clicado!")  # Confirma clique
        confirmed_class_weights = {int(classes[i]): slider.value for i, slider in enumerate(class_weight_sliders)}  # Define pesos manuais
        confirm_weights_button.disabled = True  # Desabilita bot√£o de confirma√ß√£o
        reset_weights_button.disabled = True  # Desabilita bot√£o de reset
        with weights_output:  # Usa widget de sa√≠da
            clear_output(wait=True)  # Limpa sa√≠da anterior
            formatted_weights = {k: round(v, 2) for k, v in confirmed_class_weights.items()}  # Formata pesos
            print(f"‚úÖ Pesos manuais confirmados: {formatted_weights}")  # Exibe pesos confirmados

    def on_reset_weights(b):  # Define fun√ß√£o para resetar pesos
        nonlocal confirmed_class_weights  # Acessa vari√°vel externa
        print("üîç Bot√£o 'Reset Pesos' clicado!")  # Confirma clique
        confirmed_class_weights = None  # Reseta pesos confirmados
        for i, slider in enumerate(class_weight_sliders):  # Itera sobre sliders
            slider.value = class_weights_auto[i]  # Reseta valores para autom√°ticos
        with weights_output:  # Usa widget de sa√≠da
            clear_output(wait=True)  # Limpa sa√≠da anterior
            print("üîÑ Pesos resetados para os valores autom√°ticos.")  # Confirma reset
        confirm_weights_button.disabled = False  # Reabilita bot√£o de confirma√ß√£o
        reset_weights_button.disabled = False  # Reabilita bot√£o de reset

    enable_manual_weights_button.on_click(on_enable_manual_weights)  # Conecta bot√£o manual
    enable_auto_weights_button.on_click(on_enable_auto_weights)  # Conecta bot√£o autom√°tico
    disable_weights_button.on_click(on_disable_weights)  # Conecta bot√£o sem pesos
    confirm_weights_button.on_click(on_confirm_weights)  # Conecta bot√£o de confirma√ß√£o
    reset_weights_button.on_click(on_reset_weights)  # Conecta bot√£o de reset

    display(widgets.VBox([  # Exibe interface inicial
        widgets.HBox([enable_manual_weights_button, enable_auto_weights_button, disable_weights_button]),  # Bot√µes em linha
        weights_output  # Widget de sa√≠da
    ]))
    return lambda: confirmed_class_weights  # Retorna fun√ß√£o para obter pesos confirmados

# Fun√ß√£o para configurar o modelo
def configure_model():  # Define fun√ß√£o para configurar modelo
    print("üöÄ Configurando o modelo...")  # Exibe mensagem de in√≠cio
    model_config_output = widgets.Output()  # Cria widget de sa√≠da para modelo (n√£o usado aqui)
    config_output = widgets.Output()  # Cria widget de sa√≠da para configura√ß√£o

    num_layers_slider = widgets.IntSlider(min=1, max=10, value=3, description='Camadas:')  # Slider para n√∫mero de camadas
    neurons_per_layer_slider = widgets.IntSlider(min=32, max=1024, value=64, description='Neur√¥nios:')  # Slider para neur√¥nios por camada
    dropout_slider = widgets.FloatSlider(min=0.0, max=0.5, value=0.3, description='Dropout:')  # Slider para taxa de dropout
    learning_rate_slider = widgets.FloatSlider(min=0.0001, max=0.1, value=0.001, description='Learning Rate:', readout_format='.4f')  # Slider para taxa de aprendizado
    epochs_slider = widgets.IntSlider(min=1, max=50, value=10, description='√âpocas:')  # Slider para n√∫mero de √©pocas
    global_pooling_toggle = widgets.ToggleButton(value=True, description='Pooling Global')  # Toggle para pooling global
    regularization_toggle = widgets.ToggleButton(value=True, description='Regulariza√ß√£o')  # Toggle para regulariza√ß√£o
    activation_toggle = widgets.ToggleButton(value=True, description='Ativa√ß√£o ReLU')  # Toggle para ativa√ß√£o ReLU
    early_stopping_toggle = widgets.ToggleButton(value=True, description='Early Stopping')  # Toggle para early stopping
    batch_norm_toggle = widgets.ToggleButton(value=True, description='Batch Norm')  # Toggle para normaliza√ß√£o em batch
    optimizer_dropdown = widgets.Dropdown(options=['Adam', 'SGD', 'RMSprop'], value='Adam', description='Otimizador:')  # Dropdown para otimizador
    activation_function_dropdown = widgets.Dropdown(options=['ReLU', 'Leaky ReLU', 'Sigmoid'], value='ReLU', description='Ativa√ß√£o:')  # Dropdown para fun√ß√£o de ativa√ß√£o
    normalization_dropdown = widgets.Dropdown(options=['Batch Normalization', 'Layer Normalization'], value='Batch Normalization', description='Normaliza√ß√£o:')  # Dropdown para normaliza√ß√£o
    use_lr_scheduler_toggle = widgets.ToggleButton(value=False, description='LR Scheduler')  # Toggle para scheduler de taxa de aprendizado
    use_checkpoint_toggle = widgets.ToggleButton(value=False, description='Checkpoint')  # Toggle para checkpoint

    confirm_config_button = widgets.Button(description="Confirmar Configura√ß√£o", button_style='success')  # Bot√£o para confirmar configura√ß√£o
    reset_config_button = widgets.Button(description="Reset Configura√ß√£o", button_style='warning')  # Bot√£o para resetar configura√ß√£o

    config_params = {}  # Inicializa dicion√°rio para par√¢metros

    def on_confirm_config(b):  # Define fun√ß√£o para confirmar configura√ß√£o
        nonlocal config_params  # Acessa dicion√°rio externo
        print("üîç Bot√£o 'Confirmar Configura√ß√£o' clicado!")  # Confirma clique
        config_params = {  # Define par√¢metros de configura√ß√£o
            'num_layers': num_layers_slider.value,  # N√∫mero de camadas
            'neurons_per_layer': neurons_per_layer_slider.value,  # Neur√¥nios por camada
            'dropout_rate': dropout_slider.value,  # Taxa de dropout
            'learning_rate': learning_rate_slider.value,  # Taxa de aprendizado
            'epochs': epochs_slider.value,  # N√∫mero de √©pocas
            'use_global_pooling': global_pooling_toggle.value,  # Uso de pooling global
            'use_regularization': regularization_toggle.value,  # Uso de regulariza√ß√£o
            'use_activation': activation_toggle.value,  # Uso de ativa√ß√£o
            'use_early_stopping': early_stopping_toggle.value,  # Uso de early stopping
            'use_batch_norm': batch_norm_toggle.value,  # Uso de normaliza√ß√£o em batch
            'optimizer': optimizer_dropdown.value,  # Otimizador escolhido
            'activation_function': activation_function_dropdown.value,  # Fun√ß√£o de ativa√ß√£o
            'normalization': normalization_dropdown.value,  # Tipo de normaliza√ß√£o
            'use_lr_scheduler': use_lr_scheduler_toggle.value,  # Uso de scheduler
            'use_checkpoint': use_checkpoint_toggle.value  # Uso de checkpoint
        }
        with config_output:  # Usa widget de sa√≠da
            clear_output(wait=True)  # Limpa sa√≠da anterior
            print(f"‚úÖ Configura√ß√£o do modelo: {config_params}")  # Exibe par√¢metros confirmados

    def on_reset_config(b):  # Define fun√ß√£o para resetar configura√ß√£o
        nonlocal config_params  # Acessa dicion√°rio externo
        print("üîç Bot√£o 'Reset Configura√ß√£o' clicado!")  # Confirma clique
        config_params = {}  # Reseta dicion√°rio de par√¢metros
        num_layers_slider.value = 3  # Reseta n√∫mero de camadas
        neurons_per_layer_slider.value = 64  # Reseta neur√¥nios por camada
        dropout_slider.value = 0.3  # Reseta taxa de dropout
        learning_rate_slider.value = 0.001  # Reseta taxa de aprendizado
        epochs_slider.value = 10  # Reseta n√∫mero de √©pocas
        global_pooling_toggle.value = True  # Reseta pooling global
        regularization_toggle.value = True  # Reseta regulariza√ß√£o
        activation_toggle.value = True  # Reseta ativa√ß√£o
        early_stopping_toggle.value = True  # Reseta early stopping
        batch_norm_toggle.value = True  # Reseta normaliza√ß√£o em batch
        optimizer_dropdown.value = 'Adam'  # Reseta otimizador
        activation_function_dropdown.value = 'ReLU'  # Reseta fun√ß√£o de ativa√ß√£o
        normalization_dropdown.value = 'Batch Normalization'  # Reseta normaliza√ß√£o
        use_lr_scheduler_toggle.value = False  # Reseta scheduler
        use_checkpoint_toggle.value = False  # Reseta checkpoint
        with config_output:  # Usa widget de sa√≠da
            clear_output(wait=True)  # Limpa sa√≠da anterior
            print("üîÑ Configura√ß√£o do modelo resetada.")  # Confirma reset

    confirm_config_button.on_click(on_confirm_config)  # Conecta bot√£o de confirma√ß√£o
    reset_config_button.on_click(on_reset_config)  # Conecta bot√£o de reset

    display(widgets.VBox([  # Exibe interface verticalmente
        widgets.Label("üõ†Ô∏è Configura√ß√£o do modelo:"),  # R√≥tulo da interface
        num_layers_slider, neurons_per_layer_slider, dropout_slider, learning_rate_slider, epochs_slider,  # Sliders de configura√ß√£o
        global_pooling_toggle, regularization_toggle, activation_toggle, early_stopping_toggle, batch_norm_toggle,  # Toggles de op√ß√µes
        optimizer_dropdown, activation_function_dropdown, normalization_dropdown,  # Dropdowns de escolhas
        use_lr_scheduler_toggle, use_checkpoint_toggle,  # Toggles adicionais
        widgets.HBox([confirm_config_button, reset_config_button]),  # Bot√µes em linha horizontal
        config_output  # Widget de sa√≠da
    ]))
    return lambda: config_params  # Retorna fun√ß√£o para obter par√¢metros

# Fun√ß√£o ajustada para integrar tudo
def configure_training_params(train_generator, valid_generator, test_generator, num_classes, roi_coords=None, dataDir=None, image_np=None, train_df=None, valid_df=None, test_df=None, after_weights=None):  # Define fun√ß√£o para integrar configura√ß√£o
    print("üöÄ Iniciando configure_training_params...")  # Exibe mensagem de in√≠cio

    if train_generator is None or valid_generator is None or test_generator is None:  # Verifica se geradores s√£o nulos
        print("‚ùå Erro: Um ou mais geradores s√£o None!")  # Exibe erro
        return  # Sai da fun√ß√£o

    # Configuradores
    get_augmentation_params = configure_augmentation()  # Obt√©m fun√ß√£o para par√¢metros de aumenta√ß√£o
    get_class_weights = configure_class_weights(train_generator)  # Obt√©m fun√ß√£o para pesos das classes
    get_model_config = configure_model()  # Obt√©m fun√ß√£o para configura√ß√£o do modelo

    # Bot√£o final para consolidar tudo
    final_confirm_button = widgets.Button(description="Confirmar Tudo", button_style='success')  # Cria bot√£o de confirma√ß√£o final
    final_output = widgets.Output()  # Cria widget de sa√≠da para logs finais

    def on_final_confirm(b):  # Define fun√ß√£o para confirma√ß√£o final
        print("üîç Bot√£o 'Confirmar Tudo' clicado!")  # Confirma clique
        augmentation_params = get_augmentation_params()  # Obt√©m par√¢metros de aumenta√ß√£o
        class_weights = get_class_weights()  # Obt√©m pesos das classes
        model_config = get_model_config()  # Obt√©m configura√ß√£o do modelo

        config_params = {  # Cria dicion√°rio com par√¢metros consolidados
            'class_weights': class_weights,  # Adiciona pesos das classes
            'augmentation_params': augmentation_params,  # Adiciona par√¢metros de aumenta√ß√£o
            'train_generator': train_generator,  # Adiciona gerador de treino
            'valid_generator': valid_generator,  # Adiciona gerador de valida√ß√£o
            'test_generator': test_generator,  # Adiciona gerador de teste
            'num_classes': num_classes,  # Adiciona n√∫mero de classes
            'roi_coords': roi_coords,  # Adiciona coordenadas da ROI
            'dataDir': dataDir,  # Adiciona diret√≥rio de dados
            'image_np': image_np,  # Adiciona array da imagem
            'train_df': train_df,  # Adiciona DataFrame de treino
            'valid_df': valid_df,  # Adiciona DataFrame de valida√ß√£o
            'test_df': test_df  # Adiciona DataFrame de teste
        }
        config_params.update(model_config)  # Atualiza com configura√ß√£o do modelo

        with final_output:  # Usa widget de sa√≠da
            clear_output(wait=True)  # Limpa sa√≠da anterior
            if class_weights is None:  # Verifica se pesos est√£o ausentes
                print("‚öñÔ∏è Sem pesos de classe.")  # Exibe mensagem de aus√™ncia
            else:
                formatted_weights = {k: round(v, 2) for k, v in class_weights.items()}  # Formata pesos
                print(f"‚öñÔ∏è Pesos confirmados: {formatted_weights}")  # Exibe pesos formatados
            if augmentation_params:  # Verifica se h√° par√¢metros de aumenta√ß√£o
                print(f"üîß Aumenta√ß√£o: {augmentation_params}")  # Exibe par√¢metros de aumenta√ß√£o
            print(f"üõ†Ô∏è Configura√ß√£o completa: {config_params}")  # Exibe configura√ß√£o completa

        if after_weights is not None:  # Verifica se h√° callback
            print("üöÄ Chamando after_weights...")  # Confirma chamada do callback
            after_weights(config_params)  # Executa callback com par√¢metros

    final_confirm_button.on_click(on_final_confirm)  # Conecta bot√£o √† fun√ß√£o
    display(widgets.VBox([final_confirm_button, final_output]))  # Exibe bot√£o e sa√≠da

# Fun√ß√£o after_augmentation ajustada para integrar com o fluxo principal
def after_augmentation(train_generator, valid_generator, test_generator, num_classes, roi_coords=None, train_df=None, valid_df=None, test_df=None):
    print(f"üöÄ after_augmentation chamado com num_classes={num_classes}")  # Exibe mensagem com o n√∫mero de classes usadas no treinamento
    dataDir = '/content/drive/MyDrive/Colab Notebooks/PeneiraDataSetJPG4Partes/'  # Define o caminho para o diret√≥rio de dados
    sample_image_path = get_sample_image_path_from_original(dataDir)  # Fun√ß√£o para obter o caminho de uma imagem amostra
    image_np = np.array(Image.open(sample_image_path))  # Carrega a imagem amostra e converte para array NumPy

    def after_weights(config_params):  # Fun√ß√£o para configurar e iniciar o treinamento ap√≥s a augmenta√ß√£o
        print("‚úÖ after_weights chamado com:", config_params)  # Exibe mensagem com os par√¢metros de configura√ß√£o
        try:
            from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Importa√ß√£o local da fun√ß√£o de augmenta√ß√£o do Keras
            results = []  # Lista para armazenar resultados de acur√°cia e perda
            histories = []  # Lista para armazenar o hist√≥rico de treinamento de cada modelo
            trained_models = {}  # Dicion√°rio para armazenar os modelos treinados
            for model_name in ARCHITECTURES.keys():  # Percorre todas as arquiteturas definidas
                print(f"\nüöÄ Treinando modelo {model_name}...")  # Mensagem indicando o in√≠cio do treinamento do modelo atual
                model_name_result, accuracy, loss, history, model = start_training(
                    architecture_name=model_name,  # Nome da arquitetura
                    num_layers=config_params['num_layers'],  # N√∫mero de camadas da rede
                    neurons_per_layer=[config_params['neurons_per_layer']] * config_params['num_layers'],  # Neur√¥nios por camada
                    dropout_rate=config_params['dropout_rate'],  # Taxa de dropout
                    learning_rate=config_params['learning_rate'],  # Taxa de aprendizado
                    epochs=config_params['epochs'],  # N√∫mero de √©pocas
                    use_global_pooling=config_params['use_global_pooling'],  # Uso de Global Pooling
                    use_regularization=config_params['use_regularization'],  # Regulariza√ß√£o durante o treinamento
                    use_activation=config_params['use_activation'],  # Fun√ß√£o de ativa√ß√£o
                    use_early_stopping=config_params['use_early_stopping'],  # Early stopping para evitar overfitting
                    use_batch_norm=config_params['use_batch_norm'],  # Normaliza√ß√£o em batch
                    optimizer=config_params['optimizer'],  # Otimizador a ser usado
                    activation_function=config_params['activation_function'],  # Fun√ß√£o de ativa√ß√£o das camadas
                    normalization=config_params['normalization'],  # Normaliza√ß√£o de entradas
                    use_lr_scheduler=config_params['use_lr_scheduler'],  # Scheduler da taxa de aprendizado
                    use_checkpoint=config_params['use_checkpoint'],  # Uso de checkpoints no treinamento
                    class_weights_dict=config_params['class_weights'],  # Pesos das classes
                    roi_coords=roi_coords,  # Coordenadas de ROI para treinamento focado
                    dataDir=dataDir,  # Diret√≥rio de dados de entrada
                    image_np=image_np,  # Array NumPy da imagem de entrada
                    train_generator=train_generator,  # Gerador de dados de treinamento
                    valid_generator=valid_generator,  # Gerador de dados de valida√ß√£o
                    test_generator=test_generator,  # Gerador de dados de teste
                    num_classes=num_classes,  # N√∫mero de classes para classifica√ß√£o
                    train_df=train_df,  # DataFrame de treinamento
                    valid_df=valid_df,  # DataFrame de valida√ß√£o
                    test_df=test_df  # DataFrame de teste
                )
                results.append((model_name_result, accuracy, loss, history))  # Adiciona resultados √† lista
                histories.append(history)  # Armazena o hist√≥rico do treinamento
                trained_models[model_name] = model  # Armazena o modelo treinado no dicion√°rio

            # Comparar modelos e salvar resultados usando fun√ß√µes externas
            compare_models(histories, results, test_generator, list(ARCHITECTURES.keys()))  # Compara os modelos treinados
            save_results_to_csv(results, list(ARCHITECTURES.keys()))  # Salva resultados em arquivo CSV
            display_collected_images(augmented_images_data)  # Exibe imagens aumentadas coletadas
            display_collected_actual_vs_predicted(actual_vs_predicted_data)  # Exibe compara√ß√£o real vs. previsto

            # Salvar os modelos treinados
            for model_name, model in trained_models.items():  # Itera sobre os modelos treinados
                if model is not None:
                    model.save(f'/content/drive/MyDrive/Colab Notebooks/{model_name}_modelo_treinado.keras')  # Salva o modelo
                    print(f"‚úÖ Modelo {model_name} salvo com sucesso!")  # Exibe mensagem de sucesso
                else:
                    print(f"‚ö†Ô∏è Modelo {model_name} n√£o foi treinado corretamente.")  # Mensagem de aviso caso o modelo n√£o tenha sido treinado

            print("‚úÖ Treinamento conclu√≠do com sucesso!")  # Mensagem final de sucesso
        except Exception as e:
            print(f"‚ùå Erro em after_weights: {e}")  # Exibe erro em caso de falha
            raise  # Relan√ßa a exce√ß√£o para depura√ß√£o

    # Fun√ß√£o para configurar par√¢metros e iniciar o treinamento principal
    configure_training_params(
        train_generator=train_generator,  # Gerador de treinamento
        valid_generator=valid_generator,  # Gerador de valida√ß√£o
        test_generator=test_generator,  # Gerador de teste
        num_classes=num_classes,  # N√∫mero de classes de sa√≠da
        roi_coords=roi_coords,  # Coordenadas de ROI
        dataDir=dataDir,  # Diret√≥rio de dados
        image_np=image_np,  # Imagem de entrada em formato NumPy
        train_df=train_df,  # DataFrame de treinamento
        valid_df=valid_df,  # DataFrame de valida√ß√£o
        test_df=test_df,  # DataFrame de teste
        after_weights=after_weights  # Chamada da fun√ß√£o after_weights ap√≥s a configura√ß√£o
    )

# ============================
# Fun√ß√µes para Configura√ß√£o de Widgets Interativos e Treinamento
# ============================

# Fun√ß√£o para exibir sliders de configura√ß√£o do modelo
def display_model_config_sliders(train_generator, class_weights_dict, desired_accuracy, desired_loss, roi_coords, dataDir, image_np):    # Monta os sliders e configs pro modelo
    """
    Exibe sliders para configurar os modelos, incluindo:
    - N√∫mero de Camadas
    - Dropout
    - Learning Rate
    - √âpocas
    - Pooling Global
    - Regulariza√ß√£o
    - Camadas de Ativa√ß√£o
    - Early Stopping
    - Batch Normalization
    - Learning Rate Scheduler
    - Model Checkpoint
    - Otimizadores
    - Fun√ß√µes de Ativa√ß√£o
    - Normaliza√ß√£o
    """

    # Fun√ß√£o pra gerar lista de neur√¥nios por camada
    #def generate_neurons_per_layer(num_layers, initial_neurons, decay_factor):    # Calcula os neur√¥nios por camada, diminuindo aos poucos
    #    """
    #    Gera uma lista de neur√¥nios por camada, onde o n√∫mero de neur√¥nios diminui progressivamente.
    #    """
    #    neurons_per_layer = []                                                    # Lista pra guardar os neur√¥nios
    #    for i in range(num_layers):                                               # Passa pelas camadas
    #        neurons = int(initial_neurons * (decay_factor ** i))                  # Faz o c√°lculo com decaimento
    #        neurons_per_layer.append(neurons)                                     # Bota na lista
    #    return neurons_per_layer                                              # Devolve a lista pronta

    # Fun√ß√£o pra mudar cor dos toggles
    def update_toggle_style(toggle):                   # Troca a cor: verde se ligado, vermelho se desligado
        toggle.button_style = 'success' if toggle.value else 'danger'      # Simples: True = verde, False = vermelho

    # Sliders pra mexer nas configs
    num_layers_slider = widgets.IntSlider(min=1, max=10, step=1, value=3, description='N√∫mero de Camadas:')     # Escolhe quantas camadas, de 1 a 10, come√ßa com 3
    neurons_per_layer_slider = widgets.IntSlider(min=32, max=1024, step=32, value=64, description='Neur√¥nios por Camada:')     # Define neur√¥nios iniciais, 32 a 1024, come√ßa com 64
    dropout_slider = widgets.FloatSlider(min=0.0, max=0.5, step=0.1, value=0.3, description='Taxa de Dropout:')    # Ajusta dropout, 0 a 0.5, come√ßa em 0.3
    learning_rate_slider = widgets.FloatSlider(min=0.0001, max=0.1, step=0.0001, value=0.001, description='Learning Rate:', readout_format='.4f')    # Taxa de aprendizado, 0.0001 a 0.1, come√ßa em 0.001
    epochs_slider = widgets.IntSlider(min=1, max=50, step=1, value=10, description='√âpocas:')    # Quantas √©pocas, 1 a 50, come√ßa com 10

    # Toggles pra ligar/desligar
    global_pooling_toggle = widgets.ToggleButton(value=True, description='Pooling Global')     # Pooling global, come√ßa ligado
    regularization_toggle = widgets.ToggleButton(value=True, description='Regulariza√ß√£o L2')    # Regulariza√ß√£o L2, come√ßa ligada
    activation_toggle = widgets.ToggleButton(value=True, description='Ativa√ß√£o ReLU')     # Ativa√ß√£o ReLU, come√ßa ligada
    early_stopping_toggle = widgets.ToggleButton(value=True, description='Early Stopping')    # Early stopping, come√ßa ligado
    batch_norm_toggle = widgets.ToggleButton(value=True, description='Batch Normalization')    # Batch norm, come√ßa ligado

    # Toggles pra scheduler e checkpoint
    use_learning_rate_scheduler = widgets.ToggleButton(      # Scheduler de learning rate
        value=False,                                         # Come√ßa desligado
        description='Usar Learning Rate Scheduler',          # Nome no bot√£o
        tooltip='Ativar/Desativar Learning Rate Scheduler'   # Dica rapidinha
    )
    use_model_checkpoint = widgets.ToggleButton(      # Salvar checkpoints
        value=False,                                  # Come√ßa desligado
        description='Usar Model Checkpoint',          # Nome no bot√£o
        tooltip='Ativar/Desativar Model Checkpoint'   # Dica rapidinha
    )

    # Checkbox pras configs extras
    custom_settings_checkbox = widgets.Checkbox(value=False, description='Habilitar configura√ß√µes personalizadas')    # Libera op√ß√µes avan√ßadas, come√ßa desligada

    # Dropdowns pras coisas avan√ßadas
    optimizer_dropdown = widgets.Dropdown(      # Escolhe otimizador
        options=['Adam', 'SGD', 'RMSprop'],     # Op√ß√µes: Adam, SGD, RMSprop
        value='Adam',                           # Come√ßa com Adam
        description='Otimizador:',              # Nome do lado
        disabled=not custom_settings_checkbox.value    # S√≥ funciona se a checkbox t√° on
    )
    activation_function_dropdown = widgets.Dropdown(      # Escolhe ativa√ß√£o
        options=['ReLU', 'Leaky ReLU', 'Softmax', 'Sigmoid'],    # Op√ß√µes: ReLU, Leaky ReLU, etc
        value='ReLU',                                    # Come√ßa com ReLU
        description='Fun√ß√£o de Ativa√ß√£o:',               # Nome do lado
        disabled=not custom_settings_checkbox.value      # S√≥ funciona se a checkbox t√° on
    )
    normalization_dropdown = widgets.Dropdown(      # Escolhe normaliza√ß√£o
        options=['Batch Normalization', 'Layer Normalization'],    # Op√ß√µes: Batch ou Layer Norm
        value='Batch Normalization',                       # Come√ßa com Batch Norm
        description='Normaliza√ß√£o:',                       # Nome do lado
        disabled=not custom_settings_checkbox.value        # S√≥ funciona se a checkbox t√° on
    )

    # Fun√ß√£o pra liberar os dropdowns
    def update_dropdowns(change):      # Liga ou desliga os dropdowns com base na checkbox
        optimizer_dropdown.disabled = not change['new']    # Otimizador: liberado se checkbox on
        activation_function_dropdown.disabled = not change['new']    # Ativa√ß√£o: liberado se checkbox on
        normalization_dropdown.disabled = not change['new']    # Normaliza√ß√£o: liberado se checkbox on

    custom_settings_checkbox.observe(update_dropdowns, names='value')    # Fica olhando a checkbox pra atualizar os dropdowns

    # Bot√£o pra confirmar
    confirm_config_button = widgets.Button(description="Confirmar Configura√ß√£o", button_style='success')    # Bot√£o verde pra dar o OK

    # O que rola quando clica no bot√£o
    def on_confirm_config(b):      # Fun√ß√£o que dispara ao clicar no bot√£o
        num_layers = num_layers_slider.value    # Pega quantas camadas
        dropout_rate = dropout_slider.value    # Pega o dropout
        learning_rate = learning_rate_slider.value    # Pega a taxa de aprendizado
        epochs = epochs_slider.value    # Pega as √©pocas
        use_global_pooling = global_pooling_toggle.value    # V√™ se pooling t√° on
        use_regularization = regularization_toggle.value    # V√™ se regulariza√ß√£o t√° on
        use_activation = activation_toggle.value    # V√™ se ativa√ß√£o t√° on
        use_early_stopping = early_stopping_toggle.value    # V√™ se early stopping t√° on
        use_batch_norm = batch_norm_toggle.value    # V√™ se batch norm t√° on
        use_lr_scheduler = use_learning_rate_scheduler.value    # V√™ se scheduler t√° on
        use_checkpoint = use_model_checkpoint.value    # V√™ se checkpoint t√° on
        use_custom_settings = custom_settings_checkbox.value    # V√™ se as configs extras t√£o on

        optimizer = optimizer_dropdown.value if use_custom_settings else 'Adam'    # Pega otimizador do dropdown ou usa Adam
        activation_function = activation_function_dropdown.value if use_custom_settings else 'ReLU'    # Pega ativa√ß√£o do dropdown ou usa ReLU
        normalization = normalization_dropdown.value if use_custom_settings else 'Batch Normalization'    # Pega normaliza√ß√£o do dropdown ou usa Batch Norm

        initial_neurons = neurons_per_layer_slider.value    # Pega os neur√¥nios iniciais
        decay_factor = 0.5    # Fator fixo pra diminuir os neur√¥nios
        neurons_per_layer = generate_neurons_per_layer(num_layers, initial_neurons, decay_factor)    # Monta a lista de neur√¥nios

        print("‚úÖ Configura√ß√£o do modelo confirmada:")    # Avisa que deu certo
        print(f"- N√∫mero de Camadas: {num_layers}")    # Mostra as camadas
        print(f"- Neur√¥nios por Camada: {neurons_per_layer}")    # Mostra os neur√¥nios
        print(f"- Taxa de Dropout: {dropout_rate}")    # Mostra o dropout
        print(f"- Learning Rate: {learning_rate:.4f}")    # Mostra o learning rate
        print(f"- √âpocas: {epochs}")    # Mostra as √©pocas
        print(f"- Pooling Global: {'Ativado' if use_global_pooling else 'Desativado'}")    # Pooling on ou off
        print(f"- Regulariza√ß√£o L2: {'Ativada' if use_regularization else 'Desativada'}")    # Regulariza√ß√£o on ou off
        print(f"- Ativa√ß√£o ReLU: {'Ativada' if use_activation else 'Desativada'}")    # ReLU on ou off
        print(f"- Early Stopping: {'Ativado' if use_early_stopping else 'Desativado'}")    # Early stopping on ou off
        print(f"- Batch Normalization: {'Ativado' if use_batch_norm else 'Desativado'}")    # Batch norm on ou off
        print(f"- Learning Rate Scheduler: {'Ativado' if use_lr_scheduler else 'Desativado'}")    # Scheduler on ou off
        print(f"- Model Checkpoint: {'Ativado' if use_checkpoint else 'Desativado'}")    # Checkpoint on ou off
        print(f"- Otimizador: {optimizer}")    # Mostra o otimizador
        print(f"- Fun√ß√£o de Ativa√ß√£o: {activation_function}")    # Mostra a ativa√ß√£o
        print(f"- Normaliza√ß√£o: {normalization}")    # Mostra a normaliza√ß√£o

        confirm_config_button.disabled = True    # Trava o bot√£o pra n√£o clicar de novo

        def after_weights(adjusted_class_weights_dict):    # Fun√ß√£o pra treinar depois de ajustar pesos
            for architecture_name in ARCHITECTURES.keys():    # Passa por cada arquitetura
                print(f"\nüöÄ Iniciando treinamento da arquitetura: {architecture_name}")    # Avisa que vai treinar
                start_training(    # Chama o treino com tudo configurado
                    architecture_name=architecture_name,    # Nome da arquitetura
                    num_layers=num_layers,    # Camadas
                    neurons_per_layer=neurons_per_layer,    # Neur√¥nios
                    dropout_rate=dropout_rate,    # Dropout
                    learning_rate=learning_rate,    # Learning rate
                    epochs=epochs,    # √âpocas
                    use_global_pooling=use_global_pooling,    # Pooling
                    use_regularization=use_regularization,    # Regulariza√ß√£o
                    use_activation=use_activation,    # Ativa√ß√£o
                    use_early_stopping=use_early_stopping,    # Early stopping
                    use_batch_norm=use_batch_norm,    # Batch norm
                    optimizer=optimizer,    # Otimizador
                    activation_function=activation_function,    # Ativa√ß√£o
                    normalization=normalization,    # Normaliza√ß√£o
                    use_lr_scheduler=use_lr_scheduler,    # Scheduler
                    use_checkpoint=use_checkpoint,    # Checkpoint
                    class_weights_dict=adjusted_class_weights_dict,    # Pesos das classes
                    roi_coords=roi_coords,    # Coordenadas da ROI
                    dataDir=dataDir,    # Pasta dos dados
                    image_np=image_np,    # Imagem numpy
                    train_generator=train_generator,    # Gerador de treino
                    valid_generator=None,    # Sem valida√ß√£o por agora
                    test_generator=None    # Sem teste por agora
                )

        print("\n‚öñÔ∏è Ajuste os pesos das classes e clique em Confirmar:")    # Pede pra ajustar os pesos
        configure_training_params(train_generator, roi_coords, dataDir, image_np, after_weights)    # Chama fun√ß√£o pra ajustar e treinar

    confirm_config_button.on_click(on_confirm_config)    # Liga o bot√£o √† fun√ß√£o

    # Observadores pra mudar cor dos toggles
    global_pooling_toggle.observe(lambda change: update_toggle_style(global_pooling_toggle), names='value')    # Olha o toggle de pooling
    regularization_toggle.observe(lambda change: update_toggle_style(regularization_toggle), names='value')    # Olha o toggle de regulariza√ß√£o
    activation_toggle.observe(lambda change: update_toggle_style(activation_toggle), names='value')    # Olha o toggle de ativa√ß√£o
    early_stopping_toggle.observe(lambda change: update_toggle_style(early_stopping_toggle), names='value')    # Olha o toggle de early stopping
    batch_norm_toggle.observe(lambda change: update_toggle_style(batch_norm_toggle), names='value')    # Olha o toggle de batch norm
    use_learning_rate_scheduler.observe(lambda change: update_toggle_style(use_learning_rate_scheduler), names='value')    # Olha o toggle de scheduler
    use_model_checkpoint.observe(lambda change: update_toggle_style(use_model_checkpoint), names='value')    # Olha o toggle de checkpoint

    # Ajusta as cores dos toggles de cara
    update_toggle_style(global_pooling_toggle)    # Colore pooling (verde, t√° ligado)
    update_toggle_style(regularization_toggle)    # Colore regulariza√ß√£o (verde, t√° ligado)
    update_toggle_style(activation_toggle)    # Colore ativa√ß√£o (verde, t√° ligado)
    update_toggle_style(early_stopping_toggle)    # Colore early stopping (verde, t√° ligado)
    update_toggle_style(batch_norm_toggle)    # Colore batch norm (verde, t√° ligado)
    update_toggle_style(use_learning_rate_scheduler)    # Colore scheduler (vermelho, t√° desligado)
    update_toggle_style(use_model_checkpoint)    # Colore checkpoint (vermelho, t√° desligado)

    # Monta a interface com tudo na ordem
    config_box = widgets.VBox([    # Joga tudo numa caixa vertical
        num_layers_slider,    # Slider de camadas
        neurons_per_layer_slider,    # Slider de neur√¥nios
        dropout_slider,    # Slider de dropout
        learning_rate_slider,    # Slider de learning rate
        epochs_slider,    # Slider de √©pocas
        global_pooling_toggle,    # Toggle de pooling
        regularization_toggle,    # Toggle de regulariza√ß√£o
        activation_toggle,    # Toggle de ativa√ß√£o
        early_stopping_toggle,    # Toggle de early stopping
        batch_norm_toggle,    # Toggle de batch norm
        use_learning_rate_scheduler,    # Toggle de scheduler
        use_model_checkpoint,    # Toggle de checkpoint
        custom_settings_checkbox,    # Checkbox de configs extras
        optimizer_dropdown,    # Dropdown de otimizador
        activation_function_dropdown,    # Dropdown de ativa√ß√£o
        normalization_dropdown,    # Dropdown de normaliza√ß√£o
        confirm_config_button    # Bot√£o de confirmar
    ])
    print("üéØ Ajuste os par√¢metros de configura√ß√£o do modelo e clique em Confirmar Configura√ß√£o:")    # Avisa pra mexer e confirmar
    display(config_box)    # Mostra a interface toda


# =============================================================================#
# √ÅREA DE TREINAMENTO
# =============================================================================#

# ============================
# √Årea de Constru√ß√£o de Modelos
# ============================

# Definir o dicion√°rio de arquiteturas
ARCHITECTURES = {
    "VGG16": VGG16,
    "ResNet50": ResNet50,
    "MobileNet": MobileNet,
    "EfficientNetB0": EfficientNetB0,
    "InceptionV3": InceptionV3,
    "DenseNet121": DenseNet121,
    "Xception": Xception
}

# Habilitar execu√ß√£o eager
tf.config.run_functions_eagerly(True)  # Garante execu√ß√£o imediata das opera√ß√µes TensorFlow

# Mapeamento de strings para fun√ß√µes de ativa√ß√£o do Keras
ACTIVATION_FUNCTIONS = {
    'ReLU': activations.relu,           # Mapeia para ReLU padr√£o
    'Leaky ReLU': activations.relu,     # Placeholder para Leaky ReLU (necessita ajuste para alpha)
    'Sigmoid': activations.sigmoid,     # Mapeia para Sigmoid
    'Softmax': activations.softmax      # Mapeia para Softmax
}

# Fun√ß√£o para construir modelos
# Fun√ß√£o para construir modelos
def build_model(architecture_name, input_shape, num_classes, num_layers, neurons_per_layer, dropout_rate,
                use_global_pooling, use_regularization, use_activation, use_batch_norm,
                activation_function, normalization):  # Define fun√ß√£o para construir o modelo com par√¢metros
    """
    Constr√≥i o modelo com base na arquitetura e par√¢metros configurados.

    Args:
        architecture_name (str): Nome da arquitetura base pr√©-treinada (ex: "MobileNet", "VGG16").
        input_shape (tuple): Formato das imagens de entrada (altura, largura, canais), ex: (224, 224, 3).
        num_classes (int): N√∫mero de classes de sa√≠da para a classifica√ß√£o.
        num_layers (int): N√∫mero de camadas densas personalizadas a serem adicionadas no topo do modelo base.
                          (O valor real de neur√¥nios √© fornecido por 'neurons_per_layer').
        neurons_per_layer (list): Lista contendo o n√∫mero de neur√¥nios para cada camada densa personalizada.
                                  (gerado pela fun√ß√£o generate_neurons_per_layer).
        dropout_rate (float): Taxa de dropout a ser aplicada ap√≥s cada camada densa, se use_regularization for True.
        use_global_pooling (bool): Se True, aplica GlobalAveragePooling2D √† sa√≠da do modelo base.
                                   Se False, aplica Flatten.
        use_regularization (bool): Se True, aplica uma camada de Dropout ap√≥s cada camada densa.
                                   (Nota: Para regulariza√ß√£o L1/L2, seria necess√°rio adicionar 'kernel_regularizer' √†s camadas Dense).
        use_activation (bool): Se True, aplica a fun√ß√£o de ativa√ß√£o especificada ('activation_function') √†s camadas densas.
                               Se False, as camadas densas n√£o ter√£o fun√ß√£o de ativa√ß√£o (ser√£o lineares antes do BN/Dropout).
        use_batch_norm (bool): Se True, aplica BatchNormalization ap√≥s cada camada densa e antes do Dropout.
        activation_function (str): Nome da fun√ß√£o de ativa√ß√£o a ser usada nas camadas densas (ex: "ReLU", "Sigmoid").
                                   Mapeada atrav√©s do dicion√°rio ACTIVATION_FUNCTIONS.
        normalization (str): Tipo de normaliza√ß√£o (ex: "Batch Normalization").
                             (Nota: Atualmente, apenas 'use_batch_norm' controla a aplica√ß√£o de BatchNormalization.
                             Este par√¢metro 'normalization' n√£o est√° sendo usado para selecionar diferentes tipos de normaliza√ß√£o).

    Returns:
        Model: Modelo Keras constru√≠do e pronto para compila√ß√£o e treinamento.
    """
    # Carregar a arquitetura base com pesos pr√©-treinados do ImageNet e sem a camada de classifica√ß√£o original (include_top=False)
    base_model = ARCHITECTURES[architecture_name](
        weights='imagenet',      # Utiliza pesos pr√©-treinados no ImageNet, crucial para transfer learning
        include_top=False,       # Remove a camada de classifica√ß√£o original do modelo base
        input_shape=input_shape  # Define o formato das imagens de entrada
    )
    # Congelar as camadas do modelo base para que seus pesos n√£o sejam atualizados durante o treinamento inicial
    # Isso √© fundamental para o transfer learning, permitindo que apenas o novo "topo" seja treinado.
    base_model.trainable = False

    x = base_model.output  # Obt√©m a sa√≠da do modelo base, que servir√° de entrada para as camadas personalizadas

    # Aplicar Global Average Pooling ou Flattening √† sa√≠da do modelo base
    if use_global_pooling:  # Verifica se o pooling global deve ser usado
        x = GlobalAveragePooling2D()(x)  # Reduz as dimens√µes espaciais de cada mapa de caracter√≠sticas para um √∫nico valor (m√©dia)
    else:  # Caso contr√°rio, usa Flatten
        x = Flatten()(x)  # Achata a sa√≠da do modelo base para um vetor unidimensional, preparando para camadas densas

    # Adicionar camadas densas personalizadas (o "topo" do modelo)
    for i, neurons in enumerate(neurons_per_layer):  # Itera sobre a lista de neur√¥nios definida para cada camada do topo
        # print(f"  Adicionando Camada Densa {i + 1}: {neurons} neur√¥nios")  # Log para depura√ß√£o do n√∫mero de neur√¥nios por camada

        # Obt√©m a fun√ß√£o de ativa√ß√£o do Keras a partir do nome fornecido (string)
        # Se a fun√ß√£o n√£o for encontrada no dicion√°rio ACTIVATION_FUNCTIONS, usa activations.relu como padr√£o.
        activation_fn_keras = ACTIVATION_FUNCTIONS.get(activation_function, activations.relu)

        # Adiciona a camada Densa (totalmente conectada)
        # A fun√ß√£o de ativa√ß√£o √© aplicada apenas se use_activation for True.
        x = Dense(neurons, activation=activation_fn_keras if use_activation else None)(x)

        if use_batch_norm:  # Verifica se a normaliza√ß√£o em lote (Batch Normalization) deve ser aplicada
            x = BatchNormalization()(x)  # Aplica Batch Normalization para estabilizar e acelerar o treinamento, normalizando as ativa√ß√µes da camada anterior

        if use_regularization:  # Verifica se a regulariza√ß√£o (aqui, controlando o Dropout) deve ser aplicada
            x = Dropout(dropout_rate)(x)  # Aplica Dropout, que zera aleatoriamente uma fra√ß√£o (dropout_rate) das unidades de entrada durante o treinamento para reduzir o overfitting

    # Camada de sa√≠da para classifica√ß√£o
    # A fun√ß√£o de ativa√ß√£o 'softmax' √© usada para classifica√ß√£o multiclasse,
    # convertendo as sa√≠das da camada em um vetor de probabilidades para cada classe.
    predictions = Dense(num_classes, activation='softmax')(x)

    # Criar o modelo final
    # O modelo √© definido pela entrada do modelo base (base_model.input) e pelas sa√≠das das camadas personalizadas (predictions)
    model = Model(inputs=base_model.input, outputs=predictions)

    return model  # Retorna o modelo Keras constru√≠do

# ============================
# √Årea de para treinar e avaliar o modelo
# ============================

# Adicionar fun√ß√£o visualize_clusters
def visualize_clusters(model, test_generator, model_name, n_components):
    """
    Visualiza os clusters de features extra√≠das do modelo em 2D ou 3D usando PCA.

    Args:
        model: Modelo treinado.
        test_generator: Gerador de dados de teste.
        model_name (str): Nome do modelo.
        n_components (int): N√∫mero de componentes (2 ou 3) para a redu√ß√£o de dimensionalidade.
    """
    # Extrair features do modelo
    intermediate_layer_model = Model(inputs=model.input, outputs=model.layers[-2].output)  # Cria modelo intermedi√°rio at√© a pen√∫ltima camada
    features = intermediate_layer_model.predict(test_generator, verbose=0)  # Extrai features do test_generator silenciosamente
    labels = test_generator.classes  # Obt√©m as classes verdadeiras do gerador
    class_indices = test_generator.class_indices  # Obt√©m o mapeamento de classes
    class_names = {v: k for k, v in class_indices.items()}  # Inverte o dicion√°rio para mapear √≠ndices a nomes

    # Reduzir dimensionalidade com PCA
    reducer = PCA(n_components=n_components)  # Inicializa PCA com n√∫mero de componentes especificado
    reduced_features = reducer.fit_transform(features)  # Aplica PCA para reduzir dimensionalidade

    # Calcular a vari√¢ncia explicada por cada componente
    explained_variance_ratio = reducer.explained_variance_ratio_  # Obt√©m propor√ß√£o da vari√¢ncia explicada
    total_explained_variance = np.sum(explained_variance_ratio)  # Calcula vari√¢ncia total explicada

    # Configurar a figura para plotagem
    plt.figure(figsize=(10, 8) if n_components == 2 else (12, 10))  # Define tamanho da figura baseado em n_components

    if n_components == 2:  # Caso de visualiza√ß√£o 2D
        scatter = plt.scatter(reduced_features[:, 0], reduced_features[:, 1],  # Plota pontos em 2D
                             c=labels, cmap='tab20', edgecolors='k', linewidths=0.5, s=50)  # Define cores, bordas e tamanho
        plt.title(f"Clusters 2D - {model_name}\n"  # Define t√≠tulo com nome do modelo
                  f"Vari√¢ncia Explicada: {total_explained_variance:.2%}",  # Adiciona vari√¢ncia total
                  fontsize=14, pad=10)  # Configura tamanho e espa√ßamento do t√≠tulo
        plt.xlabel(f"Componente 1 ({explained_variance_ratio[0]:.2%} da vari√¢ncia)", fontsize=12)  # R√≥tulo do eixo X
        plt.ylabel(f"Componente 2 ({explained_variance_ratio[1]:.2%} da vari√¢ncia)", fontsize=12)  # R√≥tulo do eixo Y
        plt.grid(True, linestyle='--', alpha=0.7)  # Adiciona grade com estilo tracejado

        # Adicionar legenda com nomes das classes
        handles, labels_unique = scatter.legend_elements()  # Obt√©m elementos da legenda
        legend_labels = [class_names[int(i)] for i in range(len(class_names))]  # Gera r√≥tulos das classes
        plt.legend(handles, legend_labels, title="Classes", loc="best", bbox_to_anchor=(1.05, 1),  # Adiciona legenda
                   borderaxespad=0., fontsize=10)  # Configura posi√ß√£o e tamanho da legenda

    else:  # n_components == 3, caso de visualiza√ß√£o 3D
        ax = plt.axes(projection='3d')  # Cria eixo 3D
        scatter = ax.scatter(reduced_features[:, 0], reduced_features[:, 1], reduced_features[:, 2],  # Plota pontos em 3D
                            c=labels, cmap='tab20', edgecolors='k', linewidths=0.5, s=50)  # Define cores, bordas e tamanho
        ax.set_title(f"Clusters 3D - {model_name}\n"  # Define t√≠tulo com nome do modelo
                     f"Vari√¢ncia Explicada: {total_explained_variance:.2%}",  # Adiciona vari√¢ncia total
                     fontsize=14, pad=10)  # Configura tamanho e espa√ßamento do t√≠tulo
        ax.set_xlabel(f"Componente 1 ({explained_variance_ratio[0]:.2%} da vari√¢ncia)", fontsize=12)  # R√≥tulo do eixo X
        ax.set_ylabel(f"Componente 2 ({explained_variance_ratio[1]:.2%} da vari√¢ncia)", fontsize=12)  # R√≥tulo do eixo Y
        ax.set_zlabel(f"Componente 3 ({explained_variance_ratio[2]:.2%} da vari√¢ncia)", fontsize=12)  # R√≥tulo do eixo Z
        ax.grid(True, linestyle='--', alpha=0.7)  # Adiciona grade com estilo tracejado

        # Adicionar legenda com nomes das classes
        handles, labels_unique = scatter.legend_elements()  # Obt√©m elementos da legenda
        legend_labels = [class_names[int(i)] for i in range(len(class_names))]  # Gera r√≥tulos das classes
        ax.legend(handles, legend_labels, title="Classes", loc="best", bbox_to_anchor=(1.05, 1),  # Adiciona legenda
                  borderaxespad=0., fontsize=10)  # Configura posi√ß√£o e tamanho da legenda

    plt.tight_layout()  # Ajusta layout para evitar sobreposi√ß√£o
    plt.show()  # Exibe o gr√°fico

# Fun√ß√£o para treinar e avaliar o modelo
def train_and_evaluate_model(
    model, model_name, train_generator, valid_generator, test_generator, dataDir,
    learning_rate, epochs, roi_coords, image_np, roi_path, class_weights_dict, optimizer=None, callbacks=None
):
    """
    Treina e avalia o modelo fornecido.
    Exibe a imagem original com a ROI selecionada e as m√©tricas de acur√°cia e loss.

    Args:
        model: Modelo a ser treinado.
        model_name: Nome do modelo.
        train_generator: Gerador de dados de treinamento.
        valid_generator: Gerador de dados de valida√ß√£o.
        test_generator: Gerador de dados de teste.
        dataDir: Diret√≥rio dos dados.
        learning_rate: Taxa de aprendizado (usado se optimizer n√£o for fornecido).
        epochs: N√∫mero de √©pocas.
        roi_coords: Coordenadas da ROI.
        image_np: Imagem original como array NumPy.
        roi_path: Caminho onde a ROI foi salva.
        class_weights_dict: Pesos das classes.
        optimizer: Otimizador configurado (opcional, padr√£o √© Adam).
        callbacks: Lista de callbacks (opcional, padr√£o √© EarlyStopping).
    """

    # Depura√ß√£o: Exibe os primeiros caminhos das imagens recortadas
    print("üìã Verificando caminhos das imagens de treinamento (recortadas):")
    for index, row in train_df.head(5).iterrows():  # Exibe os 5 primeiros caminhos
        print(f" - {row['filepaths']}")
    print("üìã Verificando caminhos das imagens de valida√ß√£o (recortadas):")
    for index, row in valid_df.head(5).iterrows():
        print(f" - {row['filepaths']}")
    print("üìã Verificando caminhos das imagens de teste (recortadas):")
    for index, row in test_df.head(5).iterrows():
        print(f" - {row['filepaths']}")

    # Configurar o otimizador (usar o fornecido ou criar um padr√£o com learning_rate)
    if optimizer is None:
        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)
    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])


    # Configurar o otimizador (usar o fornecido ou criar um padr√£o com learning_rate)
    if optimizer is None:  # Verifica se o otimizador foi fornecido # Verifica se otimizador √© None
        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)  # Cria um otimizador Adam com a taxa de aprendizado # Cria Adam padr√£o
    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])  # Compila o modelo com otimizador, perda e m√©tricas # Configura modelo para treinamento

    # Configurar callbacks (usar os fornecidos ou padr√£o com EarlyStopping)
    if callbacks is None:  # Verifica se callbacks foram fornecidos # Verifica se callbacks √© None
        callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)]  # Define EarlyStopping como padr√£o # Cria callback padr√£o

    # Treinar o modelo com o n√∫mero de √©pocas escolhido
    print(f"Treinando o modelo {model_name} com os seguintes par√¢metros:")  # Exibe mensagem de in√≠cio de treinamento # Mostra in√≠cio do treinamento
    print(f"- Learning Rate: {learning_rate}")  # Mostra a taxa de aprendizado # Exibe taxa de aprendizado
    print(f"- Epochs: {epochs}")  # Mostra o n√∫mero de √©pocas # Exibe n√∫mero de √©pocas

    # Continuar com o treinamento
    #for arch, model in models.items():
    #    print(f"\nüèãÔ∏è‚Äç‚ôÇÔ∏è Treinando modelo: {arch}")
    #    model.compile(
    #        optimizer=config_params['optimizer'],
    #        loss='categorical_crossentropy',
    #        metrics=['accuracy']
    #    )

    history = model.fit(
        train_generator,
        validation_data=valid_generator,
        epochs=epochs,
        #epochs=config_params['epochs'],
        class_weight=class_weights_dict,  # Passar os pesos das classes aqui
        callbacks=callbacks,  # Usar os callbacks configurados
        verbose=1
    )

    # Avalia√ß√£o no conjunto de teste
    loss, accuracy = model.evaluate(test_generator, verbose=1)

    # Coletar imagens aumentadas do conjunto de treinamento
    print(f"\nüì∏ Coletando imagens aumentadas do conjunto de treinamento para {model_name}...")
    #augmented_images_data.update(collect_images(train_generator, model_name))
    augmented_images_data.update(collect_images(train_df, model_name))

    # Coletar compara√ß√µes de imagens reais com predi√ß√µes no conjunto de teste
    print(f"\nüîç Coletando compara√ß√µes de predi√ß√µes para {model_name}...")
    #actual_vs_predicted_data.update(collect_actual_vs_predicted(model, test_generator, model_name))
    actual_vs_predicted_data[model_name] = collect_actual_vs_predicted(model, test_df, test_generator, model_name)

    # Carregar a imagem recortada
    roi_image = Image.open(roi_path)
    roi_image_np = np.array(roi_image)

    # Exibir a imagem original com a ROI destacada e a imagem recortada
    plt.figure(figsize=(12, 6))

    # Subplot 1: Imagem original com a ROI destacada
    plt.subplot(1, 2, 1)
    plt.imshow(image_np)
    plt.title("Imagem Original com ROI Selecionada")
    # Desenhar a ROI na imagem
    x1, y1, x2, y2 = roi_coords
    rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, edgecolor='red', linewidth=2, fill=False, linestyle='--')
    plt.gca().add_patch(rect)
    plt.axis('off')  # Desativar eixos

    # Subplot 2: Imagem recortada (ROI)
    plt.subplot(1, 2, 2)
    plt.imshow(roi_image_np)
    plt.title("Imagem Recortada (ROI)")
    plt.axis('off')  # Desativar eixos

    plt.suptitle(f"Resultados do Treinamento - {model_name}\nAcur√°cia: {accuracy:.2f} | Loss: {loss:.4f}", fontsize=14)
    plt.tight_layout()
    plt.show()

    # Visualizar clusters 2D e 3D (mantido como opcional)
    #visualize_clusters(model, test_generator, model_name, n_components=2)
    #visualize_clusters(model, test_generator, model_name, n_components=3)

    return model_name, accuracy, loss, history

# ============================
# Fun√ß√µes para Configura√ß√£o de Inicio do Treinamento
# ============================

# Inicia o treinamento dos modelos com os par√¢metros configurados
def start_training(  # Define a fun√ß√£o start_training para iniciar o treinamento dos modelos
    config_params,  # Adicionado para acessar config_params['batch_size'] e outros par√¢metros
    architecture_name, num_layers, neurons_per_layer, dropout_rate, learning_rate, epochs, use_global_pooling,  # Par√¢metros de arquitetura e hiperpar√¢metros do modelo
    use_regularization, use_activation, use_early_stopping, use_batch_norm, optimizer, activation_function,  # Flags e configura√ß√µes adicionais do modelo
    normalization, use_lr_scheduler, use_checkpoint, class_weights_dict, roi_coords, dataDir, image_np,  # Configura√ß√µes de normaliza√ß√£o, callbacks, pesos e dados
    train_generator, valid_generator, test_generator, num_classes, train_df, valid_df, test_df, decay_factor=0.8,  # Geradores, n√∫mero de classes, DataFrames e fator de decaimento
    #batch_size=32  # Adicionado batch_size como par√¢metro expl√≠cito com valor padr√£o 32
):  # Fecha a defini√ß√£o dos par√¢metros da fun√ß√£o

    """
    Inicia o treinamento dos modelos com os par√¢metros configurados.

    Args:
        config_params (dict): Dicion√°rio com os par√¢metros de configura√ß√£o, incluindo batch_size.
        architecture_name (str): Nome da arquitetura (ex.: "VGG16").
        num_layers (int): N√∫mero de camadas densas.
        neurons_per_layer (list): N√∫mero de neur√¥nios em cada camada densa.
        dropout_rate (float): Taxa de dropout.
        learning_rate (float): Taxa de aprendizado.
        epochs (int): N√∫mero de √©pocas.
        use_global_pooling (bool): Se deve usar pooling global.
        use_regularization (bool): Se deve usar regulariza√ß√£o.
        use_activation (bool): Se deve usar fun√ß√µes de ativa√ß√£o.
        use_early_stopping (bool): Se deve usar parada antecipada.
        use_batch_norm (bool): Se deve usar normaliza√ß√£o em lote.
        optimizer (str): Otimizador a ser usado.
        activation_function (str): Fun√ß√£o de ativa√ß√£o.
        normalization (str): Tipo de normaliza√ß√£o.
        use_lr_scheduler (bool): Se deve usar agendador de taxa de aprendizado.
        use_checkpoint (bool): Se deve usar checkpoint para salvar o melhor modelo.
        class_weights_dict (dict): Dicion√°rio de pesos das classes.
        roi_coords (tuple): Coordenadas da ROI (x1, y1, x2, y2).
        dataDir (str): Diret√≥rio dos dados.
        image_np (ndarray): Imagem em formato numpy.
        train_generator: Gerador de dados de treinamento.
        valid_generator: Gerador de dados de valida√ß√£o.
        test_generator: Gerador de dados de teste.
        num_classes (int): N√∫mero de classes.
        train_df (DataFrame): DataFrame de treinamento.
        valid_df (DataFrame): DataFrame de valida√ß√£o.
        test_df (DataFrame): DataFrame de teste.
        decay_factor (float): Fator de decaimento para os neur√¥nios por camada.

    Returns:
        tuple: (model_name, accuracy, loss, history, model)
    """
    # Definir o input_shape com base no target_size
    # O target_size foi ajustado em on_roi_confirmed como (altura, largura)
    # O input_shape deve ser (altura, largura, 3) para corresponder ao target_size do gerador
    input_shape = (config_params['target_size'][0], config_params['target_size'][1], 3)  # Ex.: (654, 1301, 3)
    print(f"‚úÖ Usando input_shape baseado no target_size para {architecture_name}: {input_shape}")

    # Verifica se os geradores est√£o presentes e compat√≠veis
    if train_generator is None or valid_generator is None or test_generator is None:  # Verifica se algum dos geradores √© None
        raise ValueError(f"‚ùå Geradores n√£o fornecidos para {architecture_name}. Forne√ßa train_generator, valid_generator e test_generator.")  # Levanta erro se geradores n√£o forem fornecidos
    if train_generator.target_size != (input_shape[0], input_shape[1]):  # Compara o target_size do train_generator com o input_shape
        raise ValueError(f"‚ùå target_size do train_generator ({train_generator.target_size}) n√£o corresponde ao input_shape ({input_shape}). Ajuste o target_size em augment_data.")  # Levanta erro se houver incompatibilidade
    if valid_generator.target_size != (input_shape[0], input_shape[1]):  # Compara o target_size do valid_generator com o input_shape
        raise ValueError(f"‚ùå target_size do valid_generator ({valid_generator.target_size}) n√£o corresponde ao input_shape ({input_shape}). Ajuste o target_size em augment_data.")  # Levanta erro se houver incompatibilidade
    if test_generator.target_size != (input_shape[0], input_shape[1]):  # Compara o target_size do test_generator com o input_shape
        raise ValueError(f"‚ùå target_size do test_generator ({test_generator.target_size}) n√£o corresponde ao input_shape ({input_shape}). Ajuste o target_size em augment_data.")  # Levanta erro se houver incompatibilidade
    print(f"‚úÖ Geradores validados com target_size compat√≠vel: {train_generator.target_size}")  # Confirma que os geradores est√£o alinhados com o input_shape

    # Gera lista de neur√¥nios por camada com decaimento progressivo
    neurons_per_layer_list = generate_neurons_per_layer(num_layers, neurons_per_layer[0], decay_factor)  # Gera lista de neur√¥nios por camada com decaimento
    print(f"üìè Lista de neur√¥nios por camada para {architecture_name}: {neurons_per_layer_list}")  # Exibe a lista de neur√¥nios gerada

    # Constru√ß√£o do modelo
    try:  # Inicia um bloco try para capturar exce√ß√µes durante a constru√ß√£o do modelo
        # Verifica se ARCHITECTURES est√° dispon√≠vel globalmente
        if 'ARCHITECTURES' not in globals():
            raise ValueError("üö´ Dicion√°rio ARCHITECTURES n√£o est√° definido! Certifique-se de que ele foi inicializado em train_and_evaluate.")

        # Verifica se a arquitetura est√° dispon√≠vel em ARCHITECTURES
        if architecture_name not in ARCHITECTURES:
            raise ValueError(f"‚ùå Arquitetura {architecture_name} n√£o encontrada em ARCHITECTURES: {list(ARCHITECTURES.keys())}")

        model = build_model(  # Chama a fun√ß√£o build_model para construir o modelo
            architecture_name=architecture_name,  # Passa o nome da arquitetura (ex.: VGG16, ResNet50)
            input_shape=input_shape,  # Passa o formato de entrada calculado a partir da ROI
            num_classes=num_classes,  # Passa o n√∫mero de classes para a camada de sa√≠da
            num_layers=num_layers,  # Passa o n√∫mero de camadas densas
            neurons_per_layer=neurons_per_layer_list,  # Passa a lista de neur√¥nios por camada
            dropout_rate=dropout_rate,  # Passa a taxa de dropout
            use_global_pooling=use_global_pooling,  # Passa a flag de pooling global
            use_regularization=use_regularization,  # Passa a flag de regulariza√ß√£o
            use_activation=use_activation,  # Passa a flag de ativa√ß√£o
            use_batch_norm=use_batch_norm,  # Passa a flag de normaliza√ß√£o em lote
            activation_function=activation_function,  # Passa a fun√ß√£o de ativa√ß√£o escolhida
            normalization=normalization  # Passa o tipo de normaliza√ß√£o
        )  # Constr√≥i o modelo com os par√¢metros fornecidos
        print(f"‚úÖ Modelo {architecture_name} constru√≠do com sucesso!")  # Confirma que o modelo foi constru√≠do com sucesso
    except Exception as e:  # Captura qualquer exce√ß√£o que ocorra na constru√ß√£o do modelo
        print(f"üö´ Erro ao construir o modelo {architecture_name}: {str(e)}")  # Exibe mensagem de erro com detalhes da exce√ß√£o
        raise  # Relan√ßa a exce√ß√£o para tratamento externo

    # Configura√ß√£o do otimizador
    optimizer = optimizer.lower()  # Converte o nome do otimizador para letras min√∫sculas
    if optimizer == 'adam':  # Verifica se o otimizador escolhido √© Adam
        opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)  # Configura o otimizador Adam com a taxa de aprendizado
    elif optimizer == 'sgd':  # Verifica se o otimizador escolhido √© SGD
        opt = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)  # Configura o SGD com taxa de aprendizado e momentum
    elif optimizer == 'rmsprop':  # Verifica se o otimizador escolhido √© RMSprop
        opt = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)  # Configura o RMSprop com a taxa de aprendizado
    else:  # Caso o otimizador n√£o seja reconhecido
        opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)  # Usa Adam como otimizador padr√£o
        print(f"‚ö†Ô∏è Otimizador '{optimizer}' n√£o reconhecido. Usando Adam como padr√£o.")  # Exibe aviso sobre o uso do padr√£o

    # Configura√ß√£o dos callbacks
    callbacks = []  # Inicializa uma lista vazia para armazenar os callbacks
    if use_early_stopping:  # Verifica se a parada antecipada est√° ativada
        callbacks.append(tf.keras.callbacks.EarlyStopping(  # Adiciona o callback EarlyStopping √† lista
            monitor='val_loss', patience=50, restore_best_weights=True  # Configura para monitorar val_loss, com paci√™ncia de 20 √©pocas
        ))  # Fecha a configura√ß√£o do EarlyStopping

    # >>> ADICIONE O ReduceLROnPlateau AQUI <<<
    # Adiciona ReduceLROnPlateau para reduzir a taxa de aprendizado quando a val_loss estagnar
    callbacks.append(ReduceLROnPlateau(monitor='val_loss',  # M√©trica a ser monitorada
                                     factor=0.2,      # Fator pelo qual a taxa de aprendizado ser√° reduzida (new_lr = lr * factor)
                                     patience=5,      # N√∫mero de √©pocas sem melhora antes de reduzir a LR
                                     min_lr=0.00001,  # Limite inferior para a taxa de aprendizado
                                     verbose=1))     # Exibe mensagem quando a LR √© atualizada

    #if use_lr_scheduler:  # Verifica se o agendador de taxa de aprendizado est√° ativado
    #    callbacks.append(tf.keras.callbacks.LearningRateScheduler(  # Adiciona o callback LearningRateScheduler √† lista
    #        lambda epoch: learning_rate * (0.9 ** epoch)))  # Define uma fun√ß√£o que reduz a taxa de aprendizado exponencialmente
             # Fecha a configura√ß√£o do LearningRateScheduler
    if use_checkpoint:  # Verifica se o checkpoint est√° ativado
        checkpoint_path = f'/content/drive/MyDrive/Colab Notebooks/{architecture_name}_best_model.keras'  # Define o caminho para salvar o melhor modelo
        callbacks.append(tf.keras.callbacks.ModelCheckpoint(  # Adiciona o callback ModelCheckpoint √† lista
            filepath=checkpoint_path, monitor='val_loss', save_best_only=True, mode='min', verbose=1  # Configura para salvar o melhor modelo baseado em val_loss
        ))  # Fecha a configura√ß√£o do ModelCheckpoint

    # Treinamento do modelo usando os geradores fornecidos
    print(f"‚úÖ Iniciando treinamento da arquitetura {architecture_name} com geradores fornecidos...")  # Informa o in√≠cio do treinamento com geradores
    try:  # Inicia um bloco try para capturar exce√ß√µes durante o treinamento
        model_name, accuracy, loss, history = train_and_evaluate_model(  # Chama a fun√ß√£o de treinamento e avalia√ß√£o
            model=model,  # Passa o modelo constru√≠do
            model_name=architecture_name,  # Passa o nome da arquitetura
            train_generator=train_generator,  # Passa o gerador de treinamento fornecido
            valid_generator=valid_generator,  # Passa o gerador de valida√ß√£o fornecido
            test_generator=test_generator,  # Passa o gerador de teste fornecido
            dataDir=dataDir,  # Passa o diret√≥rio de dados
            learning_rate=learning_rate,  # Passa a taxa de aprendizado
            epochs=epochs,  # Passa o n√∫mero de √©pocas
            roi_coords=roi_coords,  # Passa as coordenadas da ROI
            image_np=image_np,  # Passa a imagem em formato numpy
            roi_path='/content/drive/MyDrive/Colab Notebooks/PeneiraDataSetJPG4Partes/roi_selecionada.jpg',  # Passa o caminho da ROI salva
            class_weights_dict=class_weights_dict,  # Passa o dicion√°rio de pesos das classes
            optimizer=opt,  # Passa o otimizador configurado
            callbacks=callbacks  # Passa a lista de callbacks
        )  # Executa o treinamento e avalia√ß√£o do modelo
    except Exception as e:  # Captura qualquer exce√ß√£o que ocorra durante o treinamento
        print(f"üö´ Erro ao treinar {architecture_name} com geradores: {str(e)}")  # Exibe mensagem de erro com detalhes da exce√ß√£o
        raise  # Relan√ßa a exce√ß√£o para tratamento externo

    print(f"‚úÖ Treinamento da arquitetura {architecture_name} conclu√≠do!")  # Confirma que o treinamento foi conclu√≠do com sucesso
    return model_name, accuracy, loss, history, model  # Retorna o nome do modelo, acur√°cia, perda, hist√≥rico e o modelo treinado

# ============================
# Fun√ß√£o Principal de Treinamento e Exibir Imagens Coletadas
# ============================

# Fun√ß√£o para exibir a estrutura de diret√≥rios de forma hier√°rquica
def print_directory_structure(root_dir):
    """
    Exibe a estrutura de diret√≥rios de forma hier√°rquica, semelhante ao comando 'find' com formata√ß√£o.

    Args:
        root_dir (str): Caminho do diret√≥rio raiz.
    """
    # Fun√ß√£o interna para percorrer e imprimir a estrutura dos diret√≥rios recursivamente
    def _print_tree(current_dir, prefix=""):
        print(f"{prefix}|-{os.path.basename(current_dir)}")  # Exibe o nome do diret√≥rio atual com prefixo hier√°rquico

        # Obt√©m a lista de subdiret√≥rios ordenada alfabeticamente
        subdirs = [d for d in os.listdir(current_dir) if os.path.isdir(os.path.join(current_dir, d))]

        # Itera sobre os subdiret√≥rios encontrados
        for i, subdir in enumerate(sorted(subdirs)):
            subdir_path = os.path.join(current_dir, subdir)  # Obt√©m o caminho completo do subdiret√≥rio

            # Define o novo prefixo para manter a formata√ß√£o hier√°rquica
            new_prefix = prefix + " |" if i < len(subdirs) - 1 else prefix + "  "

            _print_tree(subdir_path, new_prefix)  # Chamada recursiva para percorrer os subdiret√≥rios

    print("\n‚úÖ Estrutura do dataset ap√≥s divis√£o:")  # Exibe um t√≠tulo indicando a estrutura do dataset
    print(" | | | | |")  # Linha inicial para alinhar com o exemplo fornecido

    if os.path.exists(root_dir):  # Verifica se o diret√≥rio raiz existe
        _print_tree(root_dir)  # Chama a fun√ß√£o recursiva para exibir a estrutura
    else:
        print(f"‚ùå Diret√≥rio {root_dir} n√£o encontrado!")  # Exibe uma mensagem de erro caso o diret√≥rio n√£o exista

# ============================
# Fun√ß√£o de Aplicar a ROI √†s imagens de um DataFrame
# ============================

# Importa as bibliotecas necess√°rias
#import cv2  # Biblioteca para processamento de imagens
import os  # Biblioteca para manipula√ß√£o de diret√≥rios e arquivos
import pandas as pd  # Biblioteca para manipula√ß√£o de DataFrames
from pathlib import Path  # Biblioteca para manipula√ß√£o de caminhos de arquivos

# Define a fun√ß√£o que aplica uma Regi√£o de Interesse (ROI) √†s imagens listadas em um DataFrame
def apply_roi_to_dataframe(df, roi_coords, dataDir):
    """Aplica a ROI √†s imagens de um DataFrame e retorna um novo DataFrame com os caminhos atualizados."""

    roi_dir = os.path.join(dataDir, 'roi_images')  # Define o diret√≥rio para salvar as imagens com ROI
    os.makedirs(roi_dir, exist_ok=True)  # Cria o diret√≥rio se ele n√£o existir

    new_rows = []  # Lista para armazenar os novos dados das imagens processadas

    for _, row in df.iterrows():  # Itera sobre cada linha do DataFrame
        image_path = row['image_path']  # Obt√©m o caminho da imagem na coluna 'image_path'
        img = cv2.imread(image_path)  # L√™ a imagem do caminho especificado
        if img is None:  # Verifica se a imagem foi carregada corretamente
            continue  # Se n√£o, pula para a pr√≥xima itera√ß√£o

        x, y, w, h = roi_coords  # Extrai as coordenadas da ROI (Regi√£o de Interesse)
        roi_img = img[y:y+h, x:x+w]  # Recorta a imagem usando as coordenadas da ROI

        roi_image_path = os.path.join(roi_dir, f"roi_{Path(image_path).name}")  # Define o caminho para salvar a nova imagem com ROI
        cv2.imwrite(roi_image_path, roi_img)  # Salva a imagem processada no novo diret√≥rio

        new_rows.append({'image_path': roi_image_path, 'labels': row['labels']})  # Adiciona a nova imagem e suas informa√ß√µes √† lista

    return pd.DataFrame(new_rows)  # Retorna um novo DataFrame contendo os caminhos das imagens com ROI e seus r√≥tulos


# ============================
# Fun√ß√£o Principal de Treinamento
# ============================

import os  # Importa o m√≥dulo os para manipula√ß√£o de arquivos e diret√≥rios
import shutil  # Importa o m√≥dulo shutil para opera√ß√µes de alto n√≠vel com arquivos (como copiar ou remover)
import numpy as np  # Importa o NumPy para opera√ß√µes num√©ricas e manipula√ß√£o de arrays
from PIL import Image  # Importa a classe Image do PIL para manipula√ß√£o de imagens
import ipywidgets as widgets  # Importa o m√≥dulo ipywidgets para criar interfaces interativas no Jupyter
import psutil  # Importa o m√≥dulo psutil para monitoramento de recursos do sistema (CPU, mem√≥ria, etc.)
from IPython.display import display, clear_output  # Importa fun√ß√µes para exibir widgets e limpar sa√≠das no Jupyter
from tqdm.notebook import tqdm  # Importa a vers√£o de tqdm otimizada para notebooks para barras de progresso
import matplotlib.pyplot as plt  # Importa Matplotlib para cria√ß√£o de gr√°ficos e visualiza√ß√µes
from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3, MobileNet, EfficientNetB0, EfficientNetB3, DenseNet121, Xception  # Importa arquiteturas pr√©-treinadas do Keras
import time  # Importa o m√≥dulo time para controle de temporiza√ß√£o (ex.: pausas)

def train_and_evaluate():  # Define a fun√ß√£o principal que gerencia o fluxo de treinamento e avalia√ß√£o
    """Fluxo principal para treinar e avaliar modelos."""
    try:  # Inicia um bloco try para capturar exce√ß√µes durante a execu√ß√£o
        global ARCHITECTURES, augmented_images_data, actual_vs_predicted_data  # Declara vari√°veis globais para acesso em outras fun√ß√µes
        ARCHITECTURES = {  # Define um dicion√°rio com arquiteturas de redes neurais dispon√≠veis
            'VGG16': VGG16,  # Associa o nome 'VGG16' √† classe VGG16 do Keras
            'ResNet50': ResNet50,  # Associa o nome 'ResNet50' √† classe ResNet50
            'InceptionV3': InceptionV3,  # Associa o nome 'InceptionV3' √† classe InceptionV3
            'MobileNet': MobileNet,  # Associa o nome 'MobileNet' √† classe MobileNet
            'EfficientNetB0': EfficientNetB0,  # Associa o nome 'EfficientNetB0' √† classe EfficientNetB0
            'DenseNet121': DenseNet121,  # Associa o nome 'DenseNet121' √† classe DenseNet121
            'Xception': Xception  # Associa o nome 'Xception' √† classe Xception
        }

        augmented_images_data = {}  # Inicializa um dicion√°rio vazio para armazenar dados de imagens aumentadas
        actual_vs_predicted_data = {}  # Inicializa um dicion√°rio vazio para armazenar dados de previs√µes reais vs previstas

        dataDir = '/content/drive/MyDrive/Colab Notebooks/PeneiraDataSetJPG4Partes/'  # Define o caminho do diret√≥rio de dados
        roi_path = '/content/drive/MyDrive/Colab Notebooks/PeneiraDataSetJPG4Partes/roi_selecionada.jpg'  # Define o caminho onde a ROI selecionada ser√° salva

        if not os.path.exists(dataDir):  # Verifica se o diret√≥rio de dados n√£o existe
            os.makedirs(dataDir)  # Cria o diret√≥rio se ele n√£o existir
            print(f"üõ†Ô∏è Diret√≥rio {dataDir} criado com sucesso! Adicione os dados ao diret√≥rio.")  # Informa que o diret√≥rio foi criado
        else:  # Caso o diret√≥rio j√° exista
            print(f"üìÇ Diret√≥rio {dataDir} encontrado! Conte√∫do: {os.listdir(dataDir)}")  # Informa que o diret√≥rio existe e lista seu conte√∫do

        print("üîÑ Dividindo o dataset em treino, valida√ß√£o e teste...")  # Informa que o dataset ser√° dividido
        train_df, valid_df, test_df = load_and_split_dataset(dataDir)  # Chama uma fun√ß√£o para carregar e dividir o dataset em treino, valida√ß√£o e teste
        if train_df is None or valid_df is None or test_df is None:  # Verifica se algum dos DataFrames retornados √© None
            raise ValueError("üö´ Falha ao carregar ou dividir o dataset.")  # Levanta um erro se o carregamento falhar

        def print_directory_structure(data_dir):  # Define uma fun√ß√£o para exibir a estrutura do diret√≥rio
            print("\nüîç Estrutura do diret√≥rio de dados:")  # Imprime um cabe√ßalho para a estrutura do diret√≥rio
            for dir_name in ['train_data', 'valid_data', 'test_data']:  # Itera sobre os subdiret√≥rios esperados
                dir_path = os.path.join(data_dir, dir_name)  # Constr√≥i o caminho completo do subdiret√≥rio
                if os.path.exists(dir_path):  # Verifica se o subdiret√≥rio existe
                    files = os.listdir(dir_path)  # Lista os arquivos no subdiret√≥rio
                    print(f"{dir_name}: {len(files)} arquivos - {files[:5]}...")  # Exibe o nome, n√∫mero de arquivos e uma amostra
                else:  # Caso o subdiret√≥rio n√£o exista
                    print(f"{dir_name}: N√£o encontrado")  # Informa que o subdiret√≥rio n√£o foi encontrado

        print_directory_structure(dataDir)  # Chama a fun√ß√£o para exibir a estrutura do diret√≥rio

        print("\nüñºÔ∏è Carregando uma imagem aleat√≥ria do dataset...")  # Informa que uma imagem ser√° carregada
        sample_image_path = get_sample_image_path_from_original(dataDir)  # Obt√©m o caminho de uma imagem de exemplo do dataset
        image = Image.open(sample_image_path)  # Abre a imagem usando PIL
        image_np = np.array(image)  # Converte a imagem para um array NumPy

        print("\nüìä Preparando os DataFrames com ROI...")  # Informa que os DataFrames est√£o sendo preparados com ROI
        train_df_roi = None  # Inicializa a c√≥pia do DataFrame de treino com ROI como None
        valid_df_roi = None  # Inicializa a c√≥pia do DataFrame de valida√ß√£o com ROI como None
        test_df_roi = None  # Inicializa a c√≥pia do DataFrame de teste com ROI como None

        roi_coords = None  # Inicializa as coordenadas da ROI como None
        num_classes = len(train_df['labels'].unique())  # Calcula o n√∫mero de classes √∫nicas no DataFrame de treino
        print(f"‚úÖ N√∫mero de classes detectadas no dataset: {num_classes}")  # Exibe o n√∫mero de classes detectadas

        config_params = {}  # Inicializa um dicion√°rio vazio para armazenar par√¢metros de configura√ß√£o
        config_completed = False  # Define uma flag indicando que a configura√ß√£o n√£o foi conclu√≠da
        train_generator = None  # Inicializa o gerador de dados de treino como None
        valid_generator = None  # Inicializa o gerador de dados de valida√ß√£o como None
        test_generator = None  # Inicializa o gerador de dados de teste como None

        def monitor_resources(output_widget):  # Define uma fun√ß√£o para monitorar os recursos do sistema
            with output_widget:  # Usa o widget de sa√≠da especificado
                clear_output(wait=True)  # Limpa a sa√≠da anterior no widget, esperando nova sa√≠da
                ram = psutil.virtual_memory()  # Obt√©m informa√ß√µes sobre o uso da mem√≥ria RAM
                disk = psutil.disk_usage('/')  # Obt√©m informa√ß√µes sobre o uso do disco
                cpu = psutil.cpu_percent(interval=1)  # Calcula o percentual de uso da CPU em 1 segundo
                print(f"üíæ RAM: {ram.percent}% usada ({ram.used / 1024**3:.2f}/{ram.total / 1024**3:.2f} GB)")  # Exibe o uso da RAM
                print(f"üíø Disco: {disk.percent}% usado ({disk.used / 1024**3:.2f}/{disk.total / 1024**3:.2f} GB)")  # Exibe o uso do disco
                print(f"üñ•Ô∏è CPU: {cpu}% em uso")  # Exibe o uso da CPU

        def on_roi_confirmed(coords):  # Define a fun√ß√£o chamada quando a ROI √© confirmada
            nonlocal train_df, valid_df, test_df, roi_coords, train_df_roi, valid_df_roi, test_df_roi, config_params  # Declara vari√°veis externas que ser√£o modificadas
            roi_coords = coords  # Armazena as coordenadas da ROI recebidas
            print(f"üìç Coordenadas da ROI selecionada: {roi_coords}")  # Exibe as coordenadas selecionadas

            x1, y1, x2, y2 = roi_coords  # Desempacota as coordenadas da ROI (x1, y1, x2, y2)
            roi_width = x2 - x1  # Calcula a largura da ROI
            roi_height = y2 - y1  # Calcula a altura da ROI
            print(f"üìè Tamanho do recorte: {roi_width}x{roi_height} pixels")  # Exibe o tamanho da ROI

            max_width, max_height = 1080, 1920  # Define as dimens√µes m√°ximas permitidas para a ROI
            if roi_width == max_width and roi_height == max_height:  # Verifica se a ROI corresponde ao tamanho total da imagem
                print(f"‚ÑπÔ∏è ROI selecionada corresponde √† imagem inteira ({max_width}x{max_height}). Prosseguindo com a imagem original.")  # Informa que a imagem inteira ser√° usada
            elif roi_width > max_width or roi_height > max_height:  # Verifica se a ROI excede o tamanho m√°ximo
                print(f"‚ö†Ô∏è Tamanho da ROI ({roi_width}x{roi_height}) excede o limite m√°ximo permitido ({max_width}x{max_height}). Selecione uma regi√£o dentro dos limites.")  # Exibe alerta e solicita nova sele√ß√£o
                return  # Sai da fun√ß√£o se a ROI ultrapassar os limites

            config_params['target_size'] = (roi_height, roi_width)  # Define o tamanho alvo como (altura, largura) para corresponder √† ordem esperada pelos geradores
# >> --- > Parte do Batch Size
            area = roi_width * roi_height  # Calcula a √°rea da ROI
            max_area = 1080 * 1920  # Define a √°rea m√°xima de refer√™ncia (1080x1920)
            base_batch_size = 32  # Define um tamanho de batch base
            calculated_batch_size = max(1, int(base_batch_size * (max_area / area) * 0.5))  # Calcula o batch size ajustado com base na √°rea
            # Ajusta o batch_size para n√£o exceder metade do menor conjunto de dados
            min_dataset_size = min(len(train_df), len(valid_df), len(test_df))  # Obt√©m o menor conjunto de dados dispon√≠vel
            calculated_batch_size = min(calculated_batch_size, max(1, min_dataset_size // 2))  # Garante que o batch_size n√£o exceda metade do menor conjunto
            calculated_batch_size = min(64, calculated_batch_size)  # Limita o batch size m√°ximo a 64
            config_params['auto_batch_size'] = calculated_batch_size  # Armazena o batch size calculado no dicion√°rio de configura√ß√£o
            print(f"üìè Batch size calculado com base na ROI e ajustado pelo menor conjunto ({min_dataset_size}): {calculated_batch_size}")  # Exibe o batch size calculado
# >> --- > Parte do Batch Size
            roi_output_dir = os.path.join(dataDir, 'roi_images')  # Define o diret√≥rio onde as imagens recortadas ser√£o salvas
            if os.path.exists(roi_output_dir):  # Verifica se o diret√≥rio j√° existe
                shutil.rmtree(roi_output_dir)  # Remove o diret√≥rio existente e seu conte√∫do
            os.makedirs(roi_output_dir, exist_ok=True)  # Cria o diret√≥rio, ignorando se j√° existir

            try:  # Inicia um bloco try para capturar erros ao aplicar a ROI
                train_df = apply_roi_to_df(train_df, roi_coords, roi_output_dir)  # Aplica a ROI ao DataFrame de treino
                valid_df = apply_roi_to_df(valid_df, roi_coords, roi_output_dir)  # Aplica a ROI ao DataFrame de valida√ß√£o
                test_df = apply_roi_to_df(test_df, roi_coords, roi_output_dir)  # Aplica a ROI ao DataFrame de teste
            except FileNotFoundError as e:  # Captura erros de arquivo n√£o encontrado
                print(f"‚ùå Erro ao aplicar ROI: {str(e)}. Verifique se os arquivos de imagem est√£o acess√≠veis.")  # Exibe o erro
                return  # Sai da fun√ß√£o se houver erro

            train_df_roi = train_df.copy()  # Cria uma c√≥pia do DataFrame de treino com ROI aplicada
            valid_df_roi = valid_df.copy()  # Cria uma c√≥pia do DataFrame de valida√ß√£o com ROI aplicada
            test_df_roi = test_df.copy()  # Cria uma c√≥pia do DataFrame de teste com ROI aplicada

            total_roi_images = len(train_df) + len(valid_df) + len(test_df)  # Calcula o total de imagens ap√≥s aplicar a ROI
            print(f"\nüìà Total de imagens recortadas (ROI) para treinamento: {total_roi_images}")  # Exibe o total de imagens

            configure_weights(train_df, valid_df, test_df, config_params['target_size'])  # Chama a fun√ß√£o para configurar os pesos das classes

        def configure_weights(train_df, valid_df, test_df, target_size):  # Define a fun√ß√£o para configurar os pesos das classes
            weights_output = widgets.Output()  # Cria um widget de sa√≠da para exibir mensagens relacionadas aos pesos
            enable_manual_weights_button = widgets.Button(description="Habilitar Manualmente", button_style='success')  # Cria um bot√£o para ajuste manual de pesos
            enable_auto_weights_button = widgets.Button(description="Habilitar Automaticamente", button_style='info')  # Cria um bot√£o para pesos autom√°ticos
            disable_weights_button = widgets.Button(description="Desabilitar Pesos", button_style='danger')  # Cria um bot√£o para desativar pesos

            def disable_all_weight_buttons():  # Define uma fun√ß√£o para desabilitar todos os bot√µes de pesos
                enable_manual_weights_button.disabled = True  # Desabilita o bot√£o de ajuste manual
                enable_auto_weights_button.disabled = True  # Desabilita o bot√£o de pesos autom√°ticos
                disable_weights_button.disabled = True  # Desabilita o bot√£o de desativar pesos

            def on_enable_manual_weights(b):  # Define a fun√ß√£o chamada ao clicar no bot√£o de ajuste manual
                with weights_output:  # Usa o widget de sa√≠da para evitar duplicidade
                    clear_output()  # Limpa qualquer sa√≠da anterior no widget
                    print("üîç Bot√£o 'Habilitar pesos manualmente' clicado!")  # Informa que o bot√£o foi clicado
                disable_all_weight_buttons()  # Desabilita todos os bot√µes de pesos
                class_weights = {}  # Inicializa um dicion√°rio vazio para armazenar os pesos das classes
                sliders = []  # Inicializa uma lista vazia para armazenar os sliders de peso
                num_classes_local = len(train_df['labels'].unique())  # Calcula o n√∫mero de classes √∫nicas no DataFrame de treino
                for i in range(num_classes_local):  # Itera sobre o n√∫mero de classes
                    slider = widgets.FloatSlider(min=0.1, max=5.0, step=0.1, value=1.0, description=f'Peso Classe {i}:')  # Cria um slider para cada classe
                    sliders.append(slider)  # Adiciona o slider √† lista
                    display(slider)  # Exibe o slider na interface

                confirm_weights_button = widgets.Button(description="Confirmar pesos", button_style='success')  # Cria um bot√£o para confirmar os pesos
                reset_weights_button = widgets.Button(description="Resetar pesos", button_style='warning')  # Cria um bot√£o para resetar os pesos

                def on_confirm_weights(b):  # Define a fun√ß√£o chamada ao clicar no bot√£o de confirma√ß√£o de pesos
                    for i, slider in enumerate(sliders):  # Itera sobre os sliders
                        class_weights[i] = slider.value  # Armazena o valor do slider no dicion√°rio de pesos
                    with weights_output:  # Usa o widget de sa√≠da para evitar duplicidade
                        clear_output()  # Limpa qualquer sa√≠da anterior no widget
                        print(f"‚úÖ Pesos ajustados manualmente: {class_weights}")  # Exibe os pesos ajustados
                    confirm_weights_button.disabled = True  # Desabilita o bot√£o de confirma√ß√£o
                    reset_weights_button.disabled = True  # Desabilita o bot√£o de reset
                    config_params['class_weights'] = class_weights  # Armazena os pesos no dicion√°rio de configura√ß√£o
                    configure_augmentation(train_df, valid_df, test_df, config_params)  # Chama a fun√ß√£o para configurar a aumenta√ß√£o ap√≥s confirmar os pesos

                def on_reset_weights(b):  # Define a fun√ß√£o chamada ao clicar no bot√£o de reset de pesos
                    for slider in sliders:  # Itera sobre os sliders
                        slider.value = 1.0  # Reseta o valor de cada slider para 1.0
                    with weights_output:  # Usa o widget de sa√≠da para evitar duplicidade
                        clear_output()  # Limpa qualquer sa√≠da anterior no widget
                        print("‚úÖ Pesos manuais restaurados ao valor padr√£o (1.0)!")  # Informa que os pesos foram resetados

                confirm_weights_button.on_click(on_confirm_weights)  # Associa a fun√ß√£o ao clique no bot√£o de confirma√ß√£o
                reset_weights_button.on_click(on_reset_weights)  # Associa a fun√ß√£o ao clique no bot√£o de reset
                display(widgets.HBox([confirm_weights_button, reset_weights_button]))  # Exibe os bot√µes de confirma√ß√£o e reset lado a lado

            def on_enable_auto_weights(b):  # Define a fun√ß√£o chamada ao clicar no bot√£o de pesos autom√°ticos
                with weights_output:  # Usa o widget de sa√≠da para evitar duplicidade
                    clear_output()  # Limpa qualquer sa√≠da anterior no widget
                    print("üîç Bot√£o 'Automaticamente' clicado!")  # Informa que o bot√£o foi clicado
                disable_all_weight_buttons()  # Desabilita todos os bot√µes de pesos
                class_counts = train_df['labels'].value_counts().to_dict()  # Conta a frequ√™ncia de cada classe no DataFrame
                total_samples = len(train_df)  # Calcula o n√∫mero total de amostras no DataFrame
                class_weights_dict = {i: total_samples / (len(class_counts) * count) if count > 0 else 0
                                      for i, count in enumerate(class_counts.values())}  # Calcula os pesos autom√°ticos com base na frequ√™ncia inversa
                with weights_output:  # Usa o widget de sa√≠da para evitar duplicidade
                    clear_output()  # Limpa qualquer sa√≠da anterior no widget
                    print(f"‚úÖ Pesos habilitados automaticamente: {class_weights_dict}")  # Exibe os pesos calculados
                config_params['class_weights'] = class_weights_dict  # Armazena os pesos no dicion√°rio de configura√ß√£o
                configure_augmentation(train_df, valid_df, test_df, config_params)  # Chama a fun√ß√£o para configurar a aumenta√ß√£o ap√≥s confirmar os pesos

            def on_disable_weights(b):  # Define a fun√ß√£o chamada ao clicar no bot√£o de desativar pesos
                with weights_output:  # Usa o widget de sa√≠da para evitar duplicidade
                    clear_output()  # Limpa qualquer sa√≠da anterior no widget
                    print("üîç Bot√£o 'N√£o usar pesos' clicado!")  # Informa que o bot√£o foi clicado
                disable_all_weight_buttons()  # Desabilita todos os bot√µes de pesos
                with weights_output:  # Usa o widget de sa√≠da para evitar duplicidade
                    clear_output()  # Limpa qualquer sa√≠da anterior no widget
                    print("üö´ Pesos desabilitados!")  # Informa que os pesos foram desativados
                config_params['class_weights'] = None  # Define os pesos como None no dicion√°rio de configura√ß√£o
                configure_augmentation(train_df, valid_df, test_df, config_params)  # Chama a fun√ß√£o para configurar a aumenta√ß√£o ap√≥s desativar os pesos

            enable_manual_weights_button.on_click(on_enable_manual_weights)  # Associa a fun√ß√£o ao clique no bot√£o de ajuste manual
            enable_auto_weights_button.on_click(on_enable_auto_weights)  # Associa a fun√ß√£o ao clique no bot√£o de pesos autom√°ticos
            disable_weights_button.on_click(on_disable_weights)  # Associa a fun√ß√£o ao clique no bot√£o de desativar pesos
            with weights_output:  # Usa o widget de sa√≠da para evitar duplicidade
                clear_output()  # Limpa qualquer sa√≠da anterior no widget
                print("‚úÖ Bot√µes de configura√ß√£o de pesos exibidos abaixo:")  # Informa que os bot√µes de pesos est√£o sendo exibidos
                display(widgets.HBox([enable_manual_weights_button, enable_auto_weights_button, disable_weights_button]))  # Exibe os tr√™s bot√µes de pesos lado a lado
            display(weights_output)  # Exibe o widget de sa√≠da para mensagens relacionadas aos pesos

        def configure_augmentation(train_df, valid_df, test_df, config_params):  # Define a fun√ß√£o para configurar a aumenta√ß√£o de dados
            print("üîß Configurando a aumenta√ß√£o de dados...")  # Informa que a configura√ß√£o de aumenta√ß√£o come√ßou
            aug_output = widgets.Output()  # Cria um widget de sa√≠da para mensagens relacionadas √† aumenta√ß√£o
            enable_manual_augmentation_button = widgets.Button(description="Habilitar Aumenta√ß√£o Manualmente", button_style='success')  # Cria um bot√£o para ajuste manual de aumenta√ß√£o
            enable_auto_augmentation_button = widgets.Button(description="Habilitar Aumenta√ß√£o Automaticamente", button_style='info')  # Cria um bot√£o para aumenta√ß√£o autom√°tica
            disable_augmentation_button = widgets.Button(description="Desabilitar Aumenta√ß√£o", button_style='danger')  # Cria um bot√£o para desativar aumenta√ß√£o

            def disable_all_augmentation_buttons():  # Define uma fun√ß√£o para desabilitar todos os bot√µes de aumenta√ß√£o
                enable_manual_augmentation_button.disabled = True  # Desabilita o bot√£o de ajuste manual
                enable_auto_augmentation_button.disabled = True  # Desabilita o bot√£o de aumenta√ß√£o autom√°tica
                disable_augmentation_button.disabled = True  # Desabilita o bot√£o de desativar aumenta√ß√£o

            def on_enable_manual_augmentation(b):  # Define a fun√ß√£o chamada ao clicar no bot√£o de ajuste manual de aumenta√ß√£o
                with aug_output:  # Usa o widget de sa√≠da para evitar duplicidade
                    clear_output()  # Limpa qualquer sa√≠da anterior no widget
                    print("üîç Bot√£o 'Habilitar Aumenta√ß√£o Manualmente' clicado!")  # Informa que o bot√£o foi clicado
                disable_all_augmentation_buttons()  # Desabilita todos os bot√µes de aumenta√ß√£o

                print("üîß Ajuste os par√¢metros de aumenta√ß√£o e clique em Confirmar:")  # Instrui o usu√°rio a ajustar os par√¢metros
                print("Par√¢metros de Aumenta√ß√£o:")  # Exibe um cabe√ßalho para os par√¢metros

                # Cria sliders para os par√¢metros de aumenta√ß√£o
                rotation_slider = widgets.IntSlider(min=0, max=180, step=1, value=20, description="Rota√ß√£o:")  # Slider para rota√ß√£o (0 a 180 graus)
                width_shift_slider = widgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.20, description="Desloc. H:")  # Slider para deslocamento horizontal
                height_shift_slider = widgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.20, description="Desloc. V:")  # Slider para deslocamento vertical
                shear_slider = widgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.20, description="Cisalhamento:")  # Slider para cisalhamento
                zoom_slider = widgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.20, description="Zoom:")  # Slider para zoom
                flip_horizontal_toggle = widgets.Checkbox(value=False, description="Flip Horizontal")  # Checkbox para flip horizontal
                brightness_min_slider = widgets.FloatSlider(min=0.1, max=1.0, step=0.01, value=0.80, description="Brilho M√≠n:")  # Slider para brilho m√≠nimo
                brightness_max_slider = widgets.FloatSlider(min=1.0, max=2.0, step=0.01, value=1.20, description="Brilho M√°x:")  # Slider para brilho m√°ximo
                fill_mode_dropdown = widgets.Dropdown(options=['nearest', 'constant', 'reflect', 'wrap'], value='nearest', description="Modo de Preenchimento:")  # Dropdown para modo de preenchimento

                confirm_augmentation_button = widgets.Button(description="Confirmar", button_style='success')  # Cria um bot√£o para confirmar os par√¢metros de aumenta√ß√£o
                reset_augmentation_button = widgets.Button(description="Resetar", button_style='warning')  # Cria um bot√£o para resetar os par√¢metros

                def on_confirm_augmentation(b):  # Define a fun√ß√£o chamada ao clicar no bot√£o de confirma√ß√£o da aumenta√ß√£o
                    augmentation_params = {  # Cria um dicion√°rio com os par√¢metros de aumenta√ß√£o
                        'rotation_range': rotation_slider.value,  # Armazena o valor de rota√ß√£o
                        'width_shift_range': width_shift_slider.value,  # Armazena o valor de deslocamento horizontal
                        'height_shift_range': height_shift_slider.value,  # Armazena o valor de deslocamento vertical
                        'shear_range': shear_slider.value,  # Armazena o valor de cisalhamento
                        'zoom_range': zoom_slider.value,  # Armazena o valor de zoom
                        'horizontal_flip': flip_horizontal_toggle.value,  # Armazena o valor de flip horizontal
                        'brightness_range': [brightness_min_slider.value, brightness_max_slider.value],  # Armazena o intervalo de brilho
                        'fill_mode': fill_mode_dropdown.value  # Armazena o modo de preenchimento
                    }
                    config_params['augmentation_params'] = augmentation_params  # Armazena os par√¢metros de aumenta√ß√£o no dicion√°rio de configura√ß√£o
                    with aug_output:  # Usa o widget de sa√≠da para evitar duplicidade
                        clear_output()  # Limpa qualquer sa√≠da anterior no widget
                        print(f"‚úÖ Aumenta√ß√£o habilitada manualmente com os seguintes par√¢metros: {augmentation_params}")  # Exibe os par√¢metros confirmados
                    confirm_augmentation_button.disabled = True  # Desabilita o bot√£o de confirma√ß√£o
                    reset_augmentation_button.disabled = True  # Desabilita o bot√£o de reset
                    configure_training_params(train_df, valid_df, test_df, config_params['target_size'])  # Chama a fun√ß√£o para configurar os par√¢metros de treinamento

                def on_reset_augmentation(b):  # Define a fun√ß√£o chamada ao clicar no bot√£o de reset da aumenta√ß√£o
                    rotation_slider.value = 20  # Reseta o valor de rota√ß√£o
                    width_shift_slider.value = 0.20  # Reseta o valor de deslocamento horizontal
                    height_shift_slider.value = 0.20  # Reseta o valor de deslocamento vertical
                    shear_slider.value = 0.20  # Reseta o valor de cisalhamento
                    zoom_slider.value = 0.20  # Reseta o valor de zoom
                    flip_horizontal_toggle.value = False  # Reseta o valor de flip horizontal
                    brightness_min_slider.value = 0.80  # Reseta o valor de brilho m√≠nimo
                    brightness_max_slider.value = 1.20  # Reseta o valor de brilho m√°ximo
                    fill_mode_dropdown.value = 'nearest'  # Reseta o modo de preenchimento
                    with aug_output:  # Usa o widget de sa√≠da para evitar duplicidade
                        clear_output()  # Limpa qualquer sa√≠da anterior no widget
                        print("‚úÖ Par√¢metros de aumenta√ß√£o restaurados aos valores padr√£o!")  # Informa que os par√¢metros foram resetados

                confirm_augmentation_button.on_click(on_confirm_augmentation)  # Associa a fun√ß√£o ao clique no bot√£o de confirma√ß√£o
                reset_augmentation_button.on_click(on_reset_augmentation)  # Associa a fun√ß√£o ao clique no bot√£o de reset

                # Exibe os sliders e bot√µes de confirma√ß√£o/reset
                display(widgets.VBox([
                    rotation_slider, width_shift_slider, height_shift_slider, shear_slider, zoom_slider,
                    flip_horizontal_toggle, brightness_min_slider, brightness_max_slider, fill_mode_dropdown,
                    widgets.HBox([confirm_augmentation_button, reset_augmentation_button])
                ]))

            def on_enable_auto_augmentation(b):  # Define a fun√ß√£o chamada ao clicar no bot√£o de aumenta√ß√£o autom√°tica
                with aug_output:  # Usa o widget de sa√≠da para evitar duplicidade
                    clear_output()  # Limpa qualquer sa√≠da anterior no widget
                    print("üîç Bot√£o 'Habilitar Aumenta√ß√£o Automaticamente' clicado!")  # Informa que o bot√£o foi clicado
                disable_all_augmentation_buttons()  # Desabilita todos os bot√µes de aumenta√ß√£o
                augmentation_params = {  # Define os par√¢metros padr√£o de aumenta√ß√£o
                    'rotation_range': 20,  # Valor padr√£o para rota√ß√£o
                    'width_shift_range': 0.20,  # Valor padr√£o para deslocamento horizontal
                    'height_shift_range': 0.20,  # Valor padr√£o para deslocamento vertical
                    'shear_range': 0.20,  # Valor padr√£o para cisalhamento
                    'zoom_range': 0.20,  # Valor padr√£o para zoom
                    'horizontal_flip': False,  # Valor padr√£o para flip horizontal
                    'brightness_range': [0.80, 1.20],  # Valor padr√£o para intervalo de brilho
                    'fill_mode': 'nearest'  # Valor padr√£o para modo de preenchimento
                }
                config_params['augmentation_params'] = augmentation_params  # Armazena os par√¢metros de aumenta√ß√£o no dicion√°rio de configura√ß√£o
                with aug_output:  # Usa o widget de sa√≠da para evitar duplicidade
                    clear_output()  # Limpa qualquer sa√≠da anterior no widget
                    print(f"‚úÖ Aumenta√ß√£o habilitada automaticamente com os seguintes par√¢metros: {augmentation_params}")  # Exibe os par√¢metros autom√°ticos
                configure_training_params(train_df, valid_df, test_df, config_params['target_size'])  # Chama a fun√ß√£o para configurar os par√¢metros de treinamento

            def on_disable_augmentation(b):  # Define a fun√ß√£o chamada ao clicar no bot√£o de desativar aumenta√ß√£o
                with aug_output:  # Usa o widget de sa√≠da para evitar duplicidade
                    clear_output()  # Limpa qualquer sa√≠da anterior no widget
                    print("üîç Bot√£o 'Desabilitar Aumenta√ß√£o' clicado!")  # Informa que o bot√£o foi clicado
                disable_all_augmentation_buttons()  # Desabilita todos os bot√µes de aumenta√ß√£o
                with aug_output:  # Usa o widget de sa√≠da para evitar duplicidade
                    clear_output()  # Limpa qualquer sa√≠da anterior no widget
                    print("üö´ Aumenta√ß√£o desabilitada!")  # Informa que a aumenta√ß√£o foi desativada
                config_params['augmentation_params'] = None  # Define os par√¢metros de aumenta√ß√£o como None
                configure_training_params(train_df, valid_df, test_df, config_params['target_size'])  # Chama a fun√ß√£o para configurar os par√¢metros de treinamento

            enable_manual_augmentation_button.on_click(on_enable_manual_augmentation)  # Associa a fun√ß√£o ao clique no bot√£o de ajuste manual
            enable_auto_augmentation_button.on_click(on_enable_auto_augmentation)  # Associa a fun√ß√£o ao clique no bot√£o de aumenta√ß√£o autom√°tica
            disable_augmentation_button.on_click(on_disable_augmentation)  # Associa a fun√ß√£o ao clique no bot√£o de desativar aumenta√ß√£o
            with aug_output:  # Usa o widget de sa√≠da para evitar duplicidade
                clear_output()  # Limpa qualquer sa√≠da anterior no widget
                print("‚úÖ Bot√µes de configura√ß√£o de aumenta√ß√£o exibidos abaixo: Habilitar Aumenta√ß√£o Manualmente, Habilitar Aumenta√ß√£o Automaticamente e Desabilitar Aumenta√ß√£o")  # Informa que os bot√µes de aumenta√ß√£o est√£o sendo exibidos
                display(widgets.HBox([enable_manual_augmentation_button, enable_auto_augmentation_button, disable_augmentation_button]))  # Exibe os tr√™s bot√µes de aumenta√ß√£o lado a lado
            display(aug_output)  # Exibe o widget de sa√≠da para mensagens de aumenta√ß√£o

        def configure_training_params(train_df, valid_df, test_df, target_size):  # Define a fun√ß√£o para configurar os par√¢metros de treinamento
            print("üîç Iniciando configura√ß√£o dos par√¢metros de treinamento...")  # Informa que a configura√ß√£o de treinamento come√ßou
            training_output = widgets.Output()  # Cria um widget de sa√≠da para mensagens relacionadas ao treinamento

            if 'ARCHITECTURES' not in globals() or not ARCHITECTURES:  # Verifica se o dicion√°rio ARCHITECTURES est√° definido e n√£o vazio
                raise ValueError("ARCHITECTURES n√£o definido.")  # Levanta um erro se ARCHITECTURES n√£o estiver dispon√≠vel
            print(f"‚ÑπÔ∏è Arquiteturas dispon√≠veis: {list(ARCHITECTURES.keys())}")  # Exibe as arquiteturas dispon√≠veis

            arch_count_slider = widgets.IntSlider(min=1, max=len(ARCHITECTURES), step=1, value=1, description="Qtd Arquiteturas:")  # Cria um slider para escolher a quantidade de arquiteturas
            confirm_count_button = widgets.Button(description="Confirmar Quantidade", button_style='success')  # Cria um bot√£o para confirmar a quantidade
            reset_count_button = widgets.Button(description="Resetar Quantidade", button_style='warning')  # Cria um bot√£o para resetar a quantidade

            def on_reset_count(b):  # Define a fun√ß√£o chamada ao clicar no bot√£o de reset da quantidade
                arch_count_slider.value = 1  # Reseta o valor do slider para 1
                print("‚úÖ Quantidade de arquiteturas restaurada ao padr√£o (1)!")  # Informa que a quantidade foi resetada

            def on_confirm_count(b):  # Define a fun√ß√£o chamada ao clicar no bot√£o de confirma√ß√£o da quantidade
                num_architectures = arch_count_slider.value  # Obt√©m o n√∫mero de arquiteturas escolhidas no slider
                print(f"‚úÖ Quantidade de arquiteturas escolhida: {num_architectures}")  # Exibe a quantidade escolhida
                confirm_count_button.disabled = True  # Desabilita o bot√£o de confirma√ß√£o
                reset_count_button.disabled = True  # Desabilita o bot√£o de reset

                tabs = widgets.Tab()  # Cria um widget de abas para selecionar arquiteturas
                tab_contents = []  # Inicializa uma lista vazia para os conte√∫dos das abas
                selected_architectures = []  # Inicializa uma lista vazia para armazenar as arquiteturas selecionadas
                architecture_options = list(ARCHITECTURES.keys())  # Obt√©m a lista de nomes de arquiteturas dispon√≠veis

                for i in range(num_architectures):  # Itera sobre o n√∫mero de arquiteturas escolhidas
                    selector = widgets.Dropdown(options=architecture_options, value=architecture_options[i % len(architecture_options)], description=f'Arquitetura {i+1}:')  # Cria um dropdown para cada arquitetura
                    tab_contents.append(selector)  # Adiciona o dropdown √† lista de conte√∫dos
                    tabs.children = tab_contents  # Define os conte√∫dos das abas
                    tabs.set_title(i, f'Arquitetura {i+1}')  # Define o t√≠tulo de cada aba

                confirm_tabs_button = widgets.Button(description="Confirmar Arquiteturas", button_style='success')  # Cria um bot√£o para confirmar as arquiteturas
                reset_tabs_button = widgets.Button(description="Resetar Sele√ß√£o", button_style='warning')  # Cria um bot√£o para resetar a sele√ß√£o de arquiteturas

                def on_reset_tabs(b):  # Define a fun√ß√£o chamada ao clicar no bot√£o de reset das abas
                    for i, selector in enumerate(tab_contents):  # Itera sobre os seletores nas abas
                        selector.value = architecture_options[i % len(architecture_options)]  # Reseta cada seletor para o valor padr√£o
                    print("‚úÖ Sele√ß√£o de arquiteturas restaurada ao padr√£o!")  # Informa que a sele√ß√£o foi resetada

                def on_confirm_tabs(b):  # Define a fun√ß√£o chamada ao clicar no bot√£o de confirma√ß√£o das abas
                    selected_architectures.clear()  # Limpa a lista de arquiteturas selecionadas
                    for selector in tab_contents:  # Itera sobre os seletores nas abas
                        selected_architectures.append(selector.value)  # Adiciona o valor selecionado √† lista
                    if len(set(selected_architectures)) != len(selected_architectures):  # Verifica se h√° duplicatas nas sele√ß√µes
                        print("‚ùå Arquiteturas duplicadas detectadas!")  # Informa que h√° duplicatas
                        return  # Sai da fun√ß√£o se houver duplicatas
                    print(f"‚úÖ Arquiteturas selecionadas: {selected_architectures}")  # Exibe as arquiteturas selecionadas
                    confirm_tabs_button.disabled = True  # Desabilita o bot√£o de confirma√ß√£o
                    reset_tabs_button.disabled = True  # Desabilita o bot√£o de reset

                    num_layers_slider = widgets.IntSlider(min=1, max=10, step=1, value=3, description="Num Camadas:")  # Cria um slider para o n√∫mero de camadas
                    neurons_slider = widgets.IntSlider(min=32, max=512, step=32, value=128, description="Neur√¥nios/Camada:")  # Cria um slider para o n√∫mero de neur√¥nios por camada
                    dropout_slider = widgets.FloatSlider(min=0.0, max=0.5, step=0.05, value=0.2, description="Dropout:")  # Cria um slider para a taxa de dropout
                    lr_slider = widgets.FloatSlider(min=0.0001, max=0.01, step=0.0001, value=0.001, description="Learning Rate:")  # Cria um slider para a taxa de aprendizado
                    epochs_slider = widgets.IntSlider(min=1, max=50, step=1, value=10, description="√âpocas:")  # Cria um slider para o n√∫mero de √©pocas
                    optimizer_dropdown = widgets.Dropdown(options=['adam', 'sgd', 'rmsprop'], value='adam', description="Otimizador:")  # Cria um dropdown para escolher o otimizador
                    decay_factor_slider = widgets.FloatSlider(min=0.1, max=1.0, step=0.05, value=0.8, description="Decay Factor:")  # Cria um slider para o fator de decaimento
                    batch_size_slider = widgets.IntSlider(min=1, max=64, step=1, value=config_params.get('auto_batch_size', 32), description="Batch Size:")  # Cria um slider para o tamanho do batch

                    batch_size_mode_toggle = widgets.ToggleButton(  # Cria um bot√£o de altern√¢ncia para o modo de batch size
                        value=True,  # Define o valor inicial como True (modo autom√°tico)
                        description="Batch Size Autom√°tico",  # Define a descri√ß√£o do bot√£o
                        button_style='info',  # Define o estilo visual como 'info' (azul)
                        tooltip="Alternar entre modo autom√°tico e manual para o batch size"  # Define uma dica ao passar o mouse
                    )

                    config_params['batch_size_mode'] = 'auto' if batch_size_mode_toggle.value else 'manual'  # Define o modo inicial do batch size no dicion√°rio de configura√ß√£o
                    batch_size_slider.disabled = batch_size_mode_toggle.value  # Desabilita o slider se o modo for autom√°tico

                    def on_batch_size_mode_change(change):  # Define a fun√ß√£o chamada ao alterar o modo de batch size
                        if change['new']:  # Se o novo valor for True (modo autom√°tico)
                            batch_size_slider.disabled = True  # Desabilita o slider
                            batch_size_slider.value = config_params.get('auto_batch_size', 32)  # Define o valor do slider como o batch size calculado ou padr√£o
                            config_params['batch_size_mode'] = 'auto'  # Atualiza o modo no dicion√°rio de configura√ß√£o
                            print(f"‚úÖ Modo de batch size: Autom√°tico - Valor: {batch_size_slider.value}")  # Informa a mudan√ßa para modo autom√°tico
                        else:  # Se o novo valor for False (modo manual)
                            batch_size_slider.disabled = False  # Habilita o slider
                            config_params['batch_size_mode'] = 'manual'  # Atualiza o modo no dicion√°rio de configura√ß√£o
                            print("‚úÖ Modo de batch size: Manual - Ajuste o slider para definir o valor")  # Informa a mudan√ßa para modo manual

                    batch_size_mode_toggle.observe(on_batch_size_mode_change, names='value')  # Associa a fun√ß√£o ao evento de mudan√ßa no bot√£o de altern√¢ncia

                    confirm_training_button = widgets.Button(description="Confirmar Configura√ß√£o", button_style='success')  # Cria um bot√£o para confirmar a configura√ß√£o
                    reset_training_button = widgets.Button(description="Resetar Configura√ß√£o", button_style='warning')  # Cria um bot√£o para resetar a configura√ß√£o

                    def on_reset_training(b):  # Define a fun√ß√£o chamada ao clicar no bot√£o de reset da configura√ß√£o
                        num_layers_slider.value = 3  # Reseta o n√∫mero de camadas para 3
                        neurons_slider.value = 128  # Reseta o n√∫mero de neur√¥nios para 128
                        dropout_slider.value = 0.2  # Reseta a taxa de dropout para 0.2
                        lr_slider.value = 0.001  # Reseta a taxa de aprendizado para 0.001
                        epochs_slider.value = 10  # Reseta o n√∫mero de √©pocas para 10
                        optimizer_dropdown.value = 'adam'  # Reseta o otimizador para 'adam'
                        decay_factor_slider.value = 0.8  # Reseta o fator de decaimento para 0.8
                        batch_size_mode_toggle.value = True  # Reseta o modo de batch size para autom√°tico
                        batch_size_slider.value = config_params.get('auto_batch_size', 32)  # Reseta o batch size para o valor calculado ou padr√£o
                        batch_size_slider.disabled = True  # Desabilita o slider ao voltar para modo autom√°tico
                        print("‚úÖ Configura√ß√£o de treinamento restaurada aos valores padr√£o!")  # Informa que a configura√ß√£o foi resetada

                    def on_confirm_training(b):  # Define a fun√ß√£o chamada ao clicar no bot√£o de confirma√ß√£o da configura√ß√£o
                        if config_params['batch_size_mode'] == 'auto':  # Verifica se o modo de batch size √© autom√°tico
                            config_params['batch_size'] = config_params.get('auto_batch_size', 32)  # Usa o batch size calculado ou padr√£o
                            print(f"‚úÖ Batch size final (Autom√°tico): {config_params['batch_size']}")  # Exibe o batch size final
                        else:  # Se o modo for manual
                            config_params['batch_size'] = batch_size_slider.value  # Usa o valor definido pelo slider
                            print(f"‚úÖ Batch size final (Manual): {config_params['batch_size']}")  # Exibe o batch size final

                        config_params.update({  # Atualiza o dicion√°rio de configura√ß√£o com os valores escolhidos
                            'num_layers': num_layers_slider.value,  # Adiciona o n√∫mero de camadas
                            'neurons_per_layer': [neurons_slider.value],  # Adiciona o n√∫mero de neur√¥nios por camada como uma lista
                            'dropout_rate': dropout_slider.value,  # Adiciona a taxa de dropout
                            'learning_rate': lr_slider.value,  # Adiciona a taxa de aprendizado
                            'epochs': epochs_slider.value,  # Adiciona o n√∫mero de √©pocas
                            'use_global_pooling': True,  # Define o uso de pooling global como True
                            'use_regularization': True,  # Define o uso de regulariza√ß√£o como True
                            'use_activation': True,  # Define o uso de ativa√ß√£o como True
                            'use_early_stopping': True,  # Define o uso de parada antecipada como True
                            'use_batch_norm': True,  # Define o uso de normaliza√ß√£o por batch como True
                            'optimizer': optimizer_dropdown.value,  # Adiciona o otimizador escolhido
                            'activation_function': 'relu',  # Define a fun√ß√£o de ativa√ß√£o como 'relu'
                            'normalization': 'batch',  # Define o tipo de normaliza√ß√£o como 'batch'
                            'use_lr_scheduler': True,  # Define o uso de agendador de taxa de aprendizado como True
                            'use_checkpoint': True,  # Define o uso de checkpoints como True
                            'selected_architectures': selected_architectures,  # Adiciona as arquiteturas selecionadas
                            'decay_factor': decay_factor_slider.value,  # Adiciona o fator de decaimento
                            'target_size': target_size  # Adiciona o tamanho alvo da ROI
                        })

                        print(f"‚úÖ Configura√ß√£o de treinamento definida: {config_params}")  # Exibe a configura√ß√£o completa
                        confirm_training_button.disabled = True  # Desabilita o bot√£o de confirma√ß√£o
                        reset_training_button.disabled = True  # Desabilita o bot√£o de reset
                        after_augmentation(train_df, valid_df, test_df, config_params['target_size'])  # Chama a fun√ß√£o p√≥s-aumenta√ß√£o

                    confirm_training_button.on_click(on_confirm_training)  # Associa a fun√ß√£o ao clique no bot√£o de confirma√ß√£o
                    reset_training_button.on_click(on_reset_training)  # Associa a fun√ß√£o ao clique no bot√£o de reset
                    display(widgets.VBox([  # Exibe todos os widgets de configura√ß√£o em uma caixa vertical
                        num_layers_slider, neurons_slider, dropout_slider, lr_slider, epochs_slider,  # Sliders para camadas, neur√¥nios, dropout, taxa de aprendizado e √©pocas
                        decay_factor_slider, widgets.HBox([batch_size_mode_toggle, batch_size_slider]),  # Slider de decaimento e bot√£o de altern√¢ncia com slider de batch size
                        optimizer_dropdown, widgets.HBox([confirm_training_button, reset_training_button])  # Dropdown de otimizador e bot√µes de confirma√ß√£o/reset
                    ]))

                confirm_tabs_button.on_click(on_confirm_tabs)  # Associa a fun√ß√£o ao clique no bot√£o de confirma√ß√£o das abas
                reset_tabs_button.on_click(on_reset_tabs)  # Associa a fun√ß√£o ao clique no bot√£o de reset das abas
                display(widgets.VBox([tabs, widgets.HBox([confirm_tabs_button, reset_tabs_button])]))  # Exibe as abas e os bot√µes de confirma√ß√£o/reset

            confirm_count_button.on_click(on_confirm_count)  # Associa a fun√ß√£o ao clique no bot√£o de confirma√ß√£o da quantidade
            reset_count_button.on_click(on_reset_count)  # Associa a fun√ß√£o ao clique no bot√£o de reset da quantidade
            display(widgets.VBox([arch_count_slider, widgets.HBox([confirm_count_button, reset_count_button])]))  # Exibe o slider e os bot√µes de quantidade
            display(training_output)  # Exibe o widget de sa√≠da para mensagens de treinamento

        def after_augmentation(train_df, valid_df, test_df, target_size):  # Define a fun√ß√£o chamada ap√≥s a configura√ß√£o da aumenta√ß√£o
            nonlocal num_classes, train_generator, valid_generator, test_generator  # Declara vari√°veis externas que ser√£o modificadas
            print(f"‚öôÔ∏è Entrou em after_augmentation - num_classes={num_classes}")  # Informa a entrada na fun√ß√£o e o n√∫mero de classes
            total_images = len(train_df) + len(valid_df) + len(test_df)  # Calcula o total de imagens nos DataFrames
            print(f"üìà Total de imagens coletadas: {total_images}")  # Exibe o total de imagens
            print("\nüìä Contagem de imagens em cada conjunto:")  # Imprime um cabe√ßalho para a contagem
            print(f"Imagens de Treinamento: {len(train_df)}")  # Exibe o n√∫mero de imagens de treino
            print(f"Imagens de Valida√ß√£o: {len(valid_df)}")  # Exibe o n√∫mero de imagens de valida√ß√£o
            print(f"Imagens de Teste: {len(test_df)}")  # Exibe o n√∫mero de imagens de teste

            # Criar os geradores de dados antes de prosseguir para o treinamento
            print("üîÑ Criando geradores de dados com base nos DataFrames ajustados...")  # Informa que os geradores est√£o sendo criados
            try:  # Inicia um bloco try para capturar erros ao criar os geradores
                batch_size = config_params.get('batch_size', config_params.get('auto_batch_size', 32))  # Obt√©m o batch_size de config_params, com fallback para auto_batch_size
                train_generator, valid_generator, test_generator, num_classes = augment_data(  # Chama a fun√ß√£o augment_data para criar os geradores e obter o n√∫mero de classes
                    train_df=train_df,  # Passa o DataFrame de treino ajustado
                    valid_df=valid_df,  # Passa o DataFrame de valida√ß√£o ajustado
                    test_df=test_df,  # Passa o DataFrame de teste ajustado
                    target_size=target_size,  # Passa o target_size baseado na ROI
                    batch_size=batch_size,  # Passa o batch_size calculado ou definido
                    rotation_range=config_params.get('augmentation_params', {}).get('rotation_range', 0),
                    width_shift_range=config_params.get('augmentation_params', {}).get('width_shift_range', 0),
                    height_shift_range=config_params.get('augmentation_params', {}).get('height_shift_range', 0),
                    zoom_range=config_params.get('augmentation_params', {}).get('zoom_range', 0),
                    horizontal_flip=config_params.get('augmentation_params', {}).get('horizontal_flip', False),
                    shear_range=config_params.get('augmentation_params', {}).get('shear_range', 0),
                    brightness_range=config_params.get('augmentation_params', {}).get('brightness_range', None),
                    fill_mode=config_params.get('augmentation_params', {}).get('fill_mode', 'nearest')
                )  # Cria os geradores de dados e atualiza o n√∫mero de classes
                print(f"‚úÖ Geradores criados com sucesso: train_generator, valid_generator, test_generator")  # Confirma a cria√ß√£o dos geradores
                print(f"‚úÖ N√∫mero de classes atualizado: {num_classes}")  # Confirma a atualiza√ß√£o do n√∫mero de classes
            except Exception as e:  # Captura qualquer exce√ß√£o que ocorra ao criar os geradores
                print(f"‚ùå Erro ao criar geradores: {str(e)}")  # Exibe mensagem de erro com detalhes da exce√ß√£o
                raise  # Relan√ßa a exce√ß√£o para tratamento externo

            print("üîß Prosseguindo para bot√µes finais...")  # Informa que o fluxo prossegue para os bot√µes finais
            display_final_buttons(config_params, train_df, valid_df, test_df)  # Chama a fun√ß√£o para exibir os bot√µes finais

        def display_final_buttons(config_params, train_df, valid_df, test_df):  # Define a fun√ß√£o para exibir os bot√µes finais
            final_output = widgets.Output()  # Cria um widget de sa√≠da para mensagens finais
            start_training_button = widgets.Button(description="Iniciar Treinamento", button_style='primary')  # Cria um bot√£o para iniciar o treinamento
            reset_all_button = widgets.Button(description="Resetar Todos os Par√¢metros", button_style='danger')  # Cria um bot√£o para resetar todos os par√¢metros

            def on_start_training(b):  # Define a fun√ß√£o chamada ao clicar no bot√£o de iniciar treinamento
                nonlocal config_completed, train_generator, valid_generator, test_generator, num_classes  # Declara vari√°veis externas que ser√£o modificadas
                print("üîç Bot√£o 'Iniciar Treinamento' clicado!")  # Informa que o bot√£o foi clicado

                # Verifica se os geradores est√£o dispon√≠veis antes de prosseguir
                if train_generator is None or valid_generator is None or test_generator is None:  # Verifica se algum dos geradores √© None
                    print("‚ùå Geradores n√£o est√£o dispon√≠veis. Certifique-se de que a aumenta√ß√£o de dados foi configurada corretamente.")  # Exibe mensagem de erro
                    return  # Sai da fun√ß√£o se os geradores n√£o estiverem dispon√≠veis

                if not config_completed:  # Verifica se a configura√ß√£o ainda n√£o foi conclu√≠da
                    try:  # Inicia um bloco try para capturar erros durante o treinamento
                        print(f"‚úÖ Configura√ß√£o final: class_weights={config_params['class_weights']}, arquiteturas={config_params['selected_architectures']}")  # Exibe a configura√ß√£o final
                        print("ü§ñ Iniciando treinamento das arquiteturas selecionadas...")  # Informa o in√≠cio do treinamento

                        resource_monitor_output = widgets.Output()  # Cria um widget de sa√≠da para monitoramento de recursos
                        display(resource_monitor_output)  # Exibe o widget de monitoramento

                        training_progress_output = widgets.Output()  # Cria um widget de sa√≠da para progresso do treinamento
                        display(training_progress_output)  # Exibe o widget de progresso

                        results = []  # Inicializa uma lista vazia para armazenar os resultados do treinamento
                        histories = []  # Inicializa uma lista vazia para armazenar os hist√≥ricos do treinamento
                        trained_models = {}  # Inicializa um dicion√°rio vazio para armazenar os modelos treinados

                        for model_name in config_params['selected_architectures']:  # Itera sobre as arquiteturas selecionadas
                            print(f"\nü§ñ Treinando modelo {model_name}...")  # Informa que o treinamento de um modelo come√ßou
                            with training_progress_output:  # Usa o widget de progresso para exibir mensagens
                                clear_output(wait=True)  # Limpa a sa√≠da anterior no widget
                                print(f"üìä Treinamento do modelo: {model_name}")  # Exibe o nome do modelo sendo treinado
                                progress_bar = tqdm(total=config_params['epochs'], desc=f"√âpocas ({model_name})")  # Cria uma barra de progresso para as √©pocas

                            model_name_result, accuracy, loss, history, model = start_training(  # Chama a fun√ß√£o de treinamento
                                config_params=config_params,  # Passa o dicion√°rio completo de configura√ß√µes
                                architecture_name=model_name,  # Passa o nome da arquitetura
                                num_layers=config_params['num_layers'],  # Passa o n√∫mero de camadas
                                neurons_per_layer=config_params['neurons_per_layer'],  # Passa os neur√¥nios por camada
                                dropout_rate=config_params['dropout_rate'],  # Passa a taxa de dropout
                                learning_rate=config_params['learning_rate'],  # Passa a taxa de aprendizado
                                epochs=config_params['epochs'],  # Passa o n√∫mero de √©pocas
                                use_global_pooling=config_params['use_global_pooling'],  # Passa o uso de pooling global
                                use_regularization=config_params['use_regularization'],  # Passa o uso de regulariza√ß√£o
                                use_activation=config_params['use_activation'],  # Passa o uso de ativa√ß√£o
                                use_early_stopping=config_params['use_early_stopping'],  # Passa o uso de parada antecipada
                                use_batch_norm=config_params['use_batch_norm'],  # Passa o uso de normaliza√ß√£o por batch
                                optimizer=config_params['optimizer'],  # Passa o otimizador
                                activation_function=config_params['activation_function'],  # Passa a fun√ß√£o de ativa√ß√£o
                                normalization=config_params['normalization'],  # Passa o tipo de normaliza√ß√£o
                                use_lr_scheduler=config_params['use_lr_scheduler'],  # Passa o uso de agendador de taxa
                                use_checkpoint=config_params['use_checkpoint'],  # Passa o uso de checkpoints
                                class_weights_dict=config_params['class_weights'],  # Passa os pesos das classes
                                roi_coords=roi_coords,  # Passa as coordenadas da ROI
                                dataDir=dataDir,  # Passa o diret√≥rio de dados
                                image_np=image_np,  # Passa a imagem como array NumPy
                                train_generator=train_generator,  # Passa o gerador de treino
                                valid_generator=valid_generator,  # Passa o gerador de valida√ß√£o
                                test_generator=test_generator,  # Passa o gerador de teste
                                num_classes=num_classes,  # Passa o n√∫mero de classes
                                train_df=train_df,  # Passa o DataFrame de treino
                                valid_df=valid_df,  # Passa o DataFrame de valida√ß√£o
                                test_df=test_df,  # Passa o DataFrame de teste
                                decay_factor=config_params['decay_factor']  # Passa o fator de decaimento
                            )

                            for epoch in range(config_params['epochs']):  # Itera sobre o n√∫mero de √©pocas
                                monitor_resources(resource_monitor_output)  # Monitora os recursos do sistema
                                with training_progress_output:  # Usa o widget de progresso para exibir mensagens
                                    progress_bar.update(1)  # Atualiza a barra de progresso
                                    if history and 'accuracy' in history.history:  # Verifica se h√° hist√≥rico dispon√≠vel
                                        acc = history.history['accuracy'][epoch] if epoch < len(history.history['accuracy']) else acc  # Obt√©m a acur√°cia da √©poca
                                        val_acc = history.history['val_accuracy'][epoch] if epoch < len(history.history['val_accuracy']) else val_acc  # Obt√©m a acur√°cia de valida√ß√£o
                                        print(f"√âpoca {epoch+1}/{config_params['epochs']} - Acur√°cia: {acc:.4f}, Val. Acur√°cia: {val_acc:.4f}")  # Exibe as m√©tricas da √©poca
                                time.sleep(1)  # Pausa de 1 segundo para simula√ß√£o ou monitoramento

                            progress_bar.close()  # Fecha a barra de progresso
                            print(f"‚úÖ Treinamento de {model_name} conclu√≠do: Acur√°cia={accuracy}, Loss={loss}")  # Informa que o treinamento foi conclu√≠do

                            sample_label = train_df['labels'].iloc[0] if not train_df.empty else "N/A"  # Obt√©m um r√≥tulo de exemplo ou "N/A" se o DataFrame estiver vazio
                            display_results(  # Chama uma fun√ß√£o para exibir os resultados do treinamento
                                model_name=model_name,  # Passa o nome do modelo
                                accuracy=accuracy,  # Passa a acur√°cia
                                loss=loss,  # Passa a perda
                                desired_accuracy=0.9,  # Define a acur√°cia desejada como 0.9
                                desired_loss=0.1,  # Define a perda desejada como 0.1
                                image_np=image_np,  # Passa a imagem como array NumPy
                                roi_coords=roi_coords,  # Passa as coordenadas da ROI
                                roi_path=roi_path,  # Passa o caminho da ROI salva
                                label=sample_label  # Passa o r√≥tulo de exemplo
                            )

                            # Ajuste: Usa o train_generator para coletar imagens aumentadas em vez do DataFrame
                            augmented_result = collect_images(train_generator, model_name)  # Coleta imagens aumentadas do gerador de treino
                            augmented_images_data.update(augmented_result)  # Atualiza o dicion√°rio de imagens aumentadas

                            predicted_result = collect_actual_vs_predicted(model, test_df, test_generator, model_name)  # Coleta previs√µes reais vs previstas
                            actual_vs_predicted_data.update(predicted_result)  # Atualiza o dicion√°rio de previs√µes

                            # Impress√£o de depura√ß√£o
                            print(f"Debug: Imagens aumentadas coletadas para {model_name}: {len(augmented_images_data[model_name])}")
                            print(f"Debug: Previs√µes coletadas para {model_name}: {len(actual_vs_predicted_data[model_name])}")

                            print("\nüìä Exibindo imagens aumentadas:")  # Imprime um cabe√ßalho para as previs√µes
                            display_collected_images({model_name: augmented_images_data[model_name]})  # Exibe as imagens aumentadas coletadas

                            print("\nüìä Exibindo todas as previs√µes reais vs previstas:")  # Imprime um cabe√ßalho para as previs√µes
                            display_collected_images({model_name: actual_vs_predicted_data[model_name]})  # Exibe as previs√µes coletadas

                            results.append((model_name_result, accuracy, loss, history))  # Adiciona os resultados √† lista
                            histories.append(history)  # Adiciona o hist√≥rico √† lista
                            trained_models[model_name] = model  # Armazena o modelo treinado no dicion√°rio

                        print("‚úÖ Todos os modelos foram treinados. Prosseguindo para plotagem dos gr√°ficos...")  # Informa que o treinamento foi conclu√≠do
                        plot_all_graphs(histories, results, test_generator, trained_models, config_params['selected_architectures'])  # Plota gr√°ficos com os resultados
                        save_results_to_csv(results, config_params['selected_architectures'])  # Salva os resultados em um arquivo CSV

                        #print("\nüìä Exibindo imagens aumentadas:")  # Imprime um cabe√ßalho para as previs√µes
                        #collected_images(augmented_images_data[model_name])  # Exibe as imagens aumentadas coletadas
                        #print("\nüìä Exibindo todas as previs√µes reais vs previstas:")  # Imprime um cabe√ßalho para as previs√µes
                        #collected_actual_vs_predicted(actual_vs_predicted_data[model_name])  # Exibe as previs√µes coletadas

                        #display_collected_images(augmented_images_data)  # Exibe todas as imagens aumentadas coletadas
                        #print("\nüìä Exibindo todas as previs√µes reais vs previstas:")  # Imprime um cabe√ßalho para as previs√µes
                        #display_collected_actual_vs_predicted(actual_vs_predicted_data)  # Exibe todas as previs√µes reais vs previstas

                        for model_name, model in trained_models.items():  # Itera sobre os modelos treinados
                            if model is not None:  # Verifica se o modelo √© v√°lido
                                model.save(f'/content/drive/MyDrive/Colab Notebooks/{model_name}_modelo_treinado.keras')  # Salva o modelo em um arquivo .keras
                                print(f"‚úÖ Modelo {model_name} salvo com sucesso!")  # Informa que o modelo foi salvo
                            else:  # Caso o modelo seja None
                                print(f"‚ö†Ô∏è Modelo {model_name} n√£o foi treinado corretamente.")  # Informa que o modelo n√£o foi treinado

                        print("‚úÖ Processo conclu√≠do. Verifique os resultados e gr√°ficos gerados.")  # Informa que o processo terminou
                        config_completed = True  # Marca a configura√ß√£o como conclu√≠da
                        start_training_button.disabled = True  # Desabilita o bot√£o de iniciar treinamento
                        reset_all_button.disabled = True  # Desabilita o bot√£o de reset

                    except Exception as e:  # Captura quaisquer exce√ß√µes durante o treinamento
                        print(f"üö´ Erro ao iniciar treinamento: {str(e)}")  # Exibe o erro ocorrido
                        raise  # Relan√ßa a exce√ß√£o para depura√ß√£o

            def on_reset_all(b):  # Define a fun√ß√£o chamada ao clicar no bot√£o de resetar tudo
                nonlocal config_completed, roi_coords, train_df, valid_df, test_df, train_df_roi, valid_df_roi, test_df_roi, image_np, train_generator, valid_generator, test_generator  # Declara vari√°veis externas que ser√£o modificadas
                print("üîç Bot√£o 'Resetar Todos os Par√¢metros' clicado!")  # Informa que o bot√£o foi clicado
                config_completed = False  # Reseta a flag de configura√ß√£o conclu√≠da
                roi_coords = None  # Reseta as coordenadas da ROI
                train_df = train_df_roi.copy() if train_df_roi is not None else train_df  # Restaura o DataFrame de treino para a vers√£o com ROI, se dispon√≠vel
                valid_df = valid_df_roi.copy() if valid_df_roi is not None else valid_df  # Restaura o DataFrame de valida√ß√£o para a vers√£o com ROI, se dispon√≠vel
                test_df = test_df_roi.copy() if test_df_roi is not None else test_df  # Restaura o DataFrame de teste para a vers√£o com ROI, se dispon√≠vel
                image = Image.open(sample_image_path)  # Reabre a imagem de exemplo
                image_np = np.array(image)  # Converte a imagem para um array NumPy
                augmented_images_data.clear()  # Limpa o dicion√°rio de imagens aumentadas
                actual_vs_predicted_data.clear()  # Limpa o dicion√°rio de previs√µes reais vs previstas
                train_generator = None  # Reseta o gerador de treino
                valid_generator = None  # Reseta o gerador de valida√ß√£o
                test_generator = None  # Reseta o gerador de teste
                with final_output:  # Usa o widget de sa√≠da final
                    clear_output()  # Limpa a sa√≠da anterior no widget
                    print("üñ±Ô∏è Selecione a ROI na imagem exibida para reiniciar o processo...")  # Instrui o usu√°rio a selecionar uma nova ROI
                    select_roi_with_sliders(image, roi_path, train_df, valid_df, test_df,  # Chama a fun√ß√£o para selecionar ROI novamente
                                            lambda: after_augmentation(train_df, valid_df, test_df, config_params.get('target_size', (1080, 1920))),
                                            on_roi_confirmed)
                print("‚úÖ Todos os par√¢metros foram resetados! Reinicie o processo de configura√ß√£o.")  # Informa que o reset foi conclu√≠do

            start_training_button.on_click(on_start_training)  # Associa a fun√ß√£o ao clique no bot√£o de iniciar treinamento
            reset_all_button.on_click(on_reset_all)  # Associa a fun√ß√£o ao clique no bot√£o de resetar tudo
            with final_output:  # Usa o widget de sa√≠da final
                print("üñ±Ô∏è Clique em 'Iniciar Treinamento' para prosseguir ou 'Resetar Todos os Par√¢metros' para recome√ßar:")  # Instrui o usu√°rio sobre as op√ß√µes
                display(widgets.HBox([start_training_button, reset_all_button]))  # Exibe os bot√µes finais lado a lado
            display(final_output)  # Exibe o widget de sa√≠da final

        print("\nüñ±Ô∏è Selecione a ROI na imagem exibida...")  # Instrui o usu√°rio a selecionar a ROI
        select_roi_with_sliders(  # Chama a fun√ß√£o para iniciar o processo de sele√ß√£o de ROI
            image,  # Passa a imagem carregada
            roi_path,  # Passa o caminho onde a ROI ser√° salva
            train_df,  # Passa o DataFrame de treino
            valid_df,  # Passa o DataFrame de valida√ß√£o
            test_df,  # Passa o DataFrame de teste
            lambda tg, vg, tg2, nc: after_augmentation(train_df, valid_df, test_df, target_size),  # Define o callback p√≥s-aumenta√ß√£o (ajustado)
            on_roi_confirmed  # Define o callback ao confirmar a ROI
        )

    except Exception as e:  # Captura quaisquer exce√ß√µes durante a execu√ß√£o do fluxo principal
        print(f"üö´ Erro durante a execu√ß√£o: {str(e)}")  # Exibe o erro ocorrido

if __name__ == "__main__":  # Verifica se o script est√° sendo executado diretamente
    train_and_evaluate()  # Chama a fun√ß√£o principal para iniciar o fluxo


# =============================================================================#
# √ÅREA DE COMPARA√á√ÉO DE MODELOS E SALVAR
# =============================================================================#

# ============================
# Fun√ß√£o de comparar os modelos  # Define o in√≠cio da se√ß√£o da fun√ß√£o para compara√ß√£o de modelos
# ============================

def compare_models(results):  # Declara a fun√ß√£o compare_models que recebe uma lista de resultados como par√¢metro
    """
    Compara modelos com base em acur√°cia e perda, exibindo o melhor modelo e uma tabela comparativa.  # Descreve o prop√≥sito da fun√ß√£o

    Args:
        results: Lista de tuplas (model_name, accuracy, loss, history).  # Especifica o formato esperado do argumento 'results'

    Returns:
        tuple: (melhor modelo, DataFrame com a tabela comparativa).  # Indica o que a fun√ß√£o retorna
    """
    if not results:  # Verifica se a lista de resultados est√° vazia
        print("‚ö†Ô∏è Nenhum resultado fornecido para compara√ß√£o.")  # Exibe um aviso se n√£o houver resultados
        return None, None  # Retorna None para o melhor modelo e a tabela se a lista estiver vazia

    best_model = None  # Inicializa a vari√°vel para armazenar o nome do melhor modelo como None
    best_accuracy = 0  # Inicializa a melhor acur√°cia como 0 para compara√ß√£o
    comparison_table = []  # Cria uma lista vazia para armazenar os dados da tabela comparativa

    for model_name, accuracy, loss, history in results:  # Itera sobre cada tupla em 'results', desempacotando em nome, acur√°cia, perda e hist√≥rico
        comparison_table.append((model_name, accuracy, loss))  # Adiciona uma tupla com nome, acur√°cia e perda √† tabela comparativa
        if accuracy > best_accuracy:  # Verifica se a acur√°cia atual √© maior que a melhor acur√°cia registrada
            best_accuracy = accuracy  # Atualiza a melhor acur√°cia com o valor atual, se for maior
            best_model = model_name  # Atualiza o melhor modelo com o nome do modelo atual, se a acur√°cia for maior

    print(f"Melhor Modelo: {best_model} com Acur√°cia: {best_accuracy:.4f}")  # Exibe o nome do melhor modelo e sua acur√°cia com 4 casas decimais
    df_comparison = pd.DataFrame(comparison_table, columns=['Modelo', 'Acur√°cia', 'Perda'])  # Cria um DataFrame pandas com os dados da tabela, definindo os nomes das colunas
    df_comparison['Acur√°cia'] = df_comparison['Acur√°cia'].map('{:.4f}'.format)  # Formata a coluna 'Acur√°cia' para exibir 4 casas decimais
    df_comparison['Perda'] = df_comparison['Perda'].map('{:.4f}'.format)  # Formata a coluna 'Perda' para exibir 4 casas decimais
    print(df_comparison)  # Exibe o DataFrame com a tabela comparativa no console (pode ser substitu√≠do por display no Colab)

    return best_model, df_comparison  # Retorna uma tupla contendo o nome do melhor modelo e o DataFrame da tabela comparativa

# Exemplo de uso:  # Inicia uma se√ß√£o de exemplo comentada
# results = [("VGG16", 0.95, 0.1, {}), ("ResNet50", 0.92, 0.15, {})]  # Define uma lista de resultados de exemplo com tuplas (nome, acur√°cia, perda, hist√≥rico)
# best_model, table = compare_models(results)  # Chama a fun√ß√£o com os resultados de exemplo e armazena o melhor modelo e a tabela retornados

# ============================
# Salvar os resultados em um arquivo CSV  # Define o in√≠cio da se√ß√£o para salvar resultados em CSV
# ============================

import os  # Importa o m√≥dulo os para manipula√ß√£o de diret√≥rios

# Fun√ß√£o para salvar os resultados em um arquivo CSV  # Declara a fun√ß√£o para salvar os resultados em um arquivo CSV
def save_results_to_csv(results, file_path='/content/drive/MyDrive/Colab Notebooks/model_results.csv'):  # Define a fun√ß√£o com par√¢metros: results e file_path com valor padr√£o
    """
    Fun√ß√£o para salvar os resultados de treinamento em um arquivo CSV.  # Descreve o prop√≥sito da fun√ß√£o
    """
    if not results:  # Verifica se a lista de resultados est√° vazia
        print("‚ö†Ô∏è Nenhum resultado fornecido para salvar.")  # Exibe um aviso se n√£o houver resultados
        return None  # Retorna None se a lista estiver vazia

    # Cabe√ßalhos do CSV  # Coment√°rio indicando a defini√ß√£o dos cabe√ßalhos do arquivo CSV
    headers = ['Modelo', 'Acur√°cia', 'Perda']  # Define a lista de cabe√ßalhos para as colunas do CSV

    # Dados para salvar  # Coment√°rio indicando a prepara√ß√£o dos dados a serem salvos
    rows = []  # Inicializa uma lista vazia para armazenar as linhas de dados do CSV
    for i, result in enumerate(results):  # Itera sobre a lista de resultados com √≠ndice, desempacotando cada tupla
        model_name, accuracy, loss, history = result  # Desempacota a tupla em nome do modelo, acur√°cia, perda e hist√≥rico
        rows.append([model_name, f"{accuracy:.4f}", f"{loss:.4f}"])  # Adiciona uma lista com nome, acur√°cia e perda formatadas a 4 casas decimais

    # Salvando os resultados no CSV  # Coment√°rio indicando o in√≠cio do processo de escrita no arquivo CSV
    try:  # Inicia um bloco try para capturar erros durante a escrita
        os.makedirs(os.path.dirname(file_path), exist_ok=True)  # Cria o diret√≥rio do arquivo se ele n√£o existir, sem gerar erro se j√° existir
        with open(file_path, mode='w', newline='') as file:  # Abre o arquivo CSV em modo de escrita, evitando linhas em branco extras com newline=''
            writer = csv.writer(file)  # Cria um objeto escritor CSV para manipular o arquivo
            writer.writerow(headers)  # Escreve a linha de cabe√ßalhos no arquivo CSV
            writer.writerows(rows)  # Escreve todas as linhas de dados no arquivo CSV de uma vez
        print(f"Resultados salvos com sucesso em {file_path}")  # Exibe uma mensagem confirmando que os resultados foram salvos com o caminho do arquivo
        return file_path  # Retorna o caminho do arquivo salvo como confirma√ß√£o de sucesso
    except Exception as e:  # Captura qualquer exce√ß√£o que ocorra durante a escrita
        print(f"‚ùå Erro ao salvar o arquivo CSV: {str(e)}")  # Exibe uma mensagem de erro com detalhes da exce√ß√£o
        return None  # Retorna None em caso de falha


# =============================================================================#
# √ÅREA DE COMPARA√á√ÉO DE MODELOS E SALVAR
# =============================================================================#

# Imports necess√°rios para os gr√°ficos e c√°lculos
import os  # Manipula√ß√£o de arquivos e diret√≥rios
import csv  # Manipula√ß√£o de arquivos CSV
import numpy as np  # Opera√ß√µes num√©ricas
import pandas as pd  # Manipula√ß√£o de DataFrames
import matplotlib.pyplot as plt  # Cria√ß√£o de gr√°ficos
import seaborn as sns  # Visualiza√ß√µes estat√≠sticas
from sklearn.metrics import confusion_matrix, precision_recall_curve, average_precision_score, roc_curve, auc  # M√©tricas de avalia√ß√£o dispon√≠veis
from sklearn.decomposition import PCA  # Redu√ß√£o de dimensionalidade (clusters)
from sklearn.manifold import TSNE  # Redu√ß√£o de dimensionalidade (clusters)
from PIL import Image  # Manipula√ß√£o de imagens

# ============================
# Fun√ß√£o de comparar os modelos
# ============================

def compare_models(histories, results, test_generator, model_names):  # Define fun√ß√£o para comparar modelos
    best_model = None  # Inicializa vari√°vel para melhor modelo
    best_accuracy = 0  # Inicializa melhor acur√°cia como 0
    comparison_table = []  # Lista para armazenar tabela comparativa

    for model_name, accuracy, loss, history in results:  # Itera sobre resultados
        comparison_table.append((model_name, accuracy, loss))  # Adiciona linha √† tabela
        if accuracy > best_accuracy:  # Verifica se a acur√°cia atual √© a melhor
            best_accuracy = accuracy  # Atualiza melhor acur√°cia
            best_model = model_name  # Atualiza melhor modelo

    print(f"Melhor Modelo: {best_model} com Acur√°cia: {best_accuracy:.4f}")  # Exibe melhor modelo e acur√°cia
    df_comparison = pd.DataFrame(comparison_table, columns=['Modelo', 'Acur√°cia', 'Perda'])  # Cria DataFrame com tabela
    print(df_comparison)  # Exibe tabela comparativa

# ============================
# Salvar os resultados em um arquivo CSV
# ============================

def save_results_to_csv(results, model_names, file_path='/content/drive/MyDrive/Colab Notebooks/model_results.csv'):  # Define fun√ß√£o para salvar resultados
    headers = ['Modelo', 'Acur√°cia', 'Perda']  # Define cabe√ßalhos do CSV
    rows = []  # Lista para armazenar linhas do CSV
    for i, result in enumerate(results):  # Itera sobre resultados
        model_name, accuracy, loss, history = result  # Desempacota resultado
        rows.append([model_name, accuracy, loss])  # Adiciona linha ao CSV

    with open(file_path, mode='w', newline='') as file:  # Abre arquivo CSV em modo escrita
        writer = csv.writer(file)  # Cria escritor CSV
        writer.writerow(headers)  # Escreve cabe√ßalhos
        writer.writerows(rows)  # Escreve todas as linhas
    print(f"Resultados salvos com sucesso em {file_path}")  # Confirma salvamento


# =============================================================================#
# √ÅREA DE PLOTAGEM DOS GR√ÅFICOS
# =============================================================================#

# ============================
# Function to display the original and cropped images after each training
# ============================

# Defines function to display results
def display_results(model_name, accuracy, loss, desired_accuracy, desired_loss, image_np, roi_coords, roi_path, label="N/A"):
    x1, y1, x2, y2 = roi_coords  # Extracts ROI coordinates
    x1, x2 = min(x1, x2), max(x1, x2)  # Corrects x order
    y1, y2 = min(y1, y2), max(y2, y1)  # Corrects y order
    roi_coords_adjusted = [x1, y1, x2, y2]  # Stores adjusted coordinates

    roi_image = Image.open(roi_path)  # Opens cropped image
    roi_image_np = np.array(roi_image)  # Converts to NumPy array

    width_roi = x2 - x1  # Calculates ROI width
    height_roi = y2 - y1  # Calculates ROI height

    if roi_image_np.size > 0:  # Checks if the image has pixels
        rgb_mean = np.mean(roi_image_np, axis=(0, 1)).astype(int)  # Calculates RGB mean
        pixel_info = f"Average RGB Values: ({rgb_mean[0]}, {rgb_mean[1]}, {rgb_mean[2]})"  # Formats RGB info
    else:
        pixel_info = "Average RGB Values: (N/A)"  # Sets default info if empty

    plt.figure(figsize=(18, 6))  # Creates figure with specific size
    plt.subplot(1, 2, 1)  # Defines first subplot
    plt.imshow(image_np)  # Displays original image
    plt.title(f"Original Image\nLabel: {label}\nROI: (x1={x1}, y1={y1}, x2={x2}, y2={y2})")  # Sets title
    rect = plt.Rectangle((x1, y1), width_roi, height_roi, edgecolor='red', linewidth=2, fill=False, linestyle='--')  # Creates ROI rectangle
    plt.gca().add_patch(rect)  # Adds rectangle to subplot
    plt.xlabel(f'Width: {width_roi} pixels | Height: {height_roi} pixels')  # X-axis label
    plt.ylabel('Pixels')  # Y-axis label
    plt.grid(True, linestyle='--', alpha=0.5)  # Adds grid
    plt.axis('off')  # Removes axes

    plt.subplot(1, 2, 2)  # Defines second subplot
    plt.imshow(roi_image_np)  # Displays cropped image
    plt.title(f"Cropped Image (ROI)\nLabel: {label}")  # Sets title
    plt.xlabel(f'Width: {width_roi} pixels | Height: {height_roi} pixels')  # X-axis label
    plt.ylabel('Pixels')  # Y-axis label
    plt.text(0.5, -0.1, pixel_info, transform=plt.gca().transAxes, ha='center')  # Adds RGB info
    plt.grid(True, linestyle='--', alpha=0.5)  # Adds grid
    plt.axis('off')  # Removes axes

    plt.suptitle(f"Training Results - {model_name}\nAccuracy: {accuracy:.2f} (Desired: {desired_accuracy:.2f})\nLoss: {loss:.4f} (Desired: {desired_loss:.4f})", fontsize=14)  # Overall title
    plt.tight_layout()  # Adjusts layout
    plt.show()  # Displays plot

# ============================
# Function to visualize clusters
# ============================

def visualize_clusters(model, test_generator, model_name, n_components=2):  # Defines function to visualize clusters
    X = []  # Initializes list to store features (model predictions)
    y = []  # Initializes list to store true labels
    batch_size = test_generator.batch_size  # Gets batch size from generator
    total_samples = test_generator.samples  # Gets total number of samples in generator

    # Iterates over all batches in the generator
    for batch_images, batch_labels in test_generator:  # Loop to extract images and labels from batches
        preds = model.predict(batch_images, verbose=0)  # Generates model predictions for the batch
        X.append(preds)  # Adds predictions to list X
        if batch_labels.ndim > 1:  # Checks if labels are one-hot encoded
            batch_labels = np.argmax(batch_labels, axis=1)  # Converts one-hot labels to indices
        y.append(batch_labels)  # Adds labels to list y
        if len(np.concatenate(y)) >= total_samples:  # Stops loop when all samples are collected
            break

    # Converts lists to arrays and limits to total number of samples
    X = np.concatenate(X, axis=0)[:total_samples]  # Concatenates predictions into array and limits to total samples
    y = np.concatenate(y, axis=0)[:total_samples]  # Concatenates labels into array and limits to total samples

    # Checks if X has the expected shape (n_samples, n_features)
    if X.shape[1] == 1:  # Checks if X is a vector (single class output)
        X = X.flatten()  # Flattens to 1D if necessary
    elif X.shape[1] > 1:  # Checks if X is multi-class (probabilities or features)
        X = X  # Keeps X as is (n_samples, n_classes)
    else:  # If X shape is invalid
        raise ValueError(f"Invalid X shape: {X.shape}. Expected (n_samples, n_features).")  # Raises error

    if len(X) != len(y):  # Checks if sizes of X and y are consistent
        raise ValueError(f"Inconsistent sizes: X ({len(X)}) vs y ({len(y)}).")  # Raises error if inconsistent

    if n_components == 2:  # If visualization is in 2D
        reducer = PCA(n_components=2)  # Initializes PCA to reduce to 2 components
        X_reduced = reducer.fit_transform(X)  # Reduces X dimensionality with PCA
        plt.figure(figsize=(10, 6))  # Creates figure with size 10x6
        scatter = plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=y, cmap='viridis')  # Plots points with colors based on y
        plt.colorbar(scatter)  # Adds colorbar to plot
        plt.title(f'2D Clusters (PCA) - {model_name}', fontsize=12)  # Sets plot title
        plt.xlabel('Component 1', fontsize=10)  # X-axis label
        plt.ylabel('Component 2', fontsize=10)  # Y-axis label
        plt.show()  # Displays plot
    elif n_components == 3:  # If visualization is in 3D
        n_samples = X.shape[0]  # Gets number of samples from X
        perplexity = min(30, max(5, n_samples - 1))  # Sets perplexity for t-SNE (minimum 5, maximum 30)
        print(f"üîç Using perplexity={perplexity} for {n_samples} samples in 3D t-SNE")  # Displays used perplexity
        reducer = TSNE(n_components=3, random_state=42, perplexity=perplexity)  # Initializes t-SNE for 3 components
        X_reduced = reducer.fit_transform(X)  # Reduces X dimensionality with t-SNE
        fig = plt.figure(figsize=(10, 8))  # Creates figure with size 10x8
        ax = fig.add_subplot(111, projection='3d')  # Adds 3D subplot
        scatter = ax.scatter(X_reduced[:, 0], X_reduced[:, 1], X_reduced[:, 2], c=y, cmap='viridis')  # Plots 3D points
        plt.colorbar(scatter)  # Adds colorbar
        ax.set_title(f'3D Clusters (TSNE) - {model_name}', fontsize=12)  # Sets plot title
        ax.set_xlabel('Component 1', fontsize=10)  # X-axis label
        ax.set_ylabel('Component 2', fontsize=10)  # Y-axis label
        ax.set_zlabel('Component 3', fontsize=10)  # Z-axis label
        plt.show()  # Displays plot

# ============================
# Function to plot all graphs
# ============================

def plot_all_graphs(histories, results, test_generator, trained_models, model_names):
    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    from sklearn.metrics import confusion_matrix, precision_recall_curve, average_precision_score

    # Set default figure size
    default_figsize = (10, 6)  # Defines default size for figures

    # Debug: Check inputs
    print(f"üîç Debug: Inputs for plot_all_graphs:")  # Displays debug header
    print(f"histories: {len(histories)} items")  # Displays number of histories
    for i, h in enumerate(histories):
        print(f"History {i}: {h.history.keys() if h else 'No history'}")  # Displays keys for each history
    print(f"results: {results}")  # Displays results
    print(f"test_generator.samples: {test_generator.samples}")  # Displays test samples
    print(f"trained_models: {list(trained_models.keys())}")  # Displays models
    print(f"model_names: {model_names}")  # Displays architectures

    # === Training Performance Plots ===
    print("\n=== Training Performance Plots ===")  # Displays header
    for i, history in enumerate(histories):  # Iterates over histories
        if not history or not history.history:  # Checks if history is valid
            print(f"‚ö†Ô∏è History {i} empty or invalid for {model_names[i]}. Skipping.")  # Displays warning
            continue
        plt.figure(figsize=default_figsize)  # Creates new figure
        if 'accuracy' in history.history:  # Checks for accuracy metric
            plt.plot(history.history['accuracy'], label='Accuracy (Training)')  # Plots training accuracy
            plt.plot(history.history['val_accuracy'], label='Accuracy (Validation)')  # Plots validation accuracy
        if 'loss' in history.history:  # Checks for loss metric
            plt.plot(history.history['loss'], label='Loss (Training)')  # Plots training loss
            plt.plot(history.history['val_loss'], label='Loss (Validation)')  # Plots validation loss
        plt.title(f'Model Performance - {model_names[i]}', fontsize=12)  # Sets title
        plt.xlabel('Epoch', fontsize=10)  # Sets x-axis label
        plt.ylabel('Metric', fontsize=10)  # Sets y-axis label
        plt.legend()  # Adds legend
        plt.grid(True, linestyle='--', alpha=0.7)  # Adds grid
        plt.tight_layout()  # Adjusts spacing automatically
        plt.subplots_adjust(top=0.85, bottom=0.15, left=0.1, right=0.9)  # Adds extra margins
        plt.show()  # Displays plot

    # === Model Evaluation Plots ===
    print("\n=== Model Evaluation Plots ===")  # Displays header
    y_true = []  # Initializes list for true labels
    y_pred_probs_dict = {}  # Initializes dictionary for predicted probabilities
    test_generator.reset()  # Resets test generator
    steps = min(10, len(test_generator))  # Limits number of steps to avoid overload

    try:  # Attempts to collect predictions
        for i in range(steps):  # Iterates over generator batches
            images, labels = next(test_generator)  # Gets images and labels
            if labels.ndim > 1:  # Checks if labels are one-hot encoded
                labels = np.argmax(labels, axis=1)  # Converts to indices
            y_true.extend(labels)  # Adds labels to list
            for model_name, model in trained_models.items():  # Iterates over models
                if model_name not in y_pred_probs_dict:  # Initializes list for model
                    y_pred_probs_dict[model_name] = []
                preds = model.predict(images, verbose=0)  # Makes predictions
                y_pred_probs_dict[model_name].extend(preds)  # Adds predictions
    except Exception as e:  # Catches errors
        print(f"‚ùå Error collecting predictions: {str(e)}")  # Displays error
        return

    y_true = np.array(y_true)  # Converts labels to array
    for model_name in y_pred_probs_dict:  # Iterates over models
        y_pred_probs_dict[model_name] = np.array(y_pred_probs_dict[model_name])[:len(y_true)]  # Converts predictions to array and limits to y_true size

    for i, result in enumerate(results):  # Iterates over results
        model_name, accuracy, loss, history = result  # Unpacks result
        model = trained_models.get(model_name)  # Gets model
        if model is None:  # Checks if model exists
            print(f"‚ö†Ô∏è Model {model_name} not found. Skipping.")  # Displays warning
            continue
        y_pred_probs = y_pred_probs_dict.get(model_name, [])  # Gets probabilities
        if len(y_pred_probs) == 0:  # Checks if predictions exist
            print(f"‚ö†Ô∏è No predictions for {model_name}. Skipping.")  # Displays warning
            continue
        y_pred = np.argmax(y_pred_probs, axis=1)  # Converts probabilities to classes
        n_classes = len(test_generator.class_indices)  # Gets number of classes

        # Precision-Recall Curve
        plt.figure(figsize=default_figsize)  # Creates new figure
        for cls in range(n_classes):  # Iterates over classes
            y_true_bin = (y_true == cls).astype(int)  # Binarizes labels for current class
            precision, recall, _ = precision_recall_curve(y_true_bin, y_pred_probs[:, cls])  # Calculates precision and recall
            ap_score = average_precision_score(y_true_bin, y_pred_probs[:, cls])  # Calculates AP score
            plt.plot(recall, precision, label=f'Class {cls} (AP = {ap_score:.2f})')  # Plots curve
        plt.xlabel('Recall', fontsize=10)  # Sets x-axis label
        plt.ylabel('Precision', fontsize=10)  # Sets y-axis label
        plt.title(f'Precision-Recall Curve - {model_name}', fontsize=12)  # Sets title
        plt.legend()  # Adds legend
        plt.grid(True, linestyle='--', alpha=0.7)  # Adds grid
        plt.tight_layout()  # Adjusts spacing
        plt.subplots_adjust(top=0.85, bottom=0.15, left=0.1, right=0.9)  # Adds margins
        plt.show()  # Displays plot

        # Class Error Plot
        errors = y_true != y_pred  # Calculates errors
        error_counts = np.bincount(y_true[errors], minlength=n_classes)  # Counts errors per class
        plt.figure(figsize=default_figsize)  # Creates new figure
        class_names = list(test_generator.class_indices.keys())  # Gets class names
        plt.bar(class_names, error_counts, color='red')  # Plots bars
        plt.title(f'Errors per Class - {model_name}', fontsize=12)  # Sets title
        plt.xlabel('Class', fontsize=10)  # Sets x-axis label
        plt.ylabel('Number of Errors', fontsize=10)  # Sets y-axis label
        plt.xticks(rotation=45)  # Rotates labels
        plt.grid(True, linestyle='--', alpha=0.7)  # Adds grid
        plt.tight_layout()  # Adjusts spacing
        plt.subplots_adjust(top=0.85, bottom=0.2, left=0.1, right=0.9)  # Adds margins
        plt.show()  # Displays plot

        # Confusion Matrix
        cm = confusion_matrix(y_true, y_pred)  # Calculates confusion matrix
        plt.figure(figsize=default_figsize)  # Creates new figure
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')  # Plots heatmap
        plt.title(f'Confusion Matrix - {model_name}', fontsize=12)  # Sets title
        plt.xlabel('Predicted', fontsize=10)  # Sets x-axis label
        plt.ylabel('True', fontsize=10)  # Sets y-axis label
        plt.tight_layout()  # Adjusts spacing
        plt.subplots_adjust(top=0.85, bottom=0.15, left=0.1, right=0.9)  # Adds margins
        plt.show()  # Displays plot

    # === Distribution and Prediction Plots ===
    print("\n=== Distribution and Prediction Plots ===")  # Displays header
    for i, result in enumerate(results):  # Iterates over results
        model_name, accuracy, loss, history = result  # Unpacks result
        model = trained_models.get(model_name)  # Gets model
        if model is None:  # Checks model
            print(f"‚ö†Ô∏è Model {model_name} not found. Skipping.")  # Displays warning
            continue
        y_pred = np.argmax(y_pred_probs_dict.get(model_name, []), axis=1)  # Gets predicted classes
        if len(y_pred) == 0:  # Checks predictions
            print(f"‚ö†Ô∏è No predictions for {model_name}. Skipping.")  # Displays warning
            continue
        plt.figure(figsize=default_figsize)  # Creates new figure
        sns.histplot(y_pred, bins=n_classes, color="blue", kde=False)  # Plots histogram
        plt.title(f"Prediction Histogram - {model_name}", fontsize=12)  # Sets title
        plt.xlabel('Predicted Class', fontsize=10)  # Sets x-axis label
        plt.ylabel('Frequency', fontsize=10)  # Sets y-axis label
        plt.grid(True, linestyle='--', alpha=0.7)  # Adds grid
        plt.tight_layout()  # Adjusts spacing
        plt.subplots_adjust(top=0.85, bottom=0.15, left=0.1, right=0.9)  # Adds margins
        plt.show()  # Displays plot

        plt.figure(figsize=default_figsize)  # Creates new figure
        sns.histplot(y_true, bins=n_classes, color="green", label="True", kde=False, alpha=0.6)  # Plots true histogram
        sns.histplot(y_pred, bins=n_classes, color="blue", label="Predicted", kde=False, alpha=0.6)  # Plots predicted histogram
        plt.title(f"Class Distribution - {model_name}", fontsize=12)  # Sets title
        plt.xlabel('Classes', fontsize=10)  # Sets x-axis label
        plt.ylabel('Frequency', fontsize=10)  # Sets y-axis label
        plt.legend()  # Adds legend
        plt.grid(True, linestyle='--', alpha=0.7)  # Adds grid
        plt.tight_layout()  # Adjusts spacing
        plt.subplots_adjust(top=0.85, bottom=0.15, left=0.1, right=0.9)  # Adds margins
        plt.show()  # Displays plot

    # === Model Comparison Plots ===
    print("\n=== Model Comparison Plots ===")  # Displays header
    accuracies = [result[1] for result in results]  # Gets accuracies
    losses = [result[2] for result in results]  # Gets losses
    plt.figure(figsize=default_figsize)  # Creates new figure
    plt.bar(model_names, accuracies, label='Accuracy', color='skyblue')  # Plots accuracy bars
    plt.bar(model_names, losses, label='Loss', alpha=0.5, color='salmon')  # Plots loss bars
    plt.title("Accuracy and Loss Comparison Across Models", fontsize=12)  # Sets title
    plt.xlabel("Models", fontsize=10)  # Sets x-axis label
    plt.ylabel("Value", fontsize=10)  # Sets y-axis label
    plt.legend()  # Adds legend
    plt.grid(True, linestyle='--', alpha=0.7)  # Adds grid
    plt.tight_layout()  # Adjusts spacing
    plt.subplots_adjust(top=0.85, bottom=0.15, left=0.1, right=0.9)  # Adds margins
    plt.show()  # Displays plot

    # === ROC Curve Plots ===
    print("\n=== ROC Curve Plots ===")  # Displays header
    for model_name in y_pred_probs_dict:  # Iterates over models in predicted probabilities dictionary
        y_pred_probs = y_pred_probs_dict[model_name]  # Gets predicted probabilities for current model
        n_classes = len(test_generator.class_indices)  # Calculates number of classes from test generator
        plt.figure(figsize=default_figsize)  # Creates figure with default size
        for cls in range(n_classes):  # Iterates over classes
            y_true_bin = (y_true == cls).astype(int)  # Binarizes true labels for current class
            fpr, tpr, _ = roc_curve(y_true_bin, y_pred_probs[:, cls])  # Calculates FPR and TPR for ROC curve
            roc_auc = auc(fpr, tpr)  # Calculates area under ROC curve (AUC)
            plt.plot(fpr, tpr, label=f'Class {cls} (AUC = {roc_auc:.2f})')  # Plots ROC curve for class
        plt.plot([0, 1], [0, 1], 'k--', label='Random')  # Plots diagonal line (random model)
        plt.xlabel('False Positive Rate (FPR)', fontsize=10)  # Sets x-axis label
        plt.ylabel('True Positive Rate (TPR)', fontsize=10)  # Sets y-axis label
        plt.title(f'ROC Curve - {model_name}', fontsize=12)  # Sets title
        plt.legend()  # Adds legend
        plt.grid(True, linestyle='--', alpha=0.7)  # Adds grid
        plt.tight_layout()  # Adjusts layout
        plt.subplots_adjust(top=0.85, bottom=0.15, left=0.1, right=0.9)  # Adjusts margins
        plt.show()  # Displays plot

    # === Probability Calibration Plots ===
    print("\n=== Probability Calibration Plots ===")  # Displays header
    from sklearn.calibration import calibration_curve  # Imports calibration curve function
    for model_name in y_pred_probs_dict:  # Iterates over models in predicted probabilities dictionary
        y_pred_probs = y_pred_probs_dict[model_name]  # Gets predicted probabilities for current model
        n_classes = len(test_generator.class_indices)  # Calculates number of classes from test generator
        plt.figure(figsize=default_figsize)  # Creates figure with default size
        for cls in range(n_classes):  # Iterates over classes
            y_true_bin = (y_true == cls).astype(int)  # Binarizes true labels for current class
            prob_true, prob_pred = calibration_curve(y_true_bin, y_pred_probs[:, cls], n_bins=10)  # Calculates calibration curve
            plt.plot(prob_pred, prob_true, marker='o', label=f'Class {cls}')  # Plots calibration curve for class
        plt.plot([0, 1], [0, 1], 'k--', label='Perfectly Calibrated')  # Plots diagonal line (perfect calibration)
        plt.xlabel('Predicted Probability', fontsize=10)  # Sets x-axis label
        plt.ylabel('Fraction of Positives', fontsize=10)  # Sets y-axis label
        plt.title(f'Calibration Curve - {model_name}', fontsize=12)  # Sets title
        plt.legend()  # Adds legend
        plt.grid(True, linestyle='--', alpha=0.7)  # Adds grid
        plt.tight_layout()  # Adjusts layout
        plt.subplots_adjust(top=0.85, bottom=0.15, left=0.1, right=0.9)  # Adjusts margins
        plt.show()  # Displays plot

    # === Boxplot of Predicted Probabilities by Class ===
    print("\n=== Boxplot of Predicted Probabilities by Class ===")  # Displays header
    for model_name in y_pred_probs_dict:  # Iterates over models in predicted probabilities dictionary
        y_pred_probs = y_pred_probs_dict[model_name]  # Gets predicted probabilities for current model
        n_classes = len(test_generator.class_indices)  # Calculates number of classes from test generator
        class_names = list(test_generator.class_indices.keys())  # Gets class names
        plt.figure(figsize=(max(8, n_classes * 1.5), 6))  # Creates figure with width adjusted to number of classes
        data_to_plot = [y_pred_probs[:, cls] for cls in range(n_classes)]  # Prepares data for boxplot (probabilities per class)
        sns.boxplot(data=data_to_plot)  # Creates boxplot of predicted probabilities
        plt.xticks(ticks=range(n_classes), labels=class_names, rotation=45)  # Sets x-axis labels with class names
        plt.xlabel('Class', fontsize=10)  # Sets x-axis label
        plt.ylabel('Predicted Probability', fontsize=10)  # Sets y-axis label
        plt.title(f'Distribution of Predicted Probabilities - {model_name}', fontsize=12)  # Sets title
        plt.grid(True, linestyle='--', alpha=0.7)  # Adds grid
        plt.tight_layout()  # Adjusts layout
        plt.subplots_adjust(top=0.85, bottom=0.2, left=0.1, right=0.9)  # Adjusts margins
        plt.show()  # Displays plot

    # === Training Time Comparison Plots (Simulated) ===
    print("\n=== Training Time Comparison Plots (Simulated) ===")  # Displays header
    simulated_training_times = [random.uniform(100, 500) for _ in model_names]  # Generates simulated training times
    plt.figure(figsize=default_figsize)  # Creates figure with default size
    plt.bar(model_names, simulated_training_times, color='lightgreen')  # Creates bar plot with simulated times
    plt.title('Training Time Comparison Across Models', fontsize=12)  # Sets title
    plt.xlabel('Models', fontsize=10)  # Sets x-axis label
    plt.ylabel('Time (seconds)', fontsize=10)  # Sets y-axis label
    plt.grid(True, linestyle='--', alpha=0.7)  # Adds grid
    plt.tight_layout()  # Adjusts layout
    plt.subplots_adjust(top=0.85, bottom=0.15, left=0.1, right=0.9)  # Adjusts margins
    plt.show()  # Displays plot

    # === Learning Rate Over Epochs Plots ===
    print("\n=== Learning Rate Over Epochs Plots ===")  # Displays header
    for i, history in enumerate(histories):  # Iterates over training histories
        model_name = model_names[i]  # Gets model name
        if not history or not history.history:  # Checks if history is valid
            print(f"‚ö†Ô∏è History {i} empty or invalid for {model_name}. Skipping.")  # Displays warning
            continue
        # Checks if learning rate was recorded in history
        if 'lr' in history.history:  # If callback recorded learning rate
            plt.figure(figsize=default_figsize)  # Creates new figure
            plt.plot(history.history['lr'], label='Learning Rate', color='purple')  # Plots learning rate
            plt.title(f'Learning Rate Over Epochs - {model_name}', fontsize=12)  # Sets title
            plt.xlabel('Epoch', fontsize=10)  # Sets x-axis label
            plt.ylabel('Learning Rate', fontsize=10)  # Sets y-axis label
            plt.yscale('log')  # Uses logarithmic scale for better visualization
            plt.grid(True, linestyle='--', alpha=0.7)  # Adds grid
            plt.legend()  # Adds legend
            plt.tight_layout()  # Adjusts spacing
            plt.subplots_adjust(top=0.85, bottom=0.15, left=0.1, right=0.9)  # Adds margins
            plt.show()  # Displays plot
        else:
            print(f"‚ö†Ô∏è Learning rate not recorded in history for {model_name}. Simulating a typical scheduler...")
            # Simulates a decreasing learning rate (e.g., ReduceLROnPlateau)
            epochs = len(history.history['loss'])  # Number of epochs
            initial_lr = config_params.get('learning_rate', 0.001)  # Initial learning rate
            simulated_lr = [initial_lr * (0.5 ** (epoch // 5)) for epoch in range(epochs)]  # Simulates reduction every 5 epochs
            plt.figure(figsize=default_figsize)  # Creates new figure
            plt.plot(simulated_lr, label='Learning Rate (Simulated)', color='purple')  # Plots simulated learning rate
            plt.title(f'Simulated Learning Rate Over Epochs - {model_name}', fontsize=12)  # Sets title
            plt.xlabel('Epoch', fontsize=10)  # Sets x-axis label
            plt.ylabel('Learning Rate', fontsize=10)  # Sets y-axis label
            plt.yscale('log')  # Uses logarithmic scale
            plt.grid(True, linestyle='--', alpha=0.7)  # Adds grid
            plt.legend()  # Adds legend
            plt.tight_layout()  # Adjusts spacing
            plt.subplots_adjust(top=0.85, bottom=0.15, left=0.1, right=0.9)  # Adds margins
            plt.show()  # Displays plot

    # === F1-Score Comparison Plots by Class ===
    print("\n=== F1-Score Comparison Plots by Class ===")  # Displays header
    from sklearn.metrics import f1_score  # Already imported in code
    for model_name in y_pred_probs_dict:  # Iterates over models
        y_pred_probs = y_pred_probs_dict[model_name]  # Gets predicted probabilities
        y_pred = np.argmax(y_pred_probs, axis=1)  # Converts to predicted classes
        n_classes = len(test_generator.class_indices)  # Gets number of classes
        class_names = list(test_generator.class_indices.keys())  # Gets class names
        f1_scores = []  # List to store F1-Scores per class
        for cls in range(n_classes):  # Iterates over classes
            y_true_bin = (y_true == cls).astype(int)  # Binarizes labels for current class
            y_pred_bin = (y_pred == cls).astype(int)  # Binarizes predictions for current class
            f1 = f1_score(y_true_bin, y_pred_bin)  # Calculates F1-Score for class
            f1_scores.append(f1)  # Adds to list
        plt.figure(figsize=(max(8, n_classes * 1.5), 6))  # Creates figure with adjusted width
        plt.bar(class_names, f1_scores, color='orange')  # Plots bars
        plt.title(f'F1-Score per Class - {model_name}', fontsize=12)  # Sets title
        plt.xlabel('Class', fontsize=10)  # Sets x-axis label
        plt.ylabel('F1-Score', fontsize=10)  # Sets y-axis label
        plt.ylim(0, 1)  # Sets y-axis limit between 0 and 1
        plt.xticks(rotation=45)  # Rotates class labels
        plt.grid(True, linestyle='--', alpha=0.7)  # Adds grid
        plt.tight_layout()  # Adjusts spacing
        plt.subplots_adjust(top=0.85, bottom=0.2, left=0.1, right=0.9)  # Adds margins
        plt.show()  # Displays plot

    # === Validation Metrics Comparison Plots Across Models ===
    print("\n=== Validation Metrics Comparison Plots Across Models ===")  # Displays header
    val_accuracies = []  # List for validation accuracies
    val_losses = []  # List for validation losses
    valid_models = []  # List for valid models
    for i, history in enumerate(histories):  # Iterates over histories
        if not history or not history.history or 'val_accuracy' not in history.history:  # Checks if history is valid
            continue  # Skips if invalid
        val_accuracies.append(history.history['val_accuracy'][-1])  # Gets last validation accuracy
        val_losses.append(history.history['val_loss'][-1])  # Gets last validation loss
        valid_models.append(model_names[i])  # Adds model name to list
    if val_accuracies:  # Checks if data is available to plot
        plt.figure(figsize=default_figsize)  # Creates new figure
        x = np.arange(len(valid_models))  # Positions for bars
        plt.bar(x - 0.2, val_accuracies, 0.4, label='Validation Accuracy', color='skyblue')  # Plots accuracy bars
        plt.bar(x + 0.2, val_losses, 0.4, label='Validation Loss', color='salmon')  # Plots loss bars
        plt.xticks(x, valid_models, rotation=45)  # Sets model labels
        plt.title('Validation Metrics Comparison Across Models', fontsize=12)  # Sets title
        plt.xlabel('Models', fontsize=10)  # Sets x-axis label
        plt.ylabel('Value', fontsize=10)  # Sets y-axis label
        plt.legend()  # Adds legend
        plt.grid(True, linestyle='--', alpha=0.7)  # Adds grid
        plt.tight_layout()  # Adjusts spacing
        plt.subplots_adjust(top=0.85, bottom=0.2, left=0.1, right=0.9)  # Adds margins
        plt.show()  # Displays plot
    else:
        print("‚ö†Ô∏è No validation data available for comparison.")

    # === Pixel Intensity Distribution Plots ===
    print("\n=== Pixel Intensity Distribution Plots ===")  # Displays header
    test_generator.reset()  # Resets test generator
    try:
        images, _ = next(test_generator)  # Gets a sample of images from generator
        image = images[0].numpy().astype(np.uint8)  # Extracts first image and converts to uint8
    except Exception as e:
        print(f"‚ùå Error retrieving image from test_generator: {str(e)}")  # Displays error if failed
        return

    # Separates RGB channels of the image
    r_channel = image[:, :, 0]  # Red channel
    g_channel = image[:, :, 1]  # Green channel
    b_channel = image[:, :, 2]  # Blue channel

    # Flattens each channel to a 1D array
    r_pixels = r_channel.flatten()
    g_pixels = g_channel.flatten()
    b_pixels = b_channel.flatten()

    # Creates figure for histogram with specified size
    plt.figure(figsize=(10, 6))

    # Histogram for red channel
    plt.hist(r_pixels, bins=256, range=(0, 256), color='red', alpha=0.5, label='Red Channel')
    # Histogram for green channel
    plt.hist(g_pixels, bins=256, range=(0, 256), color='green', alpha=0.5, label='Green Channel')
    # Histogram for blue channel
    plt.hist(b_pixels, bins=256, range=(0, 256), color='blue', alpha=0.5, label='Blue Channel')

    # Customizes plot labels in English
    plt.xlabel('Pixel Intensity')  # X-axis label (Pixel Intensity)
    plt.ylabel('Number of Pixels')  # Y-axis label (Number of Pixels)
    plt.title('RGB Pixel Intensity Distribution')  # Plot title (RGB Pixel Intensity Distribution)

    # Adds vertical lines for Average Tone (127) and Absolute White (255)
    plt.axvline(x=127, color='gray', linestyle='--', label='Average Tone (127)')
    plt.axvline(x=255, color='gray', linestyle='--', label='Absolute White (255)')

    # Adds region labels (Shadows, Midtones, Highlights)
    plt.text(0, plt.ylim()[1] * 0.9, 'Shadows', horizontalalignment='left', fontsize=10, color='black')  # Shadows
    plt.text(127, plt.ylim()[1] * 0.9, 'Midtones', horizontalalignment='center', fontsize=10, color='black')  # Midtones
    plt.text(255, plt.ylim()[1] * 0.9, 'Highlights', horizontalalignment='right', fontsize=10, color='black')  # Highlights

    # Adds legend to distinguish channels
    plt.legend()

    # Displays plot
    plt.show()
